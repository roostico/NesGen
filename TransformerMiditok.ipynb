{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n!unzip \"maestro-v3.0.0-midi.zip\"\n!rm \"maestro-v3.0.0-midi.zip\"\n\ndataset_path = \"/kaggle/working/maestro-v3.0.0\"","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install gdown\n!pip install pretty_midi\n!pip install miditok\n!pip install pretty_midi midi-clip\n!pip install transformers\n!pip install accelerate","metadata":{"id":"-E_cQreQk-8u","trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Download NESDB dataset","metadata":{}},{"cell_type":"code","source":"!gdown 1gIli7G1wu0QWDLzRc-CPWB8C4Hu0XVn3\n!unzip nesmdb_midi.zip\n!rm nesmdb_midi.zip","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Utility library\n\n!wget https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/utility.py\n!wget https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/transformer.py\n\nfrom utility import *","metadata":{"id":"NHKsN90VswB-","trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import libraries","metadata":{"id":"Ln0a94DmCede"}},{"cell_type":"code","source":"import os\nimport random\nimport shutil\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport pretty_midi\nimport numpy as np\nfrom miditok import REMI, TokenizerConfig\nimport json\nimport keras_nlp.layers as nlp_layers\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom miditok.utils import split_files_for_training\nfrom miditok.data_augmentation import augment_dataset\nimport random\nfrom random import shuffle","metadata":{"id":"nmXk2h-HCf42","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Move files and rename them","metadata":{"id":"AEgwypV4k_-t"}},{"cell_type":"code","source":"# Paths to the files of the dataset\n\nmidi_paths = list(Path(dataset_path).resolve().glob(\"**/*.mid\")) + list(Path(dataset_path).resolve().glob(\"**/*.midi\"))\nnesmdb_paths = list(Path(\"/kaggle/working/nesmdb_midi\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/nesmdb_midi\").resolve().glob(\"**/*.midi\"))\n\nmidis_dir = \"midis\"\nos.makedirs(midis_dir, exist_ok=True)\n\nnesmdb_dir = \"nesmdb\"\nos.makedirs(nesmdb_dir, exist_ok=True)\n\n\nfor i, midi_path in enumerate(midi_paths):\n  new_midi_path = os.path.join(midis_dir, f\"{i}.midi\")\n  shutil.move(str(midi_path), new_midi_path)\n\nfor i, midi_path in enumerate(nesmdb_paths):\n  new_midi_path = os.path.join(nesmdb_dir, f\"{i}.midi\")\n  shutil.move(str(midi_path), new_midi_path)\n\nmidis = list(Path(\"/kaggle/working/midis\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/midis\").resolve().glob(\"**/*.midi\"))\nnes_midis = list(Path(\"/kaggle/working/nesmdb\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/nesmdb\").resolve().glob(\"**/*.midi\"))\n\ndef sample():\n  return str(random.choice(midis))","metadata":{"id":"a6elj9pecSnQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenizer\n\n\n","metadata":{"id":"X_qYrXTErrsH"}},{"cell_type":"code","source":"BEAT_RES = {(0, 1): 12, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n\nTOKENIZER_PARAMS = {\n\n    \"pitch_range\": (21, 109),\n\n    \"beat_res\": BEAT_RES,\n\n    \"num_velocities\": 24,\n\n    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n\n    \"use_chords\": True,\n\n    \"use_rests\": True,\n\n    \"use_tempos\": True,\n\n    \"use_time_signatures\": True,\n\n    \"use_programs\": False,  # no multitrack here\n\n    \"num_tempos\": 32,\n\n    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n\n}\n\nconfig = TokenizerConfig(**TOKENIZER_PARAMS)\n\ntokenizer = REMI(config)","metadata":{"id":"fM44SXMEHNmo","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### (Optional): load a trained tokenizer","metadata":{}},{"cell_type":"code","source":"!gdown 1XUgih6NF5mNOma5tUF1Ep7pTyc5Ps_FW\ntokenizer = REMI(params=Path(\"/kaggle/working/tokenizer.json\"))\nprint(f\"Vocab size: {len(tokenizer)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### (Optional): train the tokenizer","metadata":{"id":"VqhBEeOGHUZB"}},{"cell_type":"code","source":"tokenizer.train(vocab_size=30000, files_paths=midis + nes_midis)","metadata":{"id":"ELI4Z2GhHZFB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processed = [Path(f\"{s}\") for s in midis]\nprint(len(processed))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_num_files = len(processed)\nnum_files_valid = round(total_num_files * 0.15)\nnum_files_test = round(total_num_files * 0.15)\nshuffle(processed)\nmidi_paths_valid = processed[:num_files_valid]\nmidi_paths_test = processed[num_files_valid:num_files_valid + num_files_test]\nmidi_paths_train = processed[num_files_valid + num_files_test:]\n\n# Chunk MIDIs and perform data augmentation on each subset independently\n\nfor files_paths, subset_name in (\n\n    (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\"), (midi_paths_test, \"test\")\n\n):\n    print(files_paths[0])\n\n    # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n\n    subset_chunks_dir = Path(f\"Maestro_{subset_name}\")\n\n    split_files_for_training(\n\n        files_paths=files_paths,\n\n        tokenizer=tokenizer,\n\n        save_dir=subset_chunks_dir,\n\n        max_seq_len=1024,\n\n        num_overlap_bars=2,\n\n    )\n\n\n\n    # Perform data augmentation\n\n    augment_dataset(\n\n        subset_chunks_dir,\n\n        pitch_offsets=[-12, 12],\n\n        velocity_offsets=[-4, 4],\n\n        duration_offsets=[-0.5, 0.5],\n\n    )\nmidi_paths_train = list(Path(\"Maestro_train\").glob(\"**/*.mid\")) + list(Path(\"Maestro_train\").glob(\"**/*.midi\"))\nmidi_paths_valid = list(Path(\"Maestro_valid\").glob(\"**/*.mid\")) + list(Path(\"Maestro_valid\").glob(\"**/*.midi\"))\nmidi_paths_test = list(Path(\"Maestro_test\").glob(\"**/*.mid\")) + list(Path(\"Maestro_test\").glob(\"**/*.midi\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tokenizer the dataset","metadata":{"id":"CGr1Z52HHaaI"}},{"cell_type":"code","source":"def midi_valid(midi) -> bool:\n\n    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n\n        return False  # time signature different from 4/*, 4 beats per bar\n\n    return True\n\n\n\nif os.path.exists(\"tokenized\"):\n\n  shutil.rmtree(\"tokenized\")\n\n\nfor dir in (\"train\", \"valid\", \"test\"):\n    tokenizer.tokenize_dataset(        \n    \n        Path(f\"/kaggle/working/Maestro_{dir}\"),\n        Path(f\"/kaggle/working/tokenized_{dir}\"),\n        midi_valid,\n    \n    )","metadata":{"id":"uB8MAhdvHGEB","outputId":"abe3f495-a771-4778-ef51-2ce450d5efd6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save the tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer.save(\"/kaggle/working/tokenizer.json\")","metadata":{"id":"bZzHxEPeOrnU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Utility function to read a JSON tokenized file","metadata":{"id":"_txg7WlqOoXf"}},{"cell_type":"code","source":"def read_json(path: str) -> dict:\n\n  with open(path, \"r\") as f:\n\n    return json.load(f)\n\ndef read_json_files(json_file_paths):\n    \"\"\"Reads a list of JSON files and returns a list of objects.\n    Args:\n        json_file_paths: A list of file paths to JSON files.\n    Returns:\n        A list of objects, where each object represents the data from a JSON file.\n        Returns an empty list if any error occurs during file processing.\n    \"\"\"\n\n    objects = []\n\n    for file_path in tqdm(json_file_paths):\n\n        try:\n\n            objects.append(read_json(file_path))\n\n        except FileNotFoundError:\n\n            print(f\"Error: File not found - {file_path}\")\n\n            return [] # Return empty list on error\n\n        except json.JSONDecodeError:\n\n            print(f\"Error decoding JSON in file: {file_path}\")\n\n            return [] # Return empty list on error\n\n    return objects\n","metadata":{"id":"bZzHxEPeOrnU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Read the tokenized version of files from the JSON","metadata":{"id":"ceLrlILzQg7v"}},{"cell_type":"code","source":"tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\ndata_objects_train = read_json_files(tokenized_train)\n\ntokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\ndata_objects_valid = read_json_files(tokenized_valid)\n\ntokenized_test = list(Path(\"tokenized_test\").resolve().glob(\"**/*.json\"))\ndata_objects_test = read_json_files(tokenized_test)\n\n\nif data_objects_train:\n    print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\nelse:\n    print(\"Error reading JSON files.\")","metadata":{"id":"iR0bPrk-H1O1","outputId":"a2ad76f1-ff8e-4a77-903d-a159a8723800","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create the list of tokenized songs, taking the IDs of each one","metadata":{"id":"P9nbkZgfQllX"}},{"cell_type":"code","source":"encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\nencoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\nencoded_test = [np.array(song[\"ids\"][0]) for song in data_objects_test]","metadata":{"id":"_B81lpcTKL6m","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"End of pre-processing, proceding with data and model preparation with Tensorflow\n\n\n\n---\n\n\n","metadata":{"id":"VmJjxVpaQr13"}},{"cell_type":"markdown","source":"# Tensorflow data and model setup","metadata":{"id":"MFobYqPQQ2mL"}},{"cell_type":"markdown","source":"## Creating a Tensorflow dataset with all IDs","metadata":{"id":"PZYhXakurnaB"}},{"cell_type":"code","source":"all_ids_train = np.concatenate(encoded_train)\nall_ids_valid = np.concatenate(encoded_valid)\nall_ids_test = np.concatenate(encoded_test)\n","metadata":{"id":"0yIWzFmmowXC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(all_ids_valid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save numpy arrays","metadata":{}},{"cell_type":"code","source":"np.savetxt('ids_train', all_ids_train, delimiter=',')\nnp.savetxt('ids_valid', all_ids_valid, delimiter=',')\nnp.savetxt('ids_test', all_ids_test, delimiter=',')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load numpy arrays","metadata":{}},{"cell_type":"code","source":"!gdown 1mYPtsOMIKj0WO_oAYswZSycfKNoQNvzZ\n!gdown 1FXyv6ONlswDqc34SRPAgo5smpCPL3R-N\n!gdown 1iNhcdDBduwUCS8YZZXdVtB9zjlqgyWgP","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_ids_train = np.loadtxt(\"ids_train\", dtype=np.int32)\nall_ids_valid = np.loadtxt(\"ids_valid\", dtype=np.int32)\nall_ids_test = np.loadtxt(\"ids_test\", dtype=np.int32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### (recommended): limit arrays","metadata":{}},{"cell_type":"code","source":"all_ids_train = all_ids_train[:int(0.75 * len(all_ids_train))]\nall_ids_valid = all_ids_valid[:int(0.75 * len(all_ids_valid))]\nall_ids_test = all_ids_test[:int(0.75 * len(all_ids_test))]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create Tensorflow datasets","metadata":{}},{"cell_type":"code","source":"ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\nids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)\nids_dataset_test = tf.data.Dataset.from_tensor_slices(all_ids_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Convert into sequences","metadata":{"id":"gKA8lKB5srKw"}},{"cell_type":"code","source":"seq_length = 1024 \n\nsequences_train = ids_dataset_train.batch(seq_length+1, drop_remainder=True)\nsequences_valid = ids_dataset_valid.batch(seq_length+1, drop_remainder=True)\nsequences_test = ids_dataset_test.batch(seq_length+1, drop_remainder=True)","metadata":{"id":"X33uqO3KrWNA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparing labels","metadata":{"id":"ZnJUygt7uUFi"}},{"cell_type":"code","source":"def split_input_target(sequence):\n    # Convert to float32\n    input_seq = tf.cast(sequence[:-1], tf.int32)\n    target_seq = tf.cast(sequence[1:], tf.int32)\n    return input_seq, target_seq\n\n\n\ntrain_ds = sequences_train.map(split_input_target)\nvalid_ds = sequences_valid.map(split_input_target)\ntest_ds = sequences_test.map(split_input_target)","metadata":{"id":"Xlsk46y3sVRS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating training batches","metadata":{"id":"o6Ssr4f_um6f"}},{"cell_type":"code","source":"# Batch size\n\nBATCH_SIZE = 16 \n\n# Buffer size to shuffle the dataset\n# (TF data is designed to work with possibly infinite sequences,\n# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n# it maintains a buffer in which it shuffles elements).\n\nBUFFER_SIZE = 10000\n\n\n\ntrain_ds = (\n    train_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))\nvalid_ds = (\n    valid_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))\ntest_ds = (\n    test_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))","metadata":{"id":"G1nUYxujuorC","outputId":"a5d2411c-75dc-4328-c4ce-a7dd98512bd9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Building the model","metadata":{"id":"13TNnkIRuwKa"}},{"cell_type":"code","source":"from transformers import TFAutoModelForCausalLM, MistralConfig\n\n# Define the model configuration\nmodel_config = MistralConfig(\n    vocab_size=len(tokenizer),\n    hidden_size=512,\n    intermediate_size=1024,\n    num_hidden_layers=8,\n    num_attention_heads=8,\n    num_key_value_heads=4,\n    sliding_window=256,\n    max_position_embeddings=8192,\n    pad_token_id=tokenizer['PAD_None'],\n    bos_token_id=tokenizer['BOS_None'],\n    eos_token_id=tokenizer['EOS_None'],\n)\n\n# Initialize the TensorFlow model\nmodel = TFAutoModelForCausalLM.from_config(model_config)\nloss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(loss=loss,\n              optimizer=\"adam\",\n              weighted_metrics=[\"sparse_categorical_accuracy\"],\n              jit_compile=True,\n              )","metadata":{"id":"G1nUYxujuorC","outputId":"a5d2411c-75dc-4328-c4ce-a7dd98512bd9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check if model is doing what expected","metadata":{}},{"cell_type":"code","source":"for input_example_batch, target_example_batch in train_ds.take(1):\n\n  example_batch_predictions = model(input_example_batch)\n  logits = example_batch_predictions.logits\n  print(logits.shape, \"# (batch_size, sequence_length, vocab_size)\")\n\n\n\n# Check shapes\nprint(\"Prediction shape:\", logits.shape)\nprint(\"Target shape:\", target_example_batch.shape)\n\n# Ensure reduction is feasible\npredicted_classes = tf.argmax(logits, axis=-1)  # (batch_size, seq_length)\nprint(\"Reduced prediction shape:\", predicted_classes.shape)\n\n# Compare shapes after reduction\nif predicted_classes.shape == target_example_batch.shape:\n    print(\"Shapes are compatible for comparison.\")\nelse:\n    print(\"Shapes are NOT compatible for comparison.\")\n\n# Verify dtype compatibility\nprint(\"Prediction dtype:\", logits.dtype)\nprint(\"Target dtype:\", target_example_batch.dtype)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Directory where the checkpoints will be saved\n\ncheckpoint_dir = './training_checkpoints'\n\n# Name of the checkpoint files\n\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n\nearly_stopping = EarlyStopping(\n\n    monitor='val_loss',\n\n    patience=5,\n\n    restore_best_weights=True\n\n)\n\n\n\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n\n    filepath=checkpoint_prefix,\n\n    save_weights_only=True\n\n)","metadata":{"id":"vIfM0aScNI0p","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 15\n\nhistory = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=valid_ds,\n    #callbacks=[early_stopping]\n)","metadata":{"id":"Tpzre8kENI0p","outputId":"7bb0c20d-da42-46d3-f24c-749b806f59a8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/nesgen-automodel\") \n!zip -r nesgen-automodel.zip /kaggle/working/nesgen-automodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load previous trained model","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n!gdown 1kZe0BCf7EWyp7HEXyRtP-D37AsnLjT2Y\n!unzip nesgen-automodel.zip\n\nmodel.from_pretrained(\"/kaggle/working/kaggle/working/nesgen-automodel\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save the history","metadata":{}},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/working/trainHistoryDict', 'wb') as file_pi:\n    pickle.dump(history.history, file_pi)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the history","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/working/trainHistoryDict', \"rb\") as file_pi:\n    history = pickle.load(file_pi)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generation","metadata":{"id":"Q2cEIaBKg55B"}},{"cell_type":"markdown","source":"### Select a seed from the test set","metadata":{}},{"cell_type":"code","source":"def get_seed():\n    for seed_ids, _ in test_ds.take(1):\n    \n      seed = seed_ids\n    \n    return seed[0]","metadata":{"id":"zqVJaweJg7Py","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generate and dump MIDI","metadata":{}},{"cell_type":"code","source":"dump_seed = False\n\nseed = get_seed()\ninput_ids = tf.convert_to_tensor(seed)  # Assuming seed is a 1D tensor of token IDs\ninput_ids = tf.expand_dims(input_ids, 0)  # Add an extra dimension to represent batch size\n\nif dump_seed:\n    midi = tokenizer.decode([seed])\n    midi.dump_midi(\"seed.mid\")\n\n# Generate continuation\noutputs = model.generate(\n    input_ids=input_ids,\n    max_new_tokens=256,  # Maximum length of generated sequence\n    num_return_sequences=1,  # Number of sequences to return\n    do_sample=True,  # Use sampling (True) or greedy decoding (False)\n    temperature=0.7  # Sampling temperature (lower is more conservative)\n)\n\ninput_length = input_ids.shape[1]\ngenerated_tokens = outputs[:, input_length:] # skip seed\n\n# Decode and print the generated text\ngenerated = tokenizer.decode([generated_tokens[0]])\ngenerated.dump_midi(\"nesgen2.mid\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Second part: Fine tuning","metadata":{}},{"cell_type":"code","source":"# Paths to the files of the dataset\n\nnesmdb_paths = list(Path(\"/kaggle/working/nesmdb_midi\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/nesmdb_midi\").resolve().glob(\"**/*.midi\"))\n\nnesmdb_dir = \"nesmdb\"\nos.makedirs(nesmdb_dir, exist_ok=True)\n\nfor i, midi_path in enumerate(nesmdb_paths):\n  new_midi_path = os.path.join(nesmdb_dir, f\"{i}.midi\")\n  shutil.move(str(midi_path), new_midi_path)\n\nnes_midis = list(Path(\"/kaggle/working/nesmdb\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/nesmdb\").resolve().glob(\"**/*.midi\"))","metadata":{"id":"a6elj9pecSnQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processed = [Path(f\"{s}\") for s in nes_midis]\nprint(len(processed))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Print info of a MIDI","metadata":{}},{"cell_type":"code","source":"from utility import show_midi_info, playMidi\n\nshow_midi_info(str(processed[0]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_num_files = len(processed)\n\nnum_files_valid = round(total_num_files * 0.15)\nnum_files_test = round(total_num_files * 0.15)\nshuffle(processed)\nmidi_paths_valid = processed[:num_files_valid]\nmidi_paths_test = processed[num_files_valid:num_files_valid + num_files_test]\nmidi_paths_train = processed[num_files_valid + num_files_test:]\n\n\n\n# Chunk MIDIs and perform data augmentation on each subset independently\n\nfor files_paths, subset_name in (\n\n    (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\"), (midi_paths_test, \"test\")\n\n):\n    print(files_paths[0])\n\n    # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n\n    subset_chunks_dir = Path(f\"Nesmdb_{subset_name}\")\n\n    split_files_for_training(\n\n        files_paths=files_paths,\n\n        tokenizer=tokenizer,\n\n        save_dir=subset_chunks_dir,\n\n        max_seq_len=1024,\n\n        num_overlap_bars=2,\n\n    )\n\n\n\n    # Perform data augmentation\n\n    augment_dataset(\n\n        subset_chunks_dir,\n\n        pitch_offsets=[-12, 12],\n\n        velocity_offsets=[-4, 4],\n\n        duration_offsets=[-0.5, 0.5],\n\n    )\nmidi_paths_train = list(Path(\"Nesmdb_train\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_train\").glob(\"**/*.midi\"))\nmidi_paths_valid = list(Path(\"Nesmdb_valid\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_valid\").glob(\"**/*.midi\"))\nmidi_paths_test = list(Path(\"Nesmdb_test\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_test\").glob(\"**/*.midi\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenize the augmented NESMDB dataset into JSON files","metadata":{}},{"cell_type":"code","source":"def midi_valid(midi) -> bool:\n\n    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n\n        return False  # time signature different from 4/*, 4 beats per bar\n\n    return True\n\n\n\nif os.path.exists(\"tokenized_train\"):\n  shutil.rmtree(\"tokenized_train\")\nif os.path.exists(\"tokenized_valid\"):\n  shutil.rmtree(\"tokenized_valid\")\nif os.path.exists(\"tokenized_test\"):\n  shutil.rmtree(\"tokenized_test\")\n\n\nfor dir in (\"train\", \"valid\", \"test\"):\n    tokenizer.tokenize_dataset(        \n        Path(f\"/kaggle/working/Nesmdb_{dir}\"),\n        Path(f\"/kaggle/working/tokenized_{dir}\"),\n        midi_valid,\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Read the tokenized versions from JSON files","metadata":{}},{"cell_type":"code","source":"tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\ndata_objects_train = read_json_files(tokenized_train)\n\ntokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\ndata_objects_valid = read_json_files(tokenized_valid)\n\ntokenized_test = list(Path(\"tokenized_test\").resolve().glob(\"**/*.json\"))\ndata_objects_test = read_json_files(tokenized_test)\n\n\nif data_objects_train:\n    print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\nelse:\n    print(\"Error reading JSON files.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\nencoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\nencoded_test = [np.array(song[\"ids\"][0]) for song in data_objects_test]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_ids_train = np.concatenate(encoded_train)\nall_ids_valid = np.concatenate(encoded_valid)\nall_ids_test = np.concatenate(encoded_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save numpy arrays","metadata":{}},{"cell_type":"code","source":"np.savetxt('ids_train.txt', all_ids_train, delimiter=',')\nnp.savetxt('ids_valid.txt', all_ids_valid, delimiter=',')\nnp.savetxt('ids_test.txt', all_ids_test, delimiter=',')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load numpy arrays","metadata":{}},{"cell_type":"code","source":"# Download the files\n!gdown 1RRuql2uT_HFZSX9gau3ffHU3DFGxlpCw # train\n!gdown 1itYNImS7mdXm-If8818I9N2HR-PMUksL # valid\n!gdown 1H_rnDT8YCn-yRVQWXJdMd7SoREJFoXBt # test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_ids_train = np.loadtxt(\"ids_train.txt\", dtype=np.int32)\nall_ids_valid = np.loadtxt(\"ids_valid.txt\", dtype=np.int32)\nall_ids_test = np.loadtxt(\"ids_test.txt\", dtype=np.int32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(all_ids_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create Tensorflow datasets","metadata":{}},{"cell_type":"code","source":"ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\nids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)\nids_dataset_test = tf.data.Dataset.from_tensor_slices(all_ids_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Convert into sequences","metadata":{"id":"gKA8lKB5srKw"}},{"cell_type":"code","source":"seq_length = 1024 \n\nsequences_train = ids_dataset_train.batch(seq_length+1, drop_remainder=True)\nsequences_valid = ids_dataset_valid.batch(seq_length+1, drop_remainder=True)\nsequences_test = ids_dataset_test.batch(seq_length+1, drop_remainder=True)","metadata":{"id":"X33uqO3KrWNA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparing labels","metadata":{"id":"ZnJUygt7uUFi"}},{"cell_type":"code","source":"def split_input_target(sequence):\n    # Convert to float32\n    input_seq = tf.cast(sequence[:-1], tf.int32)\n    target_seq = tf.cast(sequence[1:], tf.int32)\n    return input_seq, target_seq\n\n\n\ntrain_ds = sequences_train.map(split_input_target)\nvalid_ds = sequences_valid.map(split_input_target)\ntest_ds = sequences_test.map(split_input_target)","metadata":{"id":"Xlsk46y3sVRS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating training batches","metadata":{"id":"o6Ssr4f_um6f"}},{"cell_type":"code","source":"# Batch size\n\nBATCH_SIZE = 16 \n\n# Buffer size to shuffle the dataset\n# (TF data is designed to work with possibly infinite sequences,\n# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n# it maintains a buffer in which it shuffles elements).\n\nBUFFER_SIZE = 10000\n\n\n\ntrain_ds = (\n    train_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))\nvalid_ds = (\n    valid_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))\ntest_ds = (\n    test_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(tf.data.experimental.AUTOTUNE))","metadata":{"id":"G1nUYxujuorC","outputId":"a5d2411c-75dc-4328-c4ce-a7dd98512bd9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get the model","metadata":{}},{"cell_type":"code","source":"!gdown 1jJnzLC66vhuraBmf7FaysPUC4tuvq9jR\n\n!unzip nesgen-automodel.zip\n!mv kaggle/working/nesgen-automodel nesgen-automodel\n!rm -rf kaggle\n!rm -rf nesgen-automodel.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the pretrained model","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModelForCausalLM\nmodel = TFAutoModelForCausalLM.from_pretrained(\"./nesgen-automodel\")\n\nloss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(loss=loss,\n              optimizer=\"adam\",\n              weighted_metrics=[\"sparse_categorical_accuracy\"],\n              jit_compile=True,\n              )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 5\n\nhistory = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=valid_ds,\n)","metadata":{"id":"Tpzre8kENI0p","outputId":"7bb0c20d-da42-46d3-f24c-749b806f59a8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"nesgen_v1\") \n!zip -r nesgen-automodel.zip nesgen-automodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}