{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xpqjf8fLFTeg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get a smaller version of the Lakh MIDI Dataset v0.1\n",
        "%%capture\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz\n",
        "!tar xvf clean_midi.tar.gz\n",
        "!rm clean_midi.tar.gz\n",
        "\n",
        "dataset_path = \"/content/clean_midi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBe7RC5BFnGd",
        "outputId": "83407868-2cbf-455b-fe9b-6186a782e21b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/5.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m5.3/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (24.1)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=1df42fc2af8f0be5c59fe1c1938c7511219c97ef044221fcbffc322d953d168b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Paths to the files of the dataset\n",
        "midi_paths = list(Path(\"clean_midi\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "Xgzc6NC0FqwB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning of files"
      ],
      "metadata": {
        "id": "mLqOtcjf-r5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.mid\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "KznPqQQe-rC2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI2Tokens"
      ],
      "metadata": {
        "id": "ofcPhnyn9GSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pretty_midi\n",
        "\n",
        "class midi_to_tokens():\n",
        "    def __init__(self, path, steps_per_beat=12):\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        try:\n",
        "          self.pm = pretty_midi.PrettyMIDI(path)\n",
        "        except OSError as e:\n",
        "          print(f\"Error reading MIDI file: {e}\")\n",
        "          return\n",
        "        self.dbs = self.pm.get_downbeats().tolist() + [self.pm.get_end_time()] # dbs := downbeats\n",
        "        self.tokens = self._tokenize()\n",
        "\n",
        "    def __call__(self):\n",
        "        return ' '.join(self.tokens)\n",
        "\n",
        "    def _time_to_step(self, time):\n",
        "        return round(self.pm.time_to_tick(time) / self.pm.resolution * self.steps_per_beat)\n",
        "\n",
        "    def _event_to_tokens(self, event):\n",
        "        if event in ('bar', 'beat'):\n",
        "            return [event]\n",
        "        elif isinstance(event, pretty_midi.containers.Note):\n",
        "            return [f'note_{event.pitch}', f'len_{self._time_to_step(event.end) - self._time_to_step(event.start)}']\n",
        "\n",
        "    def _trim_note(self, note, start, end):\n",
        "        n = copy.copy(note)\n",
        "        n.start, n.end = max(n.start, start), min(n.end, end)\n",
        "        return n\n",
        "\n",
        "    def _tokenize(self, start_measure=1, end_measure=None):\n",
        "        start, end = self.dbs[start_measure - 1], self.dbs[end_measure or -1]\n",
        "\n",
        "        notes = []\n",
        "        for inst in self.pm.instruments:\n",
        "            notes += inst.notes\n",
        "        notes.sort(key=lambda x: (x.start, -x.pitch))\n",
        "\n",
        "        events = []\n",
        "        events += [(self._time_to_step(db), 'bar') for db in self.dbs if start <= db < end]\n",
        "        events += [(self._time_to_step(b), 'beat') for b in set(self.pm.get_beats()) - set(self.dbs) if start <= b < end] # beats without downbeats\n",
        "        events += [(self._time_to_step(max(n.start, start)), self._trim_note(n, start, end)) for n in notes if start <= n.start < end or start < n.end <= end]\n",
        "        events.sort(key=lambda x: x[0])\n",
        "\n",
        "        tokens = []\n",
        "        last_beat = 0\n",
        "        for step, event in events:\n",
        "            if event in ('bar', 'beat'):\n",
        "                last_beat = step\n",
        "            if step - last_beat:\n",
        "                tokens.append(f'pos_{step - last_beat}')\n",
        "            tokens += self._event_to_tokens(event)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def measures(self, start_measure=1, end_measure=None):\n",
        "        return self._tokenize(start_measure, end_measure)"
      ],
      "metadata": {
        "id": "CrSlr4mxAWlU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokens2MIDI"
      ],
      "metadata": {
        "id": "kjvAidVeGXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokensToMidi:\n",
        "    def __init__(self, tokens, steps_per_beat=12, ticks_per_beat=960, tempo=120):\n",
        "        self.tokens = tokens\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.ticks_per_step = ticks_per_beat // steps_per_beat\n",
        "        self.tempo = tempo\n",
        "        self.ticks_per_beat = ticks_per_beat\n",
        "\n",
        "    def _ticks_to_time(self, ticks):\n",
        "        return ticks * 60 / (self.tempo * self.ticks_per_beat)\n",
        "\n",
        "    def generate_midi(self, path):\n",
        "        pm = pretty_midi.PrettyMIDI(initial_tempo=self.tempo)\n",
        "        instrument = pretty_midi.Instrument(program=38)\n",
        "\n",
        "        time = 0\n",
        "        last_beat = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(self.tokens):\n",
        "            token = self.tokens[i]\n",
        "\n",
        "            if token == \"bar\":\n",
        "                time += self._ticks_to_time(self.ticks_per_step * self.steps_per_beat)\n",
        "                last_beat = time\n",
        "            elif token == \"beat\":\n",
        "                time = last_beat\n",
        "                last_beat = time\n",
        "            elif token.startswith(\"pos_\"):\n",
        "                position = int(token.split(\"_\")[1])\n",
        "                time = last_beat + self._ticks_to_time(self.ticks_per_step * position)\n",
        "            elif token.startswith(\"note_\"):\n",
        "                pitch = int(token.split(\"_\")[1])\n",
        "                length_token = self.tokens[i + 1]\n",
        "                length = int(length_token.split(\"_\")[1])\n",
        "                duration = self._ticks_to_time(self.ticks_per_step * length)\n",
        "\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch,\n",
        "                    start=time,\n",
        "                    end=time + duration\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "                i += 1\n",
        "            i += 1\n",
        "\n",
        "        pm.instruments.append(instrument)\n",
        "        pm.write(path)\n",
        "        return pm"
      ],
      "metadata": {
        "id": "oDUS-wjOGWtg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a utility class \"Tokenizer\""
      ],
      "metadata": {
        "id": "z-jNjy70AgvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self):\n",
        "        self._encoder = LabelEncoder()\n",
        "        self.PAD_id = 0\n",
        "        self.BOS_id = 1\n",
        "        self.EOS_id = 2\n",
        "\n",
        "    def _tokenize(self, midi_paths):\n",
        "      \"\"\"\n",
        "      midi_paths: list of paths to MIDI files\n",
        "      returns: list of lists of string tokens\n",
        "      \"\"\"\n",
        "      tokens = []\n",
        "      for path in midi_paths:\n",
        "        try:\n",
        "          toAdd = midi_to_tokens(str(path), steps_per_beat=12).tokens\n",
        "          toAdd.insert(0, \"Start\")\n",
        "          toAdd.append(\"End\")\n",
        "          tokens.append(toAdd)\n",
        "        except AttributeError:\n",
        "          print(f\"Error reading MIDI file: {path}\")\n",
        "          continue\n",
        "      return tokens\n",
        "\n",
        "    def fit_and_encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      flattened_array = np.concatenate([np.array(sublist).flatten() for sublist in tokens])\n",
        "      self._encoder.fit(flattened_array)\n",
        "      transformed = [self._encoder.transform(i) for i in tokens]\n",
        "      self.EOS_id = self._encoder.transform([\"End\"])[0]\n",
        "      self.BOS_id = self._encoder.transform([\"Start\"])[0]\n",
        "      self.PAD_id = self._encoder.classes_.shape[0]\n",
        "      self._encoder.classes_ = np.append(self._encoder.classes_, [\"Pad\"])\n",
        "      return transformed\n",
        "\n",
        "    def encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      return [self._encoder.transform(i) for i in tokens]\n",
        "\n",
        "    def decode(self, encoded_tokens, path=\"reconstructed_midi.mid\"):\n",
        "      string_tokens = [self._encoder.inverse_transform(i) for i in encoded_tokens]\n",
        "      midi_reconstructor = TokensToMidi(string_tokens)\n",
        "      midi_reconstructor.generate_midi(path)\n",
        "\n",
        "    def pad(self, encoded_tokens):\n",
        "      self._seq_length = max(len(arr) for arr in encoded_tokens)\n",
        "      return np.array([np.pad(arr, (self._seq_length - len(arr), 0), mode='constant', constant_values=self.PAD_id) for arr in encoded_tokens])\n",
        "\n",
        "    @property\n",
        "    def encoder(self):\n",
        "      return self._encoder\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "      return self._encoder.classes_.shape[0]\n",
        "\n",
        "    @property\n",
        "    def seq_length(self):\n",
        "      return self._seq_length\n",
        "\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "      return self.PAD_id\n",
        "\n",
        "    @property\n",
        "    def bos_id(self):\n",
        "      return self.BOS_id\n",
        "\n",
        "    @property\n",
        "    def eos_id(self):\n",
        "      return self.EOS_id\n",
        ""
      ],
      "metadata": {
        "id": "utD8X3r1AgaG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the tokenizer"
      ],
      "metadata": {
        "id": "uITXgRsfHn4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer()\n",
        "encoded_tokens = tok.fit_and_encode(midis[:100])\n",
        "\n",
        "print(f\"PAD_id is {tok.pad_id}\")\n",
        "print(f\"BOS_id is {tok.bos_id}\")\n",
        "print(f\"EOS_id is {tok.eos_id}\")\n",
        "print(f\"Vocab size is {tok.vocab_size}\")"
      ],
      "metadata": {
        "id": "ZOxAY9VTHp56",
        "outputId": "48addaf0-c5ad-4d4f-94ef-3b1642c22475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading MIDI file: running status without last_status\n",
            "Error reading MIDI file: /content/midis/16907.mid\n",
            "Error reading MIDI file: data byte must be in range 0..127\n",
            "Error reading MIDI file: /content/midis/2651.mid\n",
            "PAD_id is 423\n",
            "BOS_id is 1\n",
            "EOS_id is 0\n",
            "Vocab size is 424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "KjDSHc2lIxwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = tok.pad(encoded_tokens)"
      ],
      "metadata": {
        "id": "8m4dFeH1Iy5D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SXi2gS2yKCvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "WGzHWz_cKAAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `keras_nlp`\n",
        "%%capture\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "pV0DmhYNFzpQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp.layers as nlp_layers\n",
        "\n",
        "def create_transformer(vocab_size, seq_len, embedding_dim, num_heads, dff, num_layers):\n",
        "  # Input\n",
        "    inputs = tf.keras.Input(shape=(seq_len,))\n",
        "\n",
        "    # Embedding\n",
        "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    # Encoder\n",
        "    encoder = nlp_layers.TransformerEncoder(num_heads=num_heads, intermediate_dim=dff)(embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = nlp_layers.TransformerDecoder(num_heads=num_heads, intermediate_dim=dff)(embedding, encoder)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "    # Crea il modello\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "RrZV_yNRF2k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tok.vocab_size\n",
        "seq_len = tok.seq_length\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model, encoder, decoder = create_transformer(vocab_size=vocab_size,\n",
        "                                             seq_len=seq_len,\n",
        "                                             embedding_dim=256,\n",
        "                                             num_heads=8,\n",
        "                                             dff=1024,\n",
        "                                             num_layers=6)"
      ],
      "metadata": {
        "id": "v90igmqzAczd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_x = padded_tokens[:70]\n",
        "normalized_val_x = padded_tokens[70:]\n",
        "\n",
        "normalized_train_y = np.roll(normalized_train_x, shift=-1, axis=1)\n",
        "normalized_val_y = np.roll(normalized_val_x, shift=-1, axis=1)\n"
      ],
      "metadata": {
        "id": "I69Mb-I0Bga0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(normalized_train_x, normalized_train_y,\n",
        "          epochs=5,\n",
        "          validation_data=(normalized_val_x, normalized_val_y),\n",
        "          callbacks=[early_stopping],\n",
        "          batch_size=32\n",
        "          )\n",
        "\n",
        "model.save(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "MvoCcmHKBR68",
        "outputId": "771ef33d-46c3-4806-abde-63b1ec9f08ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-29-8a84f8330f17>\", line 6, in <cell line: 6>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 1198919140352 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_9343]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8a84f8330f17>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model.fit(normalized_train_x, normalized_train_y,\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_val_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_val_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-29-8a84f8330f17>\", line 6, in <cell line: 6>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 1198919140352 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_9343]"
          ]
        }
      ]
    }
  ]
}