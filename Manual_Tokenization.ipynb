{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpqjf8fLFTeg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get a smaller version of the Lakh MIDI Dataset v0.1\n",
        "%%capture\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz\n",
        "!tar xvf clean_midi.tar.gz\n",
        "!rm clean_midi.tar.gz\n",
        "\n",
        "dataset_path = \"/content/clean_midi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pretty_midi"
      ],
      "metadata": {
        "id": "IBe7RC5BFnGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Paths to the files of the dataset\n",
        "midi_paths = list(Path(\"clean_midi\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "Xgzc6NC0FqwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning of files"
      ],
      "metadata": {
        "id": "mLqOtcjf-r5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.mid\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "KznPqQQe-rC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI2Tokens"
      ],
      "metadata": {
        "id": "ofcPhnyn9GSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pretty_midi\n",
        "\n",
        "class midi_to_tokens():\n",
        "    def __init__(self, path, steps_per_beat=12, limit=None):\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        try:\n",
        "          self.pm = pretty_midi.PrettyMIDI(path)\n",
        "        except OSError as e:\n",
        "          print(f\"Error reading MIDI file: {e}\")\n",
        "          return\n",
        "        self.dbs = self.pm.get_downbeats().tolist() + [self.pm.get_end_time()] # dbs := downbeats\n",
        "        self.tokens_seqs = self._tokenize(limit=limit)\n",
        "\n",
        "    def __call__(self):\n",
        "        return ' '.join(self.tokens)\n",
        "\n",
        "    def _time_to_step(self, time):\n",
        "        return round(self.pm.time_to_tick(time) / self.pm.resolution * self.steps_per_beat)\n",
        "\n",
        "    def _event_to_tokens(self, event):\n",
        "        if event in ('bar', 'beat'):\n",
        "            return [event]\n",
        "        elif isinstance(event, pretty_midi.containers.Note):\n",
        "            return [f'note_{event.pitch}', f'len_{self._time_to_step(event.end) - self._time_to_step(event.start)}']\n",
        "\n",
        "    def _trim_note(self, note, start, end):\n",
        "        n = copy.copy(note)\n",
        "        n.start, n.end = max(n.start, start), min(n.end, end)\n",
        "        return n\n",
        "\n",
        "    def _tokenize(self, start_measure=1, end_measure=None, limit=None):\n",
        "        start, end = self.dbs[start_measure - 1], self.dbs[end_measure or -1]\n",
        "\n",
        "        notes = []\n",
        "        for inst in self.pm.instruments:\n",
        "            notes += inst.notes\n",
        "        notes.sort(key=lambda x: (x.start, -x.pitch))\n",
        "\n",
        "        events = []\n",
        "        events += [(self._time_to_step(db), 'bar') for db in self.dbs if start <= db < end]\n",
        "        events += [(self._time_to_step(b), 'beat') for b in set(self.pm.get_beats()) - set(self.dbs) if start <= b < end] # beats without downbeats\n",
        "        events += [(self._time_to_step(max(n.start, start)), self._trim_note(n, start, end)) for n in notes if start <= n.start < end or start < n.end <= end]\n",
        "        events.sort(key=lambda x: x[0])\n",
        "\n",
        "        tokens_sequences = []\n",
        "        last_beat = 0\n",
        "        if limit is not None:\n",
        "          event_chunks = [events[i:i + limit] for i in range(0, len(events), limit)]\n",
        "        else:\n",
        "          event_chunks = [events]\n",
        "\n",
        "        for chunk in event_chunks:\n",
        "            tokens = []\n",
        "            try:\n",
        "                for step, event in chunk:\n",
        "                    if event in ('bar', 'beat'):\n",
        "                        last_beat = step\n",
        "                    if step - last_beat:\n",
        "                        tokens.append(f'pos_{step - last_beat}')\n",
        "                    tokens += self._event_to_tokens(event)\n",
        "                tokens_sequences.append(tokens)\n",
        "            except Exception as e:\n",
        "                print(f\"Error while translating events to tokens: {e}\")\n",
        "\n",
        "        return tokens_sequences\n",
        "\n",
        "    def measures(self, start_measure=1, end_measure=None):\n",
        "        return self._tokenize(start_measure, end_measure)"
      ],
      "metadata": {
        "id": "CrSlr4mxAWlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokens2MIDI"
      ],
      "metadata": {
        "id": "kjvAidVeGXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokensToMidi:\n",
        "    def __init__(self, tokens, steps_per_beat=12, ticks_per_beat=960, tempo=120):\n",
        "        self.tokens = tokens\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.ticks_per_step = ticks_per_beat // steps_per_beat\n",
        "        self.tempo = tempo\n",
        "        self.ticks_per_beat = ticks_per_beat\n",
        "\n",
        "    def _ticks_to_time(self, ticks):\n",
        "        return ticks * 60 / (self.tempo * self.ticks_per_beat)\n",
        "\n",
        "    def generate_midi(self, path):\n",
        "        pm = pretty_midi.PrettyMIDI(initial_tempo=self.tempo)\n",
        "        instrument = pretty_midi.Instrument(program=38)\n",
        "\n",
        "        time = 0\n",
        "        last_beat = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(self.tokens):\n",
        "            token = self.tokens[i]\n",
        "\n",
        "            if token == \"bar\":\n",
        "                time += self._ticks_to_time(self.ticks_per_step * self.steps_per_beat)\n",
        "                last_beat = time\n",
        "            elif token == \"beat\":\n",
        "                time = last_beat\n",
        "                last_beat = time\n",
        "            elif token.startswith(\"pos_\"):\n",
        "                position = int(token.split(\"_\")[1])\n",
        "                time = last_beat + self._ticks_to_time(self.ticks_per_step * position)\n",
        "            elif token.startswith(\"note_\"):\n",
        "                pitch = int(token.split(\"_\")[1])\n",
        "                try:\n",
        "                  length_token = self.tokens[i + 1]\n",
        "                  length = int(length_token.split(\"_\")[1])\n",
        "                except IndexError:\n",
        "                  length = 1\n",
        "                duration = self._ticks_to_time(self.ticks_per_step * length)\n",
        "\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch,\n",
        "                    start=time,\n",
        "                    end=time + duration\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "                i += 1\n",
        "            i += 1\n",
        "\n",
        "        pm.instruments.append(instrument)\n",
        "        pm.write(path)\n",
        "        return pm"
      ],
      "metadata": {
        "id": "oDUS-wjOGWtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a utility class \"Tokenizer\""
      ],
      "metadata": {
        "id": "z-jNjy70AgvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self, limit=None):\n",
        "        self._encoder = LabelEncoder()\n",
        "        self.PAD_id = 0\n",
        "        self.BOS_id = 1\n",
        "        self.EOS_id = 2\n",
        "        self.limit = limit\n",
        "\n",
        "    def _tokenize(self, midi_paths):\n",
        "      \"\"\"\n",
        "      midi_paths: list of paths to MIDI files\n",
        "      returns: list of lists of string tokens\n",
        "      \"\"\"\n",
        "      tokens = []\n",
        "      for path in tqdm(midi_paths):\n",
        "        try:\n",
        "          seqs = midi_to_tokens(str(path), steps_per_beat=12, limit=self.limit).tokens_seqs\n",
        "          for seq in seqs:\n",
        "            seq.insert(0, \"Start\")\n",
        "            seq.append(\"End\")\n",
        "            tokens.append(seq)\n",
        "        except AttributeError:\n",
        "          print(f\"Error reading MIDI file: {path}\")\n",
        "          continue\n",
        "        except Exception as e:\n",
        "          print(f\"There was an unexpected error: {e}\")\n",
        "          continue\n",
        "      return tokens\n",
        "\n",
        "    def fit_and_encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      flattened_array = np.concatenate([np.array(sublist).flatten() for sublist in tokens])\n",
        "      self._encoder.fit(flattened_array)\n",
        "      transformed = [self._encoder.transform(i) for i in tokens]\n",
        "      self.EOS_id = self._encoder.transform([\"End\"])[0]\n",
        "      self.BOS_id = self._encoder.transform([\"Start\"])[0]\n",
        "      self.PAD_id = self._encoder.classes_.shape[0]\n",
        "      self._encoder.classes_ = np.append(self._encoder.classes_, [\"Pad\"])\n",
        "      return transformed\n",
        "\n",
        "    def encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      return [self._encoder.transform(i) for i in tokens]\n",
        "\n",
        "    def decode(self, encoded_tokens, path=\"reconstructed_midi.mid\"):\n",
        "      string_tokens = [self._encoder.inverse_transform(i) for i in encoded_tokens]\n",
        "      for i in range(len(string_tokens)):\n",
        "        midi_reconstructor = TokensToMidi(string_tokens[i])\n",
        "        midi_reconstructor.generate_midi(str(i) + path)\n",
        "\n",
        "    def pad(self, encoded_tokens):\n",
        "      self._seq_length = max(len(arr) for arr in encoded_tokens)\n",
        "      return np.array([np.pad(arr, (self._seq_length - len(arr), 0), mode='constant', constant_values=self.PAD_id) for arr in encoded_tokens])\n",
        "\n",
        "    def save(self, path: str):\n",
        "      np.savetxt(path, self.encoder.classes_, fmt=\"%s\")\n",
        "\n",
        "    def load(self, path: str):\n",
        "      self._encoder.classes_ = np.loadtxt(path, dtype=\"str\")\n",
        "\n",
        "    @property\n",
        "    def encoder(self):\n",
        "      return self._encoder\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "      return self._encoder.classes_.shape[0]\n",
        "\n",
        "    @property\n",
        "    def seq_length(self):\n",
        "      return self._seq_length\n",
        "\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "      return self.PAD_id\n",
        "\n",
        "    @property\n",
        "    def bos_id(self):\n",
        "      return self.BOS_id\n",
        "\n",
        "    @property\n",
        "    def eos_id(self):\n",
        "      return self.EOS_id\n"
      ],
      "metadata": {
        "id": "utD8X3r1AgaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download trained Tokenizer and tokens"
      ],
      "metadata": {
        "id": "ZEHCnWHiCmqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1QrMzoYewqyxv2TJEgwS53-8l6rlpi4RG\n",
        "!gdown 1dwNkvRopC8gIpDzD2iEFZADe4aeF-w_F\n",
        "\n",
        "!mv tokens_lim1000_nFiles2500.txt tokens.txt\n",
        "!mv tokenizer_lim1000_nFiles2500.txt tokenizer.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b1cVVQ7CpmS",
        "outputId": "2df80404-f54f-4f14-f042-e22629295087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1trgZB8lrn9APQF3NWQCucAVbC-rLsyd1\n",
            "To: /content/tokenizer.txt\n",
            "100% 10.7k/10.7k [00:00<00:00, 31.1MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12zSaNlKv2twSeym7LS91pFCxmsKVVaes\n",
            "From (redirected): https://drive.google.com/uc?id=12zSaNlKv2twSeym7LS91pFCxmsKVVaes&confirm=t&uuid=8d2c6779-3236-495f-8925-75b44252a80c\n",
            "To: /content/tokens.txt\n",
            "100% 393M/393M [00:06<00:00, 59.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a previously fitted Tokenizer"
      ],
      "metadata": {
        "id": "FXJQ4eeyCETV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(limit=500)\n",
        "tok.load(\"tokenizer.txt\")"
      ],
      "metadata": {
        "id": "EDyLhCU5CKUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load already tokenized data..."
      ],
      "metadata": {
        "id": "EWrvEj48CQjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = np.loadtxt(\"tokens.txt\")\n",
        "print(f\"Loaded tokenized version of {padded_tokens.shape[0]} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "065RdJgOCThU",
        "outputId": "54d92575-aac3-47a8-98fd-b2de592117f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tokenized version of 58954 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ...or fit the tokenizer"
      ],
      "metadata": {
        "id": "uITXgRsfHn4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(limit=500)\n",
        "encoded_tokens = tok.fit_and_encode(midis[:100])\n",
        "\n",
        "print(f\"PAD_id is {tok.pad_id}\")\n",
        "print(f\"BOS_id is {tok.bos_id}\")\n",
        "print(f\"EOS_id is {tok.eos_id}\")\n",
        "print(f\"Vocab size is {tok.vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOxAY9VTHp56",
        "outputId": "43994544-6fba-4cef-cecf-4563bc7decdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading MIDI file: running status without last_status\n",
            "Error reading MIDI file: /content/midis/16907.mid\n",
            "Error reading MIDI file: data byte must be in range 0..127\n",
            "Error reading MIDI file: /content/midis/2651.mid\n",
            "PAD_id is 285\n",
            "BOS_id is 1\n",
            "EOS_id is 0\n",
            "Vocab size is 286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "KjDSHc2lIxwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = tok.pad(encoded_tokens)\n",
        "print(f\"Maximum sequence len is {tok.seq_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m4dFeH1Iy5D",
        "outputId": "99dd2847-a810-4f20-87a6-5f4bed343306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence len is 1412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SXi2gS2yKCvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "WGzHWz_cKAAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `keras_nlp`\n",
        "%%capture\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "pV0DmhYNFzpQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp.layers as nlp_layers\n",
        "\n",
        "def create_transformer(vocab_size, seq_len, embedding_dim, num_heads, dff, num_layers):\n",
        "  # Input\n",
        "    inputs = tf.keras.Input(shape=(seq_len,))\n",
        "\n",
        "    # Embedding\n",
        "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    # Encoder\n",
        "    encoder = nlp_layers.TransformerEncoder(num_heads=num_heads, intermediate_dim=dff)(embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = nlp_layers.TransformerDecoder(num_heads=num_heads, intermediate_dim=dff)(embedding, encoder)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "    # Crea il modello\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "RrZV_yNRF2k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tok.vocab_size\n",
        "seq_len = padded_tokens.shape[1]\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model, encoder, decoder = create_transformer(vocab_size=vocab_size,\n",
        "                                             seq_len=seq_len,\n",
        "                                             embedding_dim=256,\n",
        "                                             num_heads=8,\n",
        "                                             dff=1024,\n",
        "                                             num_layers=6)"
      ],
      "metadata": {
        "id": "v90igmqzAczd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_perc = 0.8\n",
        "train_size = int(train_perc * padded_tokens.shape[0])\n",
        "\n",
        "normalized_train_x = padded_tokens[:train_size]\n",
        "normalized_val_x = padded_tokens[train_size:]\n",
        "\n",
        "normalized_train_y = np.roll(normalized_train_x, shift=-1, axis=1)\n",
        "normalized_val_y = np.roll(normalized_val_x, shift=-1, axis=1)\n"
      ],
      "metadata": {
        "id": "I69Mb-I0Bga0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(normalized_train_x, normalized_train_y,\n",
        "          epochs=100,\n",
        "          validation_data=(normalized_val_x, normalized_val_y),\n",
        "          callbacks=[early_stopping],\n",
        "          batch_size=32\n",
        "          )\n",
        "\n",
        "model.save(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "MvoCcmHKBR68",
        "outputId": "6ba17e8a-99bd-4c85-dedf-bec23ff3424f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1474/1474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1511s\u001b[0m 1s/step - accuracy: 0.4578 - loss: 2.1846 - val_accuracy: 0.4906 - val_loss: 1.8453\n",
            "Epoch 2/100\n",
            "\u001b[1m1263/1474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:09\u001b[0m 897ms/step - accuracy: 0.4882 - loss: 1.8377"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jH3LNvLpMmVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "tL1VLQPHMnXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_random_ids_from_dataset(dataset):\n",
        "  return dataset[np.random.choice(dataset.shape[0])]\n",
        "\n",
        "def sample_next_token(probabilities) -> int:\n",
        "  # Ensure the probabilities sum to 1 (they should, but numerical issues might affect it)\n",
        "  last_token_probs = probabilities[0, -1]\n",
        "  last_token_probs /= last_token_probs.sum()\n",
        "  return np.random.choice(len(last_token_probs), p=last_token_probs)\n",
        "\n",
        "def next_token(model, seed_ids):\n",
        "    probabilities = model.predict(seed_ids, verbose=0)\n",
        "    next_token = sample_next_token(probabilities)\n",
        "    return next_token\n",
        "\n",
        "def generate_ids(model, seed_ids, eos_id, pad_id, bos_id, max_len=None, show_progress=True):\n",
        "  if max_len is None:\n",
        "    max_len = seed_ids.shape[1]\n",
        "  seed = seed_ids\n",
        "  generated_ids = []\n",
        "  if not show_progress:\n",
        "    iterations = range(max_len)\n",
        "  else:\n",
        "    iterations = tqdm(range(max_len))\n",
        "\n",
        "  for _ in iterations:\n",
        "    next_token_id = next_token(model, seed)\n",
        "    generated_ids.append(next_token_id)\n",
        "    if next_token_id == eos_id:\n",
        "      break\n",
        "    elif next_token_id == pad_id:\n",
        "      continue\n",
        "\n",
        "    seed = np.roll(seed, -1, axis=1)\n",
        "    seed[0, -1] = next_token_id\n",
        "\n",
        "  result = np.array(generated_ids)\n",
        "  result[0] = bos_id\n",
        "  result[-1] = eos_id\n",
        "  return result"
      ],
      "metadata": {
        "id": "f9qp4S3bMdIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = get_random_ids_from_dataset(normalized_train_x).reshape((1, seq_len))\n",
        "generated_ids = generate_ids(\n",
        "    model,\n",
        "    seed,\n",
        "    eos_id=tok.eos_id,\n",
        "    pad_id=tok.pad_id,\n",
        "    bos_id=tok.bos_id,\n",
        "    max_len=500\n",
        ")\n",
        "print(\"\\nGenerated\\n\" + str(generated_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI_xK86eMxHp",
        "outputId": "6be975bb-b975-4e00-d872-c37cb2588b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:40<00:00, 12.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated\n",
            "[  1 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285\n",
            " 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285\n",
            " 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285\n",
            " 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285\n",
            " 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285 285\n",
            "   1   2 229   4 281 201   4   3   2 228   4 283 239   4 199   4 233  91\n",
            " 227  53 271 230   6 281 235  41 199   4 260 229   4 226  82 194   4 194\n",
            "   4 283 213   4 260 229   4 187 112 263 225  72 276 226   5 279 208   4\n",
            " 281 216   4 260 239   4 199   4 280 213   4 259 211  99 281 187  72 281\n",
            " 222  72 268 228   4 281 219   5 281 187 213   5 281 229  53 271 204   4\n",
            " 283 220  47 260 229   4 281 194   4 144 259 219 106   3 229   4 282   4\n",
            "   3 234   4 207  99 281 194   4 199   4 201   4 282   4 235  86 281 229\n",
            "  72 259 201   4 260 219  72 281 241  88 260 217 125 261 236   4 281 213\n",
            "   4 260 223   5   2 190  99 281 194 112 284 193   4 282 228   4 260 226\n",
            "  47 228   4 194   4 201   4 262 213   4 206   4 199   4 281 201   4 194\n",
            "   4 157   4 282 214   5 284 193   4 268 220  72 283 205  72 276 213   4\n",
            " 260  54 216  29 283 226 112   3 201   4 133 199   4 198   4 281 223 140\n",
            " 276 229   4 281 203  53 271 216   4 224   5 201   4 224   4 259 203   4\n",
            " 201   4 281 213   4 197   4 281 217   5 260 197   4 260 239   4 279 201\n",
            "   4 260 231 151 208   4  56 224 112 284 219 112 281 228   4 217  72 224\n",
            " 139 201   4 217  99 261 204   4 281 229   4 283 219  36 284 211 125 228\n",
            "   4 281 234  72 283 190 115 242 112 281 219  53 271 228   4 198   4 260\n",
            " 226   4 259 225  72   2 229   4 213   4 268 229   4 223   5 284 202 160\n",
            " 211 125 281 228   4 268 199 112 268 229  53 271 228   4 281 221  99 281\n",
            " 209   4 203   4 260 228   4 260 229  99 208   4   3 201   4 199   4 204\n",
            "   4 268 201   4 281 194   4 282 228   4 197   4   3   3 228   4 260 216\n",
            "  52   2 223  86 268 220   4 268 223   4 260 229   4 260 194   4 268 223\n",
            "   4 268 236   4   3 229   4 268 235  19 281 239   4   0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_midi(\n",
        "    ids: np.ndarray,\n",
        "    tokenizer: Tokenizer,\n",
        "    file_name: str =\"result.mid\",\n",
        "  ):\n",
        "  tokenizer.decode([ids], file_name)"
      ],
      "metadata": {
        "id": "8YBkMklbNIkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_midi(generated_ids, tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ditQskqwNeQq",
        "outputId": "8b1bd41c-6ace-48d5-87db-14e7c38dc059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Start' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad'\n",
            " 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Pad' 'Start' 'bar' 'note_70' 'len_0'\n",
            " 'pos_6' 'note_42' 'len_0' 'beat' 'bar' 'note_69' 'len_0' 'pos_8'\n",
            " 'note_80' 'len_0' 'note_40' 'len_0' 'note_74' 'len_44' 'note_68' 'len_23'\n",
            " 'pos_24' 'note_71' 'len_10' 'pos_6' 'note_76' 'len_19' 'note_40' 'len_0'\n",
            " 'pos_10' 'note_70' 'len_0' 'note_67' 'len_38' 'note_35' 'len_0' 'note_35'\n",
            " 'len_0' 'pos_8' 'note_54' 'len_0' 'pos_10' 'note_70' 'len_0' 'note_28'\n",
            " 'len_6' 'pos_13' 'note_66' 'len_3' 'pos_3' 'note_67' 'len_1' 'pos_4'\n",
            " 'note_49' 'len_0' 'pos_6' 'note_57' 'len_0' 'pos_10' 'note_80' 'len_0'\n",
            " 'note_40' 'len_0' 'pos_5' 'note_54' 'len_0' 'pos_1' 'note_52' 'len_5'\n",
            " 'pos_6' 'note_28' 'len_3' 'pos_6' 'note_63' 'len_3' 'pos_2' 'note_69'\n",
            " 'len_0' 'pos_6' 'note_60' 'len_1' 'pos_6' 'note_28' 'note_54' 'len_1'\n",
            " 'pos_6' 'note_70' 'len_23' 'pos_24' 'note_45' 'len_0' 'pos_8' 'note_61'\n",
            " 'len_2' 'pos_10' 'note_70' 'len_0' 'pos_6' 'note_35' 'len_0' 'len_83'\n",
            " 'pos_1' 'note_60' 'len_54' 'beat' 'note_70' 'len_0' 'pos_7' 'len_0'\n",
            " 'beat' 'note_75' 'len_0' 'note_48' 'len_5' 'pos_6' 'note_35' 'len_0'\n",
            " 'note_40' 'len_0' 'note_42' 'len_0' 'pos_7' 'len_0' 'note_76' 'len_4'\n",
            " 'pos_6' 'note_70' 'len_3' 'pos_1' 'note_42' 'len_0' 'pos_10' 'note_60'\n",
            " 'len_3' 'pos_6' 'note_82' 'len_41' 'pos_10' 'note_58' 'len_7' 'pos_11'\n",
            " 'note_77' 'len_0' 'pos_6' 'note_54' 'len_0' 'pos_10' 'note_64' 'len_1'\n",
            " 'bar' 'note_31' 'len_5' 'pos_6' 'note_35' 'len_6' 'pos_9' 'note_34'\n",
            " 'len_0' 'pos_7' 'note_69' 'len_0' 'pos_10' 'note_67' 'len_2' 'note_69'\n",
            " 'len_0' 'note_35' 'len_0' 'note_42' 'len_0' 'pos_12' 'note_54' 'len_0'\n",
            " 'note_47' 'len_0' 'note_40' 'len_0' 'pos_6' 'note_42' 'len_0' 'note_35'\n",
            " 'len_0' 'len_95' 'len_0' 'pos_7' 'note_55' 'len_1' 'pos_9' 'note_34'\n",
            " 'len_0' 'pos_2' 'note_61' 'len_3' 'pos_8' 'note_46' 'len_3' 'pos_3'\n",
            " 'note_54' 'len_0' 'pos_10' 'len_238' 'note_57' 'len_15' 'pos_8' 'note_67'\n",
            " 'len_6' 'beat' 'note_42' 'len_0' 'len_762' 'note_40' 'len_0' 'note_39'\n",
            " 'len_0' 'pos_6' 'note_64' 'len_8' 'pos_3' 'note_70' 'len_0' 'pos_6'\n",
            " 'note_44' 'len_23' 'pos_24' 'note_57' 'len_0' 'note_65' 'len_1' 'note_42'\n",
            " 'len_0' 'note_65' 'len_0' 'pos_1' 'note_44' 'len_0' 'note_42' 'len_0'\n",
            " 'pos_6' 'note_54' 'len_0' 'note_38' 'len_0' 'pos_6' 'note_58' 'len_1'\n",
            " 'pos_10' 'note_38' 'len_0' 'pos_10' 'note_80' 'len_0' 'pos_4' 'note_42'\n",
            " 'len_0' 'pos_10' 'note_72' 'len_9' 'note_49' 'len_0' 'len_24' 'note_65'\n",
            " 'len_6' 'pos_9' 'note_60' 'len_6' 'pos_6' 'note_69' 'len_0' 'note_58'\n",
            " 'len_3' 'note_65' 'len_79' 'note_42' 'len_0' 'note_58' 'len_5' 'pos_11'\n",
            " 'note_45' 'len_0' 'pos_6' 'note_70' 'len_0' 'pos_8' 'note_60' 'len_18'\n",
            " 'pos_9' 'note_52' 'len_7' 'note_69' 'len_0' 'pos_6' 'note_75' 'len_3'\n",
            " 'pos_8' 'note_31' 'len_61' 'note_83' 'len_6' 'pos_6' 'note_60' 'len_23'\n",
            " 'pos_24' 'note_69' 'len_0' 'note_39' 'len_0' 'pos_10' 'note_67' 'len_0'\n",
            " 'pos_1' 'note_66' 'len_3' 'bar' 'note_70' 'len_0' 'note_54' 'len_0'\n",
            " 'pos_2' 'note_70' 'len_0' 'note_64' 'len_1' 'pos_9' 'note_43' 'len_97'\n",
            " 'note_52' 'len_7' 'pos_6' 'note_69' 'len_0' 'pos_2' 'note_40' 'len_6'\n",
            " 'pos_2' 'note_70' 'len_23' 'pos_24' 'note_69' 'len_0' 'pos_6' 'note_62'\n",
            " 'len_5' 'pos_6' 'note_50' 'len_0' 'note_44' 'len_0' 'pos_10' 'note_69'\n",
            " 'len_0' 'pos_10' 'note_70' 'len_5' 'note_49' 'len_0' 'beat' 'note_42'\n",
            " 'len_0' 'note_40' 'len_0' 'note_45' 'len_0' 'pos_2' 'note_42' 'len_0'\n",
            " 'pos_6' 'note_35' 'len_0' 'pos_7' 'note_69' 'len_0' 'note_38' 'len_0'\n",
            " 'beat' 'beat' 'note_69' 'len_0' 'pos_10' 'note_57' 'len_22' 'bar'\n",
            " 'note_64' 'len_4' 'pos_2' 'note_61' 'len_0' 'pos_2' 'note_64' 'len_0'\n",
            " 'pos_10' 'note_70' 'len_0' 'pos_10' 'note_35' 'len_0' 'pos_2' 'note_64'\n",
            " 'len_0' 'pos_2' 'note_77' 'len_0' 'beat' 'note_70' 'len_0' 'pos_2'\n",
            " 'note_76' 'len_13' 'pos_6' 'note_80' 'len_0' 'End']\n"
          ]
        }
      ]
    }
  ]
}