{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xpqjf8fLFTeg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get a smaller version of the Lakh MIDI Dataset v0.1\n",
        "%%capture\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz\n",
        "!tar xvf clean_midi.tar.gz\n",
        "!rm clean_midi.tar.gz\n",
        "\n",
        "dataset_path = \"/content/clean_midi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBe7RC5BFnGd",
        "outputId": "83407868-2cbf-455b-fe9b-6186a782e21b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/5.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m5.3/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (24.1)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=1df42fc2af8f0be5c59fe1c1938c7511219c97ef044221fcbffc322d953d168b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Paths to the files of the dataset\n",
        "midi_paths = list(Path(\"clean_midi\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "Xgzc6NC0FqwB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning of files"
      ],
      "metadata": {
        "id": "mLqOtcjf-r5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.mid\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "KznPqQQe-rC2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI2Tokens"
      ],
      "metadata": {
        "id": "ofcPhnyn9GSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pretty_midi\n",
        "\n",
        "class midi_to_tokens():\n",
        "    def __init__(self, path, steps_per_beat=12, limit=None):\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        try:\n",
        "          self.pm = pretty_midi.PrettyMIDI(path)\n",
        "        except OSError as e:\n",
        "          print(f\"Error reading MIDI file: {e}\")\n",
        "          return\n",
        "        self.dbs = self.pm.get_downbeats().tolist() + [self.pm.get_end_time()] # dbs := downbeats\n",
        "        self.tokens = self._tokenize(limit=limit)\n",
        "\n",
        "    def __call__(self):\n",
        "        return ' '.join(self.tokens)\n",
        "\n",
        "    def _time_to_step(self, time):\n",
        "        return round(self.pm.time_to_tick(time) / self.pm.resolution * self.steps_per_beat)\n",
        "\n",
        "    def _event_to_tokens(self, event):\n",
        "        if event in ('bar', 'beat'):\n",
        "            return [event]\n",
        "        elif isinstance(event, pretty_midi.containers.Note):\n",
        "            return [f'note_{event.pitch}', f'len_{self._time_to_step(event.end) - self._time_to_step(event.start)}']\n",
        "\n",
        "    def _trim_note(self, note, start, end):\n",
        "        n = copy.copy(note)\n",
        "        n.start, n.end = max(n.start, start), min(n.end, end)\n",
        "        return n\n",
        "\n",
        "    def _tokenize(self, start_measure=1, end_measure=None, limit=None):\n",
        "        start, end = self.dbs[start_measure - 1], self.dbs[end_measure or -1]\n",
        "\n",
        "        notes = []\n",
        "        for inst in self.pm.instruments:\n",
        "            notes += inst.notes\n",
        "        notes.sort(key=lambda x: (x.start, -x.pitch))\n",
        "\n",
        "        events = []\n",
        "        events += [(self._time_to_step(db), 'bar') for db in self.dbs if start <= db < end]\n",
        "        events += [(self._time_to_step(b), 'beat') for b in set(self.pm.get_beats()) - set(self.dbs) if start <= b < end] # beats without downbeats\n",
        "        events += [(self._time_to_step(max(n.start, start)), self._trim_note(n, start, end)) for n in notes if start <= n.start < end or start < n.end <= end]\n",
        "        events.sort(key=lambda x: x[0])\n",
        "\n",
        "        tokens = []\n",
        "        last_beat = 0\n",
        "        if limit is not None:\n",
        "            events = events[:limit]\n",
        "        for step, event in events:\n",
        "            if event in ('bar', 'beat'):\n",
        "                last_beat = step\n",
        "            if step - last_beat:\n",
        "                tokens.append(f'pos_{step - last_beat}')\n",
        "            tokens += self._event_to_tokens(event)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def measures(self, start_measure=1, end_measure=None):\n",
        "        return self._tokenize(start_measure, end_measure)"
      ],
      "metadata": {
        "id": "CrSlr4mxAWlU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokens2MIDI"
      ],
      "metadata": {
        "id": "kjvAidVeGXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokensToMidi:\n",
        "    def __init__(self, tokens, steps_per_beat=12, ticks_per_beat=960, tempo=120):\n",
        "        self.tokens = tokens\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.ticks_per_step = ticks_per_beat // steps_per_beat\n",
        "        self.tempo = tempo\n",
        "        self.ticks_per_beat = ticks_per_beat\n",
        "\n",
        "    def _ticks_to_time(self, ticks):\n",
        "        return ticks * 60 / (self.tempo * self.ticks_per_beat)\n",
        "\n",
        "    def generate_midi(self, path):\n",
        "        pm = pretty_midi.PrettyMIDI(initial_tempo=self.tempo)\n",
        "        instrument = pretty_midi.Instrument(program=38)\n",
        "\n",
        "        time = 0\n",
        "        last_beat = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(self.tokens):\n",
        "            token = self.tokens[i]\n",
        "\n",
        "            if token == \"bar\":\n",
        "                time += self._ticks_to_time(self.ticks_per_step * self.steps_per_beat)\n",
        "                last_beat = time\n",
        "            elif token == \"beat\":\n",
        "                time = last_beat\n",
        "                last_beat = time\n",
        "            elif token.startswith(\"pos_\"):\n",
        "                position = int(token.split(\"_\")[1])\n",
        "                time = last_beat + self._ticks_to_time(self.ticks_per_step * position)\n",
        "            elif token.startswith(\"note_\"):\n",
        "                pitch = int(token.split(\"_\")[1])\n",
        "                length_token = self.tokens[i + 1]\n",
        "                length = int(length_token.split(\"_\")[1])\n",
        "                duration = self._ticks_to_time(self.ticks_per_step * length)\n",
        "\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch,\n",
        "                    start=time,\n",
        "                    end=time + duration\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "                i += 1\n",
        "            i += 1\n",
        "\n",
        "        pm.instruments.append(instrument)\n",
        "        pm.write(path)\n",
        "        return pm"
      ],
      "metadata": {
        "id": "oDUS-wjOGWtg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a utility class \"Tokenizer\""
      ],
      "metadata": {
        "id": "z-jNjy70AgvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self, limit=None):\n",
        "        self._encoder = LabelEncoder()\n",
        "        self.PAD_id = 0\n",
        "        self.BOS_id = 1\n",
        "        self.EOS_id = 2\n",
        "        self.limit = limit\n",
        "\n",
        "    def _tokenize(self, midi_paths):\n",
        "      \"\"\"\n",
        "      midi_paths: list of paths to MIDI files\n",
        "      returns: list of lists of string tokens\n",
        "      \"\"\"\n",
        "      tokens = []\n",
        "      for path in midi_paths:\n",
        "        try:\n",
        "          toAdd = midi_to_tokens(str(path), steps_per_beat=12, limit=self.limit).tokens\n",
        "          toAdd.insert(0, \"Start\")\n",
        "          toAdd.append(\"End\")\n",
        "          tokens.append(toAdd)\n",
        "        except AttributeError:\n",
        "          print(f\"Error reading MIDI file: {path}\")\n",
        "          continue\n",
        "      return tokens\n",
        "\n",
        "    def fit_and_encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      flattened_array = np.concatenate([np.array(sublist).flatten() for sublist in tokens])\n",
        "      self._encoder.fit(flattened_array)\n",
        "      transformed = [self._encoder.transform(i) for i in tokens]\n",
        "      self.EOS_id = self._encoder.transform([\"End\"])[0]\n",
        "      self.BOS_id = self._encoder.transform([\"Start\"])[0]\n",
        "      self.PAD_id = self._encoder.classes_.shape[0]\n",
        "      self._encoder.classes_ = np.append(self._encoder.classes_, [\"Pad\"])\n",
        "      return transformed\n",
        "\n",
        "    def encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      return [self._encoder.transform(i) for i in tokens]\n",
        "\n",
        "    def decode(self, encoded_tokens, path=\"reconstructed_midi.mid\"):\n",
        "      string_tokens = [self._encoder.inverse_transform(i) for i in encoded_tokens]\n",
        "      for i in range(len(string_tokens)):\n",
        "        midi_reconstructor = TokensToMidi(string_tokens[i])\n",
        "        midi_reconstructor.generate_midi(str(i) + path)\n",
        "\n",
        "    def pad(self, encoded_tokens):\n",
        "      self._seq_length = max(len(arr) for arr in encoded_tokens)\n",
        "      return np.array([np.pad(arr, (self._seq_length - len(arr), 0), mode='constant', constant_values=self.PAD_id) for arr in encoded_tokens])\n",
        "\n",
        "    @property\n",
        "    def encoder(self):\n",
        "      return self._encoder\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "      return self._encoder.classes_.shape[0]\n",
        "\n",
        "    @property\n",
        "    def seq_length(self):\n",
        "      return self._seq_length\n",
        "\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "      return self.PAD_id\n",
        "\n",
        "    @property\n",
        "    def bos_id(self):\n",
        "      return self.BOS_id\n",
        "\n",
        "    @property\n",
        "    def eos_id(self):\n",
        "      return self.EOS_id\n",
        ""
      ],
      "metadata": {
        "id": "utD8X3r1AgaG"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the tokenizer"
      ],
      "metadata": {
        "id": "uITXgRsfHn4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(limit=50)\n",
        "encoded_tokens = tok.fit_and_encode(midis[:100])\n",
        "\n",
        "print(f\"PAD_id is {tok.pad_id}\")\n",
        "print(f\"BOS_id is {tok.bos_id}\")\n",
        "print(f\"EOS_id is {tok.eos_id}\")\n",
        "print(f\"Vocab size is {tok.vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOxAY9VTHp56",
        "outputId": "15267998-cad8-42fc-83be-0be8bbadcb9d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading MIDI file: running status without last_status\n",
            "Error reading MIDI file: /content/midis/16907.mid\n",
            "Error reading MIDI file: data byte must be in range 0..127\n",
            "Error reading MIDI file: /content/midis/2651.mid\n",
            "PAD_id is 203\n",
            "BOS_id is 1\n",
            "EOS_id is 0\n",
            "Vocab size is 204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "KjDSHc2lIxwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = tok.pad(encoded_tokens)\n",
        "print(f\"Maximum sequence len is {tok.seq_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m4dFeH1Iy5D",
        "outputId": "cf82405d-5564-4062-ca17-9cce77270362"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence len is 134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SXi2gS2yKCvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "WGzHWz_cKAAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `keras_nlp`\n",
        "%%capture\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "pV0DmhYNFzpQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp.layers as nlp_layers\n",
        "\n",
        "def create_transformer(vocab_size, seq_len, embedding_dim, num_heads, dff, num_layers):\n",
        "  # Input\n",
        "    inputs = tf.keras.Input(shape=(seq_len,))\n",
        "\n",
        "    # Embedding\n",
        "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    # Encoder\n",
        "    encoder = nlp_layers.TransformerEncoder(num_heads=num_heads, intermediate_dim=dff)(embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = nlp_layers.TransformerDecoder(num_heads=num_heads, intermediate_dim=dff)(embedding, encoder)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "    # Crea il modello\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "RrZV_yNRF2k6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tok.vocab_size\n",
        "seq_len = tok.seq_length\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model, encoder, decoder = create_transformer(vocab_size=vocab_size,\n",
        "                                             seq_len=seq_len,\n",
        "                                             embedding_dim=256,\n",
        "                                             num_heads=8,\n",
        "                                             dff=1024,\n",
        "                                             num_layers=6)"
      ],
      "metadata": {
        "id": "v90igmqzAczd"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_x = padded_tokens[:70]\n",
        "normalized_val_x = padded_tokens[70:]\n",
        "\n",
        "normalized_train_y = np.roll(normalized_train_x, shift=-1, axis=1)\n",
        "normalized_val_y = np.roll(normalized_val_x, shift=-1, axis=1)\n"
      ],
      "metadata": {
        "id": "I69Mb-I0Bga0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(normalized_train_x, normalized_train_y,\n",
        "          epochs=5,\n",
        "          validation_data=(normalized_val_x, normalized_val_y),\n",
        "          callbacks=[early_stopping],\n",
        "          batch_size=32\n",
        "          )\n",
        "\n",
        "model.save(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "MvoCcmHKBR68",
        "outputId": "ca3b5a7b-3ff7-4289-96e9-ed166d6f2ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.1137 - loss: 5.1872 - val_accuracy: 0.3177 - val_loss: 3.4921\n",
            "Epoch 2/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3507 - loss: 3.2062 - val_accuracy: 0.3292 - val_loss: 3.2455\n",
            "Epoch 3/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3754 - loss: 2.8788 - val_accuracy: 0.3422 - val_loss: 3.1119\n",
            "Epoch 4/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3850 - loss: 2.7136 - val_accuracy: 0.3515 - val_loss: 3.0307\n",
            "Epoch 5/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4097 - loss: 2.5710 - val_accuracy: 0.3478 - val_loss: 2.9859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jH3LNvLpMmVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "tL1VLQPHMnXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_random_ids_from_dataset(dataset):\n",
        "  return dataset[np.random.choice(dataset.shape[0])]\n",
        "\n",
        "def sample_next_token(probabilities) -> int:\n",
        "  # Ensure the probabilities sum to 1 (they should, but numerical issues might affect it)\n",
        "  last_token_probs = probabilities[0, -1]\n",
        "  last_token_probs /= last_token_probs.sum()\n",
        "  return np.random.choice(len(last_token_probs), p=last_token_probs)\n",
        "\n",
        "def next_token(model, seed_ids):\n",
        "    probabilities = model.predict(seed_ids, verbose=0)\n",
        "    next_token = sample_next_token(probabilities)\n",
        "    return next_token\n",
        "\n",
        "def generate_ids(model, seed_ids, eos_id, pad_id, bos_id, max_len=None, show_progress=True):\n",
        "  if max_len is None:\n",
        "    max_len = seed_ids.shape[1]\n",
        "  seed = seed_ids\n",
        "  generated_ids = []\n",
        "  if not show_progress:\n",
        "    iterations = range(max_len)\n",
        "  else:\n",
        "    iterations = tqdm(range(max_len))\n",
        "\n",
        "  for _ in iterations:\n",
        "    next_token_id = next_token(model, seed)\n",
        "    generated_ids.append(next_token_id)\n",
        "    if next_token_id == eos_id:\n",
        "      break\n",
        "    elif next_token_id == pad_id:\n",
        "      continue\n",
        "\n",
        "    seed = np.roll(seed, -1, axis=1)\n",
        "    seed[0, -1] = next_token_id\n",
        "\n",
        "  result = np.array(generated_ids)\n",
        "  result[0] = bos_id\n",
        "  result[-1] = eos_id\n",
        "  return result"
      ],
      "metadata": {
        "id": "f9qp4S3bMdIJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = get_random_ids_from_dataset(normalized_train_x).reshape((1, seq_len))\n",
        "generated_ids = generate_ids(\n",
        "    model,\n",
        "    seed,\n",
        "    eos_id=tok.eos_id,\n",
        "    pad_id=tok.pad_id,\n",
        "    bos_id=tok.bos_id,\n",
        "    max_len=100\n",
        ")\n",
        "print(\"\\nGenerated\\n\" + str(generated_ids))"
      ],
      "metadata": {
        "id": "sI_xK86eMxHp",
        "outputId": "4cf3b9ff-28e3-42e8-980b-57c31fc06131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 14.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated\n",
            "[  1 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203\n",
            " 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203\n",
            " 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203\n",
            " 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203\n",
            " 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203 203\n",
            " 203 203 203 124  74 199 155   9 199   0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_midi(\n",
        "    ids: np.ndarray,\n",
        "    tokenizer: Tokenizer,\n",
        "    file_name: str =\"result.mid\",\n",
        "  ):\n",
        "  tokenizer.decode([ids], file_name)"
      ],
      "metadata": {
        "id": "8YBkMklbNIkc"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_midi(generated_ids, tok)"
      ],
      "metadata": {
        "id": "ditQskqwNeQq"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}