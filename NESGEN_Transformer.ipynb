{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIDI music generation with Transformer\n",
        "\n",
        "In this notebook we'll be presenting various approaches for training a Transformer model that generates music in the form of MIDI (Musical Instrument Digital Interface) files.\n",
        "\n",
        "Notebook presented for the A.A. 2023/2024 Deep Learning project.\n",
        "\n",
        "Group members:\n",
        "\n",
        "- Valerio Di Zio - valerio.dizio@studio.unibo.it\n",
        "- Francesco Magnani - francesco.magnani14@studio.unibo.it\n",
        "- Luca Rubboli - mail@diluca.it"
      ],
      "metadata": {
        "id": "u00hbTlLk7VO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of libraries"
      ],
      "metadata": {
        "id": "KfCzH-Z5s5tO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u-NyqFwak4dU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown\n",
        "!pip install pretty_midi\n",
        "!pip install miditok\n",
        "!pip install pretty_midi midi-clip\n",
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Download"
      ],
      "metadata": {
        "id": "I55SUO_ztKNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
        "!unzip \"maestro-v3.0.0-midi.zip\"\n",
        "!rm \"maestro-v3.0.0-midi.zip\"\n",
        "\n",
        "dataset_path = \"maestro-v3.0.0\""
      ],
      "metadata": {
        "id": "UHnI-Z7-tNag"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Import of libraries and setup of downloaded files"
      ],
      "metadata": {
        "id": "bW6Z2multX0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from random import shuffle\n",
        "\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from miditok import REMI, TokenizerConfig\n",
        "from miditok.data_augmentation import augment_dataset\n",
        "from miditok.utils import split_files_for_training\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "z6V8GN03tk9i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files of the dataset\n",
        "\n",
        "midi_paths = list(Path(dataset_path).resolve().glob(\"**/*.mid\")) + list(Path(dataset_path).resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.midi\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\")) + list(Path(\"midis\").resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "def sample():\n",
        "  return str(random.choice(midis))"
      ],
      "metadata": {
        "id": "upVam-gYtv-7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "A tokenizer in the context of MIDI tokenization converts MIDI files into a sequence of **tokens** (e.g., integers or strings) that represent musical elements like notes, durations, velocities, and time shifts.\n",
        "\n",
        "The Miditok library provides predefined tokenization methods (e.g. **REMI**) to translate MIDI events into tokens and vice versa, ensuring a structured and efficient representation of musical data."
      ],
      "metadata": {
        "id": "GlCY3jLut44O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First approach to tokenization\n",
        "Tokenization is probably one of the most important steps in the process.\n",
        "\n",
        "For tokenization, in this specific example, a representation in the following form was used.\n",
        "\n",
        "note-duration\n",
        "\n",
        "Example: \"C4-1.0, C4-1.0, G4-1.0, G4-1.0, A4-1.0, A4-1.0, G4-2.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-1.0, D4-1.0, C4-2.0, G4-1.0, G4-1.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-2.0, G4-1.0, G4-1.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-2.0\"\n",
        "\n",
        "This allows each token to be assigned, 1 note.\n",
        "\n",
        "A midi file, in fact, is much more complicated than this and by going about tokenizing differently, there is a risk of generating tokens that in sequence do not make sense.\n",
        "\n",
        "By going to restrict the model so that we get for each token 1 note we make subsequent training and generation easier.\n",
        "\n",
        "**This method unfortunately works worse than Miditok, consequently in this notebook Miditok will be used as the main tokenizer.**"
      ],
      "metadata": {
        "id": "OhgfVN3_-XMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRING_TOKENIZATION = False\n",
        "if STRING_TOKENIZATION:\n",
        "  def find_midi_files(directory):\n",
        "      \"\"\"Recursively finds all MIDI files in the directory.\"\"\"\n",
        "      midi_files = []\n",
        "      for root, _, files in os.walk(directory):\n",
        "          for file in files:\n",
        "              if file.endswith((\".mid\", \".midi\")):\n",
        "                  midi_files.append(os.path.join(root, file))\n",
        "      return midi_files\n",
        "\n",
        "  def midi_to_note_representation(file_path):\n",
        "      \"\"\"Converts a MIDI file into a note-duration representation.\"\"\"\n",
        "      try:\n",
        "          midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "          note_events = []\n",
        "\n",
        "          for instrument in midi_data.instruments:\n",
        "              for note in instrument.notes:\n",
        "                  # Convert pitch to note name\n",
        "                  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
        "                  duration = note.end - note.start\n",
        "                  note_events.append(f\"{note_name}-{duration:.1f}\")\n",
        "\n",
        "          return \", \".join(note_events)\n",
        "      except Exception as e:\n",
        "          print(f\"Error in file conversion {file_path}: {e}\")\n",
        "          return None\n",
        "\n",
        "  def create_dataset_from_midi(directory, output_file):\n",
        "      \"\"\"Creates a JSON dataset with the representation of notes from MIDI files.\"\"\"\n",
        "      dataset = {}\n",
        "      midi_files = find_midi_files(directory)\n",
        "\n",
        "      for midi_file in tqdm(midi_files):\n",
        "          note_representation = midi_to_note_representation(midi_file)\n",
        "          if note_representation:\n",
        "              dataset[midi_file] = note_representation\n",
        "\n",
        "      with open(output_file, \"w\") as json_file:\n",
        "          json.dump(dataset, json_file, indent=4)\n",
        "\n",
        "      print(f\"Dataset created and saved in {output_file}\")\n",
        "\n",
        "  midi_directory = \"./Maestro\"\n",
        "  output_dataset_file = \"midi_dataset.json\"\n",
        "\n",
        "\n",
        "  create_dataset_from_midi(midi_directory, output_dataset_file)\n",
        "\n",
        "  dataset_file = \"midi_dataset.json\"\n",
        "\n",
        "  with open(dataset_file, \"r\") as json_file:\n",
        "      dataset = json.load(json_file)\n",
        "      maestro_dataset = list(dataset.values())\n",
        "\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "  tokenizer = Tokenizer(filters=\"\", lower=False, split=\",\")\n",
        "  tokenizer.fit_on_texts(maestro_dataset)\n",
        "  tokenized_melodies = tokenizer.texts_to_sequences(maestro_dataset)"
      ],
      "metadata": {
        "id": "rcjhLsIt-WAH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miditok Tokenization"
      ],
      "metadata": {
        "id": "IgkoM4Hg_rD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEAT_RES defines the temporal resolution for tokenizing MIDI events,\n",
        "# mapping beat intervals to the number of subdivisions per beat.\n",
        "BEAT_RES = {(0, 1): 12, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n",
        "\n",
        "TOKENIZER_PARAMS = {\n",
        "    \"pitch_range\": (21, 109),\n",
        "    \"beat_res\": BEAT_RES,\n",
        "    \"num_velocities\": 24,\n",
        "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n",
        "    \"use_chords\": True,\n",
        "    \"use_rests\": True,\n",
        "    \"use_tempos\": True,\n",
        "    \"use_time_signatures\": True,\n",
        "    \"use_programs\": False,  # no multitrack\n",
        "    \"num_tempos\": 32,\n",
        "    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n",
        "}\n",
        "\n",
        "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
        "\n",
        "tokenizer = REMI(config)"
      ],
      "metadata": {
        "id": "40PhMXS6uXME"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a trained tokenizer"
      ],
      "metadata": {
        "id": "5qLDUEVuvjJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1SDRkoWwyuSl4udoCHdcitjLLm9d0kfxS\n",
        "tokenizer = REMI(params=Path(\"maestro_tokenizer.json\"))\n",
        "print(f\"Vocab size: {len(tokenizer)}\")"
      ],
      "metadata": {
        "id": "qloz4kvDvmQL",
        "outputId": "a4724950-8be4-47cb-9941-4e31fee6821c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SDRkoWwyuSl4udoCHdcitjLLm9d0kfxS\n",
            "To: /content/maestro_tokenizer.json\n",
            "\r  0% 0.00/1.66M [00:00<?, ?B/s]\r100% 1.66M/1.66M [00:00<00:00, 141MB/s]\n",
            "Vocab size: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): train the tokenizer\n",
        "This cell is optional because the tokenizer train is long, consequently as a matter of time it is skipped in favor of the previous cell that imports the already trained tokenizer"
      ],
      "metadata": {
        "id": "juVWqNWivsO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TOKENIZER = False\n",
        "if TRAIN_TOKENIZER:\n",
        "  tokenizer.train(vocab_size=30000, files_paths=midis)\n",
        "  processed = [Path(f\"{s}\") for s in midis]\n",
        "  print(len(processed))"
      ],
      "metadata": {
        "id": "xN1YBCa_vqnl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset\n",
        "Divide the Maestro dataset into Train, Valid and Test by also performing data augmentation"
      ],
      "metadata": {
        "id": "o5zPO14qxr7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1IQToXD9s8g4L-AlK-MY4qvGoLZ-p7bMw\n",
        "!gdown 1DWjViUKpW07LfbGimlhhhGdK7oQaJpj-\n",
        "\n",
        "all_ids_train = np.loadtxt(\"all_ids_maestro_train.txt\").astype(np.int32)\n",
        "all_ids_valid = np.loadtxt(\"all_ids_maestro_valid.txt\").astype(np.int32)"
      ],
      "metadata": {
        "id": "91VCDP68x8jM",
        "outputId": "32870673-15bd-4d61-dc4b-510a4350f896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IQToXD9s8g4L-AlK-MY4qvGoLZ-p7bMw\n",
            "From (redirected): https://drive.google.com/uc?id=1IQToXD9s8g4L-AlK-MY4qvGoLZ-p7bMw&confirm=t&uuid=2e9fdf42-4340-4666-9594-f962c18cf909\n",
            "To: /content/all_ids_maestro_train.txt\n",
            "100% 1.28G/1.28G [00:05<00:00, 226MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DWjViUKpW07LfbGimlhhhGdK7oQaJpj-\n",
            "From (redirected): https://drive.google.com/uc?id=1DWjViUKpW07LfbGimlhhhGdK7oQaJpj-&confirm=t&uuid=5853ad5a-750d-4f98-bcf6-d49540731c1a\n",
            "To: /content/all_ids_maestro_valid.txt\n",
            "100% 572M/572M [00:02<00:00, 223MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): perform split"
      ],
      "metadata": {
        "id": "SV_H1lL-zHUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_DATASET = False\n",
        "if SPLIT_DATASET:\n",
        "\n",
        "  total_num_files = len(processed)\n",
        "  num_files_valid = round(total_num_files * 0.15)\n",
        "  num_files_test = round(total_num_files * 0.15)\n",
        "  shuffle(processed)\n",
        "  midi_paths_valid = processed[:num_files_valid]\n",
        "  midi_paths_test = processed[num_files_valid:num_files_valid + num_files_test]\n",
        "  midi_paths_train = processed[num_files_valid + num_files_test:]\n",
        "\n",
        "  # Chunk MIDIs and perform data augmentation on each subset independently\n",
        "\n",
        "  for files_paths, subset_name in (\n",
        "      (midi_paths_train, \"train\"),\n",
        "      (midi_paths_valid, \"valid\"),\n",
        "        (midi_paths_test, \"test\")\n",
        "  ):\n",
        "      print(files_paths[0])\n",
        "      # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
        "      subset_chunks_dir = Path(f\"Maestro_{subset_name}\")\n",
        "\n",
        "      split_files_for_training(\n",
        "          files_paths=files_paths,\n",
        "          tokenizer=tokenizer,\n",
        "          save_dir=subset_chunks_dir,\n",
        "          max_seq_len=1024,\n",
        "          num_overlap_bars=2,\n",
        "      )\n",
        "\n",
        "      # Perform data augmentation\n",
        "      augment_dataset(\n",
        "          subset_chunks_dir,\n",
        "          pitch_offsets=[-12, 12],\n",
        "          velocity_offsets=[-4, 4],\n",
        "          duration_offsets=[-0.5, 0.5],\n",
        "      )\n",
        "  midi_paths_train = list(Path(\"Maestro_train\").glob(\"**/*.mid\")) + list(Path(\"Maestro_train\").glob(\"**/*.midi\"))\n",
        "  midi_paths_valid = list(Path(\"Maestro_valid\").glob(\"**/*.mid\")) + list(Path(\"Maestro_valid\").glob(\"**/*.midi\"))\n",
        "  midi_paths_test = list(Path(\"Maestro_test\").glob(\"**/*.mid\")) + list(Path(\"Maestro_test\").glob(\"**/*.midi\"))\n"
      ],
      "metadata": {
        "id": "sm6iZq4uxhKx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  def midi_valid(midi) -> bool:\n",
        "      if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "          return False  # time signature different from 4/*, 4 beats per bar\n",
        "      return True\n",
        "\n",
        "  if os.path.exists(\"tokenized\"):\n",
        "    shutil.rmtree(\"tokenized\")\n",
        "\n",
        "  for dir in (\"train\", \"valid\", \"test\"):\n",
        "      tokenizer.tokenize_dataset(\n",
        "          Path(f\"Maestro_{dir}\"),\n",
        "          Path(f\"tokenized_{dir}\"),\n",
        "          midi_valid,\n",
        "      )"
      ],
      "metadata": {
        "id": "BfuMgF_syIB_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  def read_json(path: str) -> dict:\n",
        "    with open(path, \"r\") as f:\n",
        "      return json.load(f)\n",
        "\n",
        "  def read_json_files(json_file_paths):\n",
        "      \"\"\"Reads a list of JSON files and returns a list of objects.\n",
        "      Args:\n",
        "          json_file_paths: A list of file paths to JSON files.\n",
        "      Returns:\n",
        "          A list of objects, where each object represents the data from a JSON file.\n",
        "          Returns an empty list if any error occurs during file processing.\n",
        "      \"\"\"\n",
        "      objects = []\n",
        "\n",
        "      for file_path in tqdm(json_file_paths):\n",
        "          try:\n",
        "              objects.append(read_json(file_path))\n",
        "          except FileNotFoundError:\n",
        "              print(f\"Error: File not found - {file_path}\")\n",
        "              return [] # Return empty list on error\n",
        "          except json.JSONDecodeError:\n",
        "              print(f\"Error decoding JSON in file: {file_path}\")\n",
        "              return [] # Return empty list on error\n",
        "      return objects"
      ],
      "metadata": {
        "id": "8Csa3vMqyWs-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_train = read_json_files(tokenized_train)\n",
        "\n",
        "  tokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_valid = read_json_files(tokenized_valid)\n",
        "\n",
        "  tokenized_test = list(Path(\"tokenized_test\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_test = read_json_files(tokenized_test)\n",
        "\n",
        "\n",
        "  if data_objects_train:\n",
        "      print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\n",
        "  else:\n",
        "      print(\"Error reading JSON files.\")"
      ],
      "metadata": {
        "id": "NFZMxxc1z-H2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\n",
        "  encoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\n",
        "  encoded_test = [np.array(song[\"ids\"][0]) for song in data_objects_test]\n",
        "\n",
        "  all_ids_train = np.concatenate(encoded_train)\n",
        "  all_ids_valid = np.concatenate(encoded_valid)\n",
        "  all_ids_test = np.concatenate(encoded_test)"
      ],
      "metadata": {
        "id": "S9OWP1BO0BjZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tensorflow Dataset"
      ],
      "metadata": {
        "id": "5sULb9Yg0PGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\n",
        "ids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)"
      ],
      "metadata": {
        "id": "lg-t03RY0NxY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert into sequences"
      ],
      "metadata": {
        "id": "btOrQBpw0lnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 1024\n",
        "\n",
        "sequences_train = ids_dataset_train.batch(SEQ_LENGTH+1, drop_remainder=True)\n",
        "sequences_valid = ids_dataset_valid.batch(SEQ_LENGTH+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "_s_7NJhs0jl-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing labels"
      ],
      "metadata": {
        "id": "_BgCctUj0v4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    # Convert to float32\n",
        "    input_seq = tf.cast(sequence[:-1], tf.int32)\n",
        "    target_seq = tf.cast(sequence[1:], tf.int32)\n",
        "    return input_seq, target_seq\n",
        "\n",
        "\n",
        "train_ds = sequences_train.map(split_input_target)\n",
        "valid_ds = sequences_valid.map(split_input_target)"
      ],
      "metadata": {
        "id": "2Gtbw2330yTg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create training batches\n",
        "Buffer size to shuffle the dataset\n",
        "(TF data is designed to work with possibly infinite sequences, so it doesn't attempt to shuffle the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements)."
      ],
      "metadata": {
        "id": "piszzuBy03qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "valid_ds = (\n",
        "    valid_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "xwJsixAK0-5g"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model"
      ],
      "metadata": {
        "id": "LM9y_1cb15gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForCausalLM, MistralConfig\n",
        "\n",
        "# Define the model configuration\n",
        "model_config = MistralConfig(\n",
        "    vocab_size=len(tokenizer),\n",
        "    hidden_size=512,\n",
        "    intermediate_size=1024,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=8,\n",
        "    num_key_value_heads=4,\n",
        "    sliding_window=256,\n",
        "    max_position_embeddings=8192,\n",
        "    pad_token_id=tokenizer['PAD_None'],\n",
        "    bos_token_id=tokenizer['BOS_None'],\n",
        "    eos_token_id=tokenizer['EOS_None'],\n",
        ")\n",
        "\n",
        "# Initialize the TensorFlow model\n",
        "model = TFAutoModelForCausalLM.from_config(model_config)\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=\"adam\",\n",
        "              weighted_metrics=[\"sparse_categorical_accuracy\"],\n",
        "              jit_compile=True,\n",
        "              )"
      ],
      "metadata": {
        "id": "2RJveLYx1-MW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "4hx8o0IS26QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1qoTIkmhmj0z4854FFofz02KLk5DnyqB1\n",
        "!unzip NESGEN_Maestro15.zip\n",
        "\n",
        "model.from_pretrained(\"nesgen-maestro0612\")"
      ],
      "metadata": {
        "id": "xLU0o0qo3FT2",
        "outputId": "87378068-0c06-44b4-fc84-c2b273e90a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qoTIkmhmj0z4854FFofz02KLk5DnyqB1\n",
            "From (redirected): https://drive.google.com/uc?id=1qoTIkmhmj0z4854FFofz02KLk5DnyqB1&confirm=t&uuid=0a6995a8-f47a-4efe-9393-ac11e4853015\n",
            "To: /content/NESGEN_Maestro15.zip\n",
            "100% 184M/184M [00:00<00:00, 187MB/s]\n",
            "Archive:  NESGEN_Maestro15.zip\n",
            "replace nesgen-maestro0612/config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMistralForCausalLM.\n",
            "\n",
            "All the layers of TFMistralForCausalLM were initialized from the model checkpoint at nesgen-maestro0612.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMistralForCausalLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.models.mistral.modeling_tf_mistral.TFMistralForCausalLM at 0x7ce26f786620>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): Train model\n",
        "Training of this model is made optional, free colab does not allow for this training."
      ],
      "metadata": {
        "id": "fgYg8Jx43cF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = False\n",
        "if TRAIN:\n",
        "  EPOCHS = 15\n",
        "\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=valid_ds,\n",
        "  )"
      ],
      "metadata": {
        "id": "-uRSJ2Ci2RNG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "ccD0NCuj3VAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a seed from the test set"
      ],
      "metadata": {
        "id": "5J6ZmFEb3xXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seed():\n",
        "    for seed_ids, _ in valid_ds.take(1):\n",
        "      seed = seed_ids\n",
        "    return seed[0]"
      ],
      "metadata": {
        "id": "RS4h5gPO3XDx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and dump MIDI\n"
      ],
      "metadata": {
        "id": "rD4SVzUg34fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dump_seed = False\n",
        "\n",
        "seed = get_seed()\n",
        "input_ids = tf.convert_to_tensor(seed)  # Assuming seed is a 1D tensor of token IDs\n",
        "input_ids = tf.expand_dims(input_ids, 0)  # Add an extra dimension to represent batch size\n",
        "\n",
        "if dump_seed:\n",
        "    midi = tokenizer.decode([seed])\n",
        "    midi.dump_midi(\"seed.mid\")\n",
        "\n",
        "# Generate continuation\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=256,  # Maximum length of generated sequence\n",
        "    num_return_sequences=1,  # Number of sequences to return\n",
        "    do_sample=True,  # Use sampling (True) or greedy decoding (False)\n",
        "    temperature=0.7  # Sampling temperature (lower is more conservative)\n",
        ")\n",
        "\n",
        "input_length = input_ids.shape[1]\n",
        "generated_tokens = outputs[:, input_length:] # skip seed\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated = tokenizer.decode([generated_tokens[0]])\n",
        "generated.dump_midi(\"nesgen-generation.mid\")"
      ],
      "metadata": {
        "id": "Z-QHjABf36-i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning with NesDB\n",
        "The purpose of the project is to generate music similar to that of the old NES console games.\n",
        "\n",
        "Consequently, it is necessary to perform fine tuning of the model trained on master using the NesDB dataset"
      ],
      "metadata": {
        "id": "lFZi9LcA_1XH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "TbvNoPNlB7u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1gIli7G1wu0QWDLzRc-CPWB8C4Hu0XVn3\n",
        "!unzip nesmdb_midi.zip\n",
        "!rm nesmdb_midi.zip"
      ],
      "metadata": {
        "id": "KZTGNGrN7pbn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "S7ummndsDUDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1ul-khIle1ue9oUGqb1Z7qHxk7LSuxrWw\n",
        "tokenizer = REMI(params=Path(\"nes_tokenizer.json\"))\n",
        "print(f\"Vocab size: {len(tokenizer)}\")"
      ],
      "metadata": {
        "id": "IPWjemgFDXAO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset"
      ],
      "metadata": {
        "id": "ejUZEMMjB-uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files\n",
        "!gdown 1iVwuKKT2sIezyVIDB9STL--FYZf0XcxF # train\n",
        "!gdown 1FoOC3x4GbdDe0fwlzE1Zs8fqZXyFQCIA # valid"
      ],
      "metadata": {
        "id": "R0RoGGijCCZs",
        "outputId": "4e230cb0-5bfd-441b-fe9d-6e2b3ebfc10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iVwuKKT2sIezyVIDB9STL--FYZf0XcxF\n",
            "From (redirected): https://drive.google.com/uc?id=1iVwuKKT2sIezyVIDB9STL--FYZf0XcxF&confirm=t&uuid=1b7227b9-72ac-4f1f-a68a-017b98a47dc4\n",
            "To: /content/all_ids_nes_train.txt\n",
            "100% 128M/128M [00:01<00:00, 90.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FoOC3x4GbdDe0fwlzE1Zs8fqZXyFQCIA\n",
            "To: /content/all_ids_nes_valid.txt\n",
            "100% 60.1M/60.1M [00:01<00:00, 41.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids_train = np.loadtxt(\"all_ids_nes_train.txt\").astype(np.int32)\n",
        "all_ids_valid = np.loadtxt(\"all_ids_nes_valid.txt\").astype(np.int32)"
      ],
      "metadata": {
        "id": "C2XOHhebCEeH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): perform split"
      ],
      "metadata": {
        "id": "1UwEgVWBCaak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  nesmdb_paths = list(Path(\"nesmdb_midi\").resolve().glob(\"**/*.mid\")) + list(Path(\"nesmdb_midi\").resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "  nesmdb_dir = \"nesmdb\"\n",
        "  os.makedirs(nesmdb_dir, exist_ok=True)\n",
        "\n",
        "  for i, midi_path in enumerate(nesmdb_paths):\n",
        "    new_midi_path = os.path.join(nesmdb_dir, f\"{i}.midi\")\n",
        "    shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "  nes_midis = list(Path(\"nesmdb\").resolve().glob(\"**/*.mid\")) + list(Path(\"nesmdb\").resolve().glob(\"**/*.midi\"))"
      ],
      "metadata": {
        "id": "1kjFnpzHA_Jw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  total_num_files = len(processed)\n",
        "\n",
        "  num_files_valid = round(total_num_files * 0.15)\n",
        "  shuffle(processed)\n",
        "  midi_paths_valid = processed[:num_files_valid]\n",
        "  midi_paths_train = processed[num_files_valid + num_files_test:]\n",
        "\n",
        "  # Chunk MIDIs and perform data augmentation on each subset independently\n",
        "  for files_paths, subset_name in (\n",
        "      (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\")\n",
        "  ):\n",
        "      print(files_paths[0])\n",
        "      # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
        "      subset_chunks_dir = Path(f\"Nesmdb_{subset_name}\")\n",
        "\n",
        "      split_files_for_training(\n",
        "          files_paths=files_paths,\n",
        "          tokenizer=tokenizer,\n",
        "          save_dir=subset_chunks_dir,\n",
        "          max_seq_len=1024,\n",
        "          num_overlap_bars=2,\n",
        "      )\n",
        "\n",
        "      # Perform data augmentation\n",
        "      augment_dataset(\n",
        "          subset_chunks_dir,\n",
        "          pitch_offsets=[-12, 12],\n",
        "          velocity_offsets=[-4, 4],\n",
        "          duration_offsets=[-0.5, 0.5],\n",
        "      )\n",
        "\n",
        "  midi_paths_train = list(Path(\"Nesmdb_train\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_train\").glob(\"**/*.midi\"))\n",
        "  midi_paths_valid = list(Path(\"Nesmdb_valid\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_valid\").glob(\"**/*.midi\"))\n"
      ],
      "metadata": {
        "id": "ywC0L1v5BagW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  def midi_valid(midi) -> bool:\n",
        "      if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "          return False  # time signature different from 4/*, 4 beats per bar\n",
        "      return True\n",
        "\n",
        "  if os.path.exists(\"tokenized_train\"):\n",
        "    shutil.rmtree(\"tokenized_train\")\n",
        "  if os.path.exists(\"tokenized_valid\"):\n",
        "    shutil.rmtree(\"tokenized_valid\")\n",
        "\n",
        "  for dir in (\"train\", \"valid\"):\n",
        "      tokenizer.tokenize_dataset(\n",
        "          Path(f\"Nesmdb_{dir}\"),\n",
        "          Path(f\"tokenized_{dir}\"),\n",
        "          midi_valid,\n",
        "      )"
      ],
      "metadata": {
        "id": "8Ku3b5IhBmwq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_train = read_json_files(tokenized_train)\n",
        "\n",
        "  tokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_valid = read_json_files(tokenized_valid)\n",
        "\n",
        "\n",
        "  if data_objects_train:\n",
        "      print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\n",
        "  else:\n",
        "      print(\"Error reading JSON files.\")"
      ],
      "metadata": {
        "id": "0tR-pOLTBv1D"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SPLIT_DATASET:\n",
        "  encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\n",
        "  encoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\n",
        "\n",
        "  all_ids_train = np.concatenate(encoded_train)\n",
        "  all_ids_valid = np.concatenate(encoded_valid)"
      ],
      "metadata": {
        "id": "b-zOTmjrB0PW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Tensorflow Dataset"
      ],
      "metadata": {
        "id": "efJeBiciCMpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\n",
        "ids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)"
      ],
      "metadata": {
        "id": "NVsDn3a2CLn0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert into sequences"
      ],
      "metadata": {
        "id": "dAwXclCVDyUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 1024\n",
        "\n",
        "sequences_train = ids_dataset_train.batch(SEQ_LENGTH+1, drop_remainder=True)\n",
        "sequences_valid = ids_dataset_valid.batch(SEQ_LENGTH+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "W-Qy2-A-Dxh4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing labels"
      ],
      "metadata": {
        "id": "sZJez9FEEAOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    # Convert to float32\n",
        "    input_seq = tf.cast(sequence[:-1], tf.int32)\n",
        "    target_seq = tf.cast(sequence[1:], tf.int32)\n",
        "    return input_seq, target_seq\n",
        "\n",
        "\n",
        "train_ds = sequences_train.map(split_input_target)\n",
        "valid_ds = sequences_valid.map(split_input_target)"
      ],
      "metadata": {
        "id": "hzAZItZcD6eE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating training batches"
      ],
      "metadata": {
        "id": "tRj4kNxnEFlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "valid_ds = (\n",
        "    valid_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "-YWJRLhxD-PI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the model"
      ],
      "metadata": {
        "id": "g1Ic7gH0EJYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1FfofRGCzuD6x54Q3mF2c_f50wuzbPp_i\n",
        "\n",
        "!unzip NESGEN_Nesmdb5.zip\n",
        "!rm -rf NESGEN_Nesmdb5.zip"
      ],
      "metadata": {
        "id": "ufz6VtpbEIa0",
        "outputId": "bd79d71a-ed38-4bca-8f6d-b7f795ffb8a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1FfofRGCzuD6x54Q3mF2c_f50wuzbPp_i\n",
            "From (redirected): https://drive.google.com/uc?id=1FfofRGCzuD6x54Q3mF2c_f50wuzbPp_i&confirm=t&uuid=cf7ddba4-54a1-4aba-abda-491db6223310\n",
            "To: /content/NESGEN_Nesmdb5.zip\n",
            "100% 184M/184M [00:04<00:00, 39.6MB/s]\n",
            "Archive:  NESGEN_Nesmdb5.zip\n",
            "   creating: nesgen_v1/\n",
            "  inflating: nesgen_v1/tf_model.h5   \n",
            "  inflating: nesgen_v1/config.json   \n",
            "  inflating: nesgen_v1/generation_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "AD8NTedeERrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForCausalLM\n",
        "model = TFAutoModelForCausalLM.from_pretrained(\"./nesgen-maestro0612\")\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=\"adam\",\n",
        "              weighted_metrics=[\"sparse_categorical_accuracy\"],\n",
        "              jit_compile=True,\n",
        "              )"
      ],
      "metadata": {
        "id": "A4DAbc3yES6R",
        "outputId": "4ea133ff-ff6b-47ab-9c46-0837a5a548e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMistralForCausalLM.\n",
            "\n",
            "All the layers of TFMistralForCausalLM were initialized from the model checkpoint at ./nesgen-maestro0612.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMistralForCausalLM for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "if TRAIN:\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=valid_ds,\n",
        "  )"
      ],
      "metadata": {
        "id": "wrue6Hn5EWct"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.from_pretrained(\"nesgen_v1\")"
      ],
      "metadata": {
        "id": "sWozgMHIICYa",
        "outputId": "0c39076f-ef17-4b83-a51e-c5c944790cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMistralForCausalLM.\n",
            "\n",
            "All the layers of TFMistralForCausalLM were initialized from the model checkpoint at nesgen_v1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMistralForCausalLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.models.mistral.modeling_tf_mistral.TFMistralForCausalLM at 0x7ce26545e350>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dump_seed = False\n",
        "\n",
        "seed = get_seed()\n",
        "input_ids = tf.convert_to_tensor(seed)  # Assuming seed is a 1D tensor of token IDs\n",
        "input_ids = tf.expand_dims(input_ids, 0)  # Add an extra dimension to represent batch size\n",
        "\n",
        "if dump_seed:\n",
        "    midi = tokenizer.decode([seed])\n",
        "    midi.dump_midi(\"seed.mid\")\n",
        "\n",
        "# Generate continuation\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=256,  # Maximum length of generated sequence\n",
        "    num_return_sequences=1,  # Number of sequences to return\n",
        "    do_sample=True,  # Use sampling (True) or greedy decoding (False)\n",
        "    temperature=0.7  # Sampling temperature (lower is more conservative)\n",
        ")\n",
        "\n",
        "input_length = input_ids.shape[1]\n",
        "generated_tokens = outputs[:, input_length:] # skip seed\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated = tokenizer.decode([generated_tokens[0]])\n",
        "generated.dump_midi(\"nesgen-nesdb-generation.mid\")"
      ],
      "metadata": {
        "id": "JbBB7k3qEjzO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DLc-Fi8Iyxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}