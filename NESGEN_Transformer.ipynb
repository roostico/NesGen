{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIDI music generation with Transformer\n",
        "\n",
        "In this notebook we'll be presenting various approaches for training a Transformer model that generates music in the form of MIDI (Musical Instrument Digital Interface) files.\n",
        "\n",
        "Notebook presented for the A.A. 2023/2024 Deep Learning project.\n",
        "\n",
        "Group members:\n",
        "\n",
        "- Valerio Di Zio - valerio.dizio@studio.unibo.it\n",
        "- Francesco Magnani - francesco.magnani14@studio.unibo.it\n",
        "- Luca Rubboli - mail@diluca.it"
      ],
      "metadata": {
        "id": "u00hbTlLk7VO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of libraries"
      ],
      "metadata": {
        "id": "KfCzH-Z5s5tO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-NyqFwak4dU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown\n",
        "!pip install pretty_midi\n",
        "!pip install miditok\n",
        "!pip install midi-clip\n",
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Download"
      ],
      "metadata": {
        "id": "I55SUO_ztKNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
        "!unzip \"maestro-v3.0.0-midi.zip\"\n",
        "!rm \"maestro-v3.0.0-midi.zip\"\n",
        "\n",
        "dataset_path = \"maestro-v3.0.0\""
      ],
      "metadata": {
        "id": "UHnI-Z7-tNag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Import of libraries and setup of downloaded files"
      ],
      "metadata": {
        "id": "bW6Z2multX0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from random import shuffle\n",
        "\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from miditok import REMI, TokenizerConfig\n",
        "from miditok.data_augmentation import augment_dataset\n",
        "from miditok.utils import split_files_for_training\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "z6V8GN03tk9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files of the dataset\n",
        "\n",
        "midi_paths = list(Path(dataset_path).resolve().glob(\"**/*.mid\")) + list(Path(dataset_path).resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.midi\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\")) + list(Path(\"midis\").resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "def sample():\n",
        "  return str(random.choice(midis))"
      ],
      "metadata": {
        "id": "upVam-gYtv-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "A tokenizer in the context of MIDI tokenization converts MIDI files into a sequence of **tokens** (e.g., integers or strings) that represent musical elements like notes, durations, velocities, and time shifts.\n",
        "\n",
        "The Miditok library provides predefined tokenization methods (e.g. **REMI**) to translate MIDI events into tokens and vice versa, ensuring a structured and efficient representation of musical data."
      ],
      "metadata": {
        "id": "GlCY3jLut44O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First approach to tokenization\n",
        "Tokenization is probably one of the most important steps in the process.\n",
        "\n",
        "For tokenization, in this specific example, a representation in the following form was used.\n",
        "\n",
        "note-duration\n",
        "\n",
        "Example: \"C4-1.0, C4-1.0, G4-1.0, G4-1.0, A4-1.0, A4-1.0, G4-2.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-1.0, D4-1.0, C4-2.0, G4-1.0, G4-1.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-2.0, G4-1.0, G4-1.0, F4-1.0, F4-1.0, E4-1.0, E4-1.0, D4-2.0\"\n",
        "\n",
        "This allows each token to be assigned, 1 note.\n",
        "\n",
        "A midi file, in fact, is much more complicated than this and by going about tokenizing differently, there is a risk of generating tokens that in sequence do not make sense.\n",
        "\n",
        "By going to restrict the model so that we get for each token 1 note we make subsequent training and generation easier.\n",
        "\n",
        "**This method unfortunately works worse than Miditok, consequently in this notebook Miditok will be used as the main tokenizer.**"
      ],
      "metadata": {
        "id": "OhgfVN3_-XMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRING_TOKENIZATION = False\n",
        "if STRING_TOKENIZATION:\n",
        "  def find_midi_files(directory):\n",
        "      \"\"\"Recursively finds all MIDI files in the directory.\"\"\"\n",
        "      midi_files = []\n",
        "      for root, _, files in os.walk(directory):\n",
        "          for file in files:\n",
        "              if file.endswith((\".mid\", \".midi\")):\n",
        "                  midi_files.append(os.path.join(root, file))\n",
        "      return midi_files\n",
        "\n",
        "  def midi_to_note_representation(file_path):\n",
        "      \"\"\"Converts a MIDI file into a note-duration representation.\"\"\"\n",
        "      try:\n",
        "          midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "          note_events = []\n",
        "\n",
        "          for instrument in midi_data.instruments:\n",
        "              for note in instrument.notes:\n",
        "                  # Convert pitch to note name\n",
        "                  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
        "                  duration = note.end - note.start\n",
        "                  note_events.append(f\"{note_name}-{duration:.1f}\")\n",
        "\n",
        "          return \", \".join(note_events)\n",
        "      except Exception as e:\n",
        "          print(f\"Error in file conversion {file_path}: {e}\")\n",
        "          return None\n",
        "\n",
        "  def create_dataset_from_midi(midi_files, output_file):\n",
        "      \"\"\"Creates a JSON dataset with the representation of notes from MIDI files.\"\"\"\n",
        "      dataset = {}\n",
        "\n",
        "      for midi_file in tqdm(midi_files):\n",
        "          note_representation = midi_to_note_representation(midi_file)\n",
        "          if note_representation:\n",
        "              dataset[midi_file] = note_representation\n",
        "\n",
        "      with open(output_file, \"w\") as json_file:\n",
        "          json.dump(dataset, json_file, indent=4)\n",
        "\n",
        "      print(f\"Dataset created and saved in {output_file}\")\n",
        "\n",
        "  output_dataset_file = \"midi_dataset.json\"\n",
        "\n",
        "  string_midis = [str(midi) for midi in midis]\n",
        "  create_dataset_from_midi(string_midis, output_dataset_file)\n",
        "\n",
        "  dataset_file = \"midi_dataset.json\"\n",
        "\n",
        "  with open(dataset_file, \"r\") as json_file:\n",
        "      dataset = json.load(json_file)\n",
        "      maestro_dataset = list(dataset.values())\n",
        "\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "  tokenizer = Tokenizer(filters=\"\", lower=False, split=\",\")\n",
        "  tokenizer.fit_on_texts(maestro_dataset)\n",
        "  tokenized_melodies = tokenizer.texts_to_sequences(maestro_dataset)"
      ],
      "metadata": {
        "id": "rcjhLsIt-WAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miditok Tokenization"
      ],
      "metadata": {
        "id": "IgkoM4Hg_rD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEAT_RES defines the temporal resolution for tokenizing MIDI events,\n",
        "# mapping beat intervals to the number of subdivisions per beat.\n",
        "BEAT_RES = {(0, 1): 12, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n",
        "\n",
        "TOKENIZER_PARAMS = {\n",
        "    \"pitch_range\": (21, 109),\n",
        "    \"beat_res\": BEAT_RES,\n",
        "    \"num_velocities\": 24,\n",
        "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n",
        "    \"use_chords\": True,\n",
        "    \"use_rests\": True,\n",
        "    \"use_tempos\": True,\n",
        "    \"use_time_signatures\": True,\n",
        "    \"use_programs\": False,  # no multitrack\n",
        "    \"num_tempos\": 32,\n",
        "    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n",
        "}\n",
        "\n",
        "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
        "\n",
        "tokenizer = REMI(config)"
      ],
      "metadata": {
        "id": "40PhMXS6uXME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a trained tokenizer"
      ],
      "metadata": {
        "id": "5qLDUEVuvjJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1SDRkoWwyuSl4udoCHdcitjLLm9d0kfxS\n",
        "tokenizer = REMI(params=Path(\"maestro_tokenizer.json\"))\n",
        "print(f\"Vocab size: {len(tokenizer)}\")"
      ],
      "metadata": {
        "id": "qloz4kvDvmQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): train the tokenizer\n",
        "This cell is optional because the tokenizer train is long, consequently as a matter of time it is skipped in favor of the previous cell that imports the already trained tokenizer"
      ],
      "metadata": {
        "id": "juVWqNWivsO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Manually train the tokenizer\n",
        "TRAIN_TOKENIZER = False # @param { type: 'boolean' }"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HtrErkuCRDeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN_TOKENIZER:\n",
        "  tokenizer.train(vocab_size=30000, files_paths=midis)\n",
        "  processed = [Path(f\"{s}\") for s in midis]\n",
        "  print(len(processed))"
      ],
      "metadata": {
        "id": "xN1YBCa_vqnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset\n",
        "Divide the Maestro dataset into Train, Valid and Test by also performing data augmentation"
      ],
      "metadata": {
        "id": "o5zPO14qxr7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1IQToXD9s8g4L-AlK-MY4qvGoLZ-p7bMw\n",
        "!gdown 1DWjViUKpW07LfbGimlhhhGdK7oQaJpj-\n",
        "\n",
        "all_ids_train = np.loadtxt(\"all_ids_maestro_train.txt\").astype(np.int32)\n",
        "all_ids_valid = np.loadtxt(\"all_ids_maestro_valid.txt\").astype(np.int32)"
      ],
      "metadata": {
        "id": "91VCDP68x8jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### (Optional): skip all the data preparation\n",
        "SKIP_DATA_PREPARATION = True # @param { type: 'boolean' }"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ua0tda06Qu5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "\n",
        "  total_num_files = len(processed)\n",
        "  num_files_valid = round(total_num_files * 0.15)\n",
        "  num_files_test = round(total_num_files * 0.15)\n",
        "  shuffle(processed)\n",
        "  midi_paths_valid = processed[:num_files_valid]\n",
        "  midi_paths_test = processed[num_files_valid:num_files_valid + num_files_test]\n",
        "  midi_paths_train = processed[num_files_valid + num_files_test:]\n",
        "\n",
        "  # Chunk MIDIs and perform data augmentation on each subset independently\n",
        "\n",
        "  for files_paths, subset_name in (\n",
        "      (midi_paths_train, \"train\"),\n",
        "      (midi_paths_valid, \"valid\"),\n",
        "        (midi_paths_test, \"test\")\n",
        "  ):\n",
        "      # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
        "      subset_chunks_dir = Path(f\"Maestro_{subset_name}\")\n",
        "\n",
        "      split_files_for_training(\n",
        "          files_paths=files_paths,\n",
        "          tokenizer=tokenizer,\n",
        "          save_dir=subset_chunks_dir,\n",
        "          max_seq_len=1024,\n",
        "          num_overlap_bars=2,\n",
        "      )\n",
        "\n",
        "      # Perform data augmentation\n",
        "      augment_dataset(\n",
        "          subset_chunks_dir,\n",
        "          pitch_offsets=[-12, 12],\n",
        "          velocity_offsets=[-4, 4],\n",
        "          duration_offsets=[-0.5, 0.5],\n",
        "      )\n",
        "  midi_paths_train = list(Path(\"Maestro_train\").glob(\"**/*.mid\")) + list(Path(\"Maestro_train\").glob(\"**/*.midi\"))\n",
        "  midi_paths_valid = list(Path(\"Maestro_valid\").glob(\"**/*.mid\")) + list(Path(\"Maestro_valid\").glob(\"**/*.midi\"))\n",
        "  midi_paths_test = list(Path(\"Maestro_test\").glob(\"**/*.mid\")) + list(Path(\"Maestro_test\").glob(\"**/*.midi\"))\n"
      ],
      "metadata": {
        "id": "sm6iZq4uxhKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  def midi_valid(midi) -> bool:\n",
        "      if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "          return False  # time signature different from 4/*, 4 beats per bar\n",
        "      return True\n",
        "\n",
        "  if os.path.exists(\"tokenized\"):\n",
        "    shutil.rmtree(\"tokenized\")\n",
        "\n",
        "  for dir in (\"train\", \"valid\", \"test\"):\n",
        "      tokenizer.tokenize_dataset(\n",
        "          Path(f\"Maestro_{dir}\").resolve(),\n",
        "          Path(f\"tokenized_{dir}\").resolve(),\n",
        "          midi_valid,\n",
        "      )"
      ],
      "metadata": {
        "id": "BfuMgF_syIB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  def read_json(path: str) -> dict:\n",
        "    with open(path, \"r\") as f:\n",
        "      return json.load(f)\n",
        "\n",
        "  def read_json_files(json_file_paths):\n",
        "      \"\"\"Reads a list of JSON files and returns a list of objects.\n",
        "      Args:\n",
        "          json_file_paths: A list of file paths to JSON files.\n",
        "      Returns:\n",
        "          A list of objects, where each object represents the data from a JSON file.\n",
        "          Returns an empty list if any error occurs during file processing.\n",
        "      \"\"\"\n",
        "      objects = []\n",
        "\n",
        "      for file_path in tqdm(json_file_paths):\n",
        "          try:\n",
        "              objects.append(read_json(file_path))\n",
        "          except FileNotFoundError:\n",
        "              print(f\"Error: File not found - {file_path}\")\n",
        "              return [] # Return empty list on error\n",
        "          except json.JSONDecodeError:\n",
        "              print(f\"Error decoding JSON in file: {file_path}\")\n",
        "              return [] # Return empty list on error\n",
        "      return objects"
      ],
      "metadata": {
        "id": "8Csa3vMqyWs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_train = read_json_files(tokenized_train)\n",
        "\n",
        "  tokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_valid = read_json_files(tokenized_valid)\n",
        "\n",
        "  tokenized_test = list(Path(\"tokenized_test\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_test = read_json_files(tokenized_test)\n",
        "\n",
        "\n",
        "  if data_objects_train:\n",
        "      print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\n",
        "  else:\n",
        "      print(\"Error reading JSON files.\")"
      ],
      "metadata": {
        "id": "NFZMxxc1z-H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\n",
        "  encoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\n",
        "  encoded_test = [np.array(song[\"ids\"][0]) for song in data_objects_test]\n",
        "\n",
        "  all_ids_train = np.concatenate(encoded_train)\n",
        "  all_ids_valid = np.concatenate(encoded_valid)\n",
        "  all_ids_test = np.concatenate(encoded_test)"
      ],
      "metadata": {
        "id": "S9OWP1BO0BjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tensorflow Dataset"
      ],
      "metadata": {
        "id": "5sULb9Yg0PGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\n",
        "ids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)"
      ],
      "metadata": {
        "id": "lg-t03RY0NxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert into sequences"
      ],
      "metadata": {
        "id": "btOrQBpw0lnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 1024\n",
        "\n",
        "sequences_train = ids_dataset_train.batch(SEQ_LENGTH+1, drop_remainder=True)\n",
        "sequences_valid = ids_dataset_valid.batch(SEQ_LENGTH+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "_s_7NJhs0jl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing labels"
      ],
      "metadata": {
        "id": "_BgCctUj0v4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    # Convert to float32\n",
        "    input_seq = tf.cast(sequence[:-1], tf.int32)\n",
        "    target_seq = tf.cast(sequence[1:], tf.int32)\n",
        "    return input_seq, target_seq\n",
        "\n",
        "\n",
        "train_ds = sequences_train.map(split_input_target)\n",
        "valid_ds = sequences_valid.map(split_input_target)"
      ],
      "metadata": {
        "id": "2Gtbw2330yTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create training batches\n",
        "Buffer size to shuffle the dataset\n",
        "(TF data is designed to work with possibly infinite sequences, so it doesn't attempt to shuffle the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements)."
      ],
      "metadata": {
        "id": "piszzuBy03qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "valid_ds = (\n",
        "    valid_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "xwJsixAK0-5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model"
      ],
      "metadata": {
        "id": "LM9y_1cb15gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForCausalLM, MistralConfig\n",
        "\n",
        "# Define the model configuration\n",
        "model_config = MistralConfig(\n",
        "    vocab_size=len(tokenizer),\n",
        "    hidden_size=512,\n",
        "    intermediate_size=1024,\n",
        "    num_hidden_layers=8,\n",
        "    num_attention_heads=8,\n",
        "    num_key_value_heads=4,\n",
        "    sliding_window=256,\n",
        "    max_position_embeddings=8192,\n",
        "    pad_token_id=tokenizer['PAD_None'],\n",
        "    bos_token_id=tokenizer['BOS_None'],\n",
        "    eos_token_id=tokenizer['EOS_None'],\n",
        ")\n",
        "\n",
        "# Initialize the TensorFlow model\n",
        "model = TFAutoModelForCausalLM.from_config(model_config)\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=\"adam\",\n",
        "              weighted_metrics=[\"sparse_categorical_accuracy\"],\n",
        "              jit_compile=True,\n",
        "              )"
      ],
      "metadata": {
        "id": "2RJveLYx1-MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "4hx8o0IS26QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1qoTIkmhmj0z4854FFofz02KLk5DnyqB1\n",
        "!unzip NESGEN_Maestro15.zip\n",
        "\n",
        "model.from_pretrained(\"nesgen-maestro0612\")"
      ],
      "metadata": {
        "id": "xLU0o0qo3FT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): Train model\n",
        "Training of this model is made optional, free colab does not allow for this training."
      ],
      "metadata": {
        "id": "fgYg8Jx43cF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = False\n",
        "if TRAIN:\n",
        "  EPOCHS = 15\n",
        "\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=valid_ds,\n",
        "  )"
      ],
      "metadata": {
        "id": "-uRSJ2Ci2RNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "ccD0NCuj3VAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a seed from the test set"
      ],
      "metadata": {
        "id": "5J6ZmFEb3xXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seed():\n",
        "    for seed_ids, _ in valid_ds.take(1):\n",
        "      seed = seed_ids\n",
        "    return seed[0]"
      ],
      "metadata": {
        "id": "RS4h5gPO3XDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and dump MIDI\n"
      ],
      "metadata": {
        "id": "rD4SVzUg34fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dump_seed = False\n",
        "\n",
        "seed = get_seed()\n",
        "input_ids = tf.convert_to_tensor(seed)  # Assuming seed is a 1D tensor of token IDs\n",
        "input_ids = tf.expand_dims(input_ids, 0)  # Add an extra dimension to represent batch size\n",
        "\n",
        "if dump_seed:\n",
        "    midi = tokenizer.decode([seed])\n",
        "    midi.dump_midi(\"seed.mid\")\n",
        "\n",
        "# Generate continuation\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=256,  # Maximum length of generated sequence\n",
        "    num_return_sequences=1,  # Number of sequences to return\n",
        "    do_sample=True,  # Use sampling (True) or greedy decoding (False)\n",
        "    temperature=0.7  # Sampling temperature (lower is more conservative)\n",
        ")\n",
        "\n",
        "input_length = input_ids.shape[1]\n",
        "generated_tokens = outputs[:, input_length:] # skip seed\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated = tokenizer.decode([generated_tokens[0]])\n",
        "generated.dump_midi(\"nesgen-generation.mid\")"
      ],
      "metadata": {
        "id": "Z-QHjABf36-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning with NesDB\n",
        "The purpose of the project is to generate music similar to that of the old NES console games.\n",
        "\n",
        "Consequently, it is necessary to perform fine tuning of the model trained on master using the NesDB dataset"
      ],
      "metadata": {
        "id": "lFZi9LcA_1XH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "TbvNoPNlB7u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1gIli7G1wu0QWDLzRc-CPWB8C4Hu0XVn3\n",
        "!unzip nesmdb_midi.zip\n",
        "!rm nesmdb_midi.zip"
      ],
      "metadata": {
        "id": "KZTGNGrN7pbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "S7ummndsDUDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1ul-khIle1ue9oUGqb1Z7qHxk7LSuxrWw\n",
        "tokenizer = REMI(params=Path(\"nes_tokenizer.json\"))\n",
        "print(f\"Vocab size: {len(tokenizer)}\")"
      ],
      "metadata": {
        "id": "IPWjemgFDXAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "ejUZEMMjB-uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files\n",
        "!gdown 1iVwuKKT2sIezyVIDB9STL--FYZf0XcxF # train\n",
        "!gdown 1FoOC3x4GbdDe0fwlzE1Zs8fqZXyFQCIA # valid"
      ],
      "metadata": {
        "id": "R0RoGGijCCZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids_train = np.loadtxt(\"all_ids_nes_train.txt\").astype(np.int32)\n",
        "all_ids_valid = np.loadtxt(\"all_ids_nes_valid.txt\").astype(np.int32)"
      ],
      "metadata": {
        "id": "C2XOHhebCEeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional): complete data preparation"
      ],
      "metadata": {
        "id": "1UwEgVWBCaak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  nesmdb_paths = list(Path(\"nesmdb_midi\").resolve().glob(\"**/*.mid\")) + list(Path(\"nesmdb_midi\").resolve().glob(\"**/*.midi\"))\n",
        "\n",
        "  nesmdb_dir = \"nesmdb\"\n",
        "  os.makedirs(nesmdb_dir, exist_ok=True)\n",
        "\n",
        "  for i, midi_path in enumerate(nesmdb_paths):\n",
        "    new_midi_path = os.path.join(nesmdb_dir, f\"{i}.midi\")\n",
        "    shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "  nes_midis = list(Path(\"nesmdb\").resolve().glob(\"**/*.mid\")) + list(Path(\"nesmdb\").resolve().glob(\"**/*.midi\"))\n",
        "  string_midis = [str(midi) for midi in nes_midis]"
      ],
      "metadata": {
        "id": "1kjFnpzHA_Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filter short pieces"
      ],
      "metadata": {
        "id": "0j5VhARILBvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  min_length_seconds = 30\n",
        "\n",
        "  def transform(file: str) -> pretty_midi.PrettyMIDI:\n",
        "    try:\n",
        "      midi = pretty_midi.PrettyMIDI(file)\n",
        "      if midi.get_end_time() < min_length_seconds:\n",
        "        return None\n",
        "      return file\n",
        "    except Exception as e:\n",
        "      print(f\"There was an error: {e}\")\n",
        "      return None\n",
        "\n",
        "  pretty_midis = list([x for x in tqdm(map(transform, string_midis)) if x is not None])\n",
        "  print(f\"Discarded {len(string_midis) - len(pretty_midis)} files\")"
      ],
      "metadata": {
        "id": "Gfs3j_MXK0gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MIDI cleaning"
      ],
      "metadata": {
        "id": "vhVubVrKLh-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  TRACK_MIN_DENSITY_PERC = 0.20\n",
        "  MIN_VELOCITY = 20\n",
        "  MIN_NOTE_LENGTH = 0.05  # Minimum note length in seconds, adjust as needed\n",
        "  VALID_TIME_UNIT = 0.1   # Notes will be adjusted to this multiple\n",
        "\n",
        "  def is_excluded(track_name):\n",
        "      \"\"\"\n",
        "      Exclusion criteria for MIDI tracks\n",
        "      \"\"\"\n",
        "      exclude_keywords = [\"drum\", \"effect\", \"percussion\", \"no\", \"tr\"]\n",
        "      return any(keyword.lower() in track_name.lower() for keyword in exclude_keywords)\n",
        "\n",
        "  def round_to_unit(value, unit):\n",
        "      \"\"\"\n",
        "      Rounds a value to the nearest multiple of a given unit.\n",
        "      \"\"\"\n",
        "      return round(value / unit) * unit\n",
        "\n",
        "  def merge_tracks_to_single_instrument(input_file, output_file, target_channel=0):\n",
        "      midi_data = pretty_midi.PrettyMIDI(input_file)\n",
        "      merged_midi = pretty_midi.PrettyMIDI()\n",
        "      merged_instrument = pretty_midi.Instrument(\n",
        "          program=pretty_midi.instrument_name_to_program('Acoustic Grand Piano'), is_drum=False\n",
        "      )\n",
        "\n",
        "      mean_notes = sum(len(instrument.notes) for instrument in midi_data.instruments) / len(midi_data.instruments)\n",
        "\n",
        "      for instrument in midi_data.instruments:\n",
        "          track_name = instrument.name\n",
        "\n",
        "          # Exclude drum instruments or effect instruments\n",
        "          if instrument.is_drum or is_excluded(track_name):\n",
        "              print(\"Excluding track: \", track_name)\n",
        "              continue\n",
        "\n",
        "          # Exclude instruments that have a low number of notes\n",
        "          if len(instrument.notes) / mean_notes < TRACK_MIN_DENSITY_PERC:\n",
        "              continue\n",
        "\n",
        "          for note in instrument.notes:\n",
        "              # Adjust note duration if it's too short\n",
        "              note_duration = note.end - note.start\n",
        "              if note_duration < MIN_NOTE_LENGTH:\n",
        "                  continue\n",
        "\n",
        "              # Optionally round to a valid time unit\n",
        "              note.end = round_to_unit(note.end, VALID_TIME_UNIT)\n",
        "\n",
        "              # Enforce minimum velocity\n",
        "              note.velocity = max(note.velocity, MIN_VELOCITY)\n",
        "              merged_instrument.notes.append(note)\n",
        "\n",
        "      # Sort notes by start time\n",
        "      merged_instrument.notes.sort(key=lambda note: note.start)\n",
        "      merged_midi.instruments.append(merged_instrument)\n",
        "\n",
        "      # Transfer tempo changes\n",
        "      tempo_times, tempi = midi_data.get_tempo_changes()\n",
        "      for time, tempo in zip(tempo_times, tempi):\n",
        "          # Add tempo changes using PrettyMIDI's built-in API\n",
        "          merged_midi.estimate_tempo()  # Automatically calculates and sets tempo\n",
        "\n",
        "      # Copy time and key signatures\n",
        "      merged_midi.time_signature_changes = midi_data.time_signature_changes\n",
        "      merged_midi.key_signature_changes = midi_data.key_signature_changes\n",
        "\n",
        "      # Write the merged MIDI file\n",
        "      merged_midi.write(output_file)\n",
        "\n",
        "  os.makedirs(\"pre-processed\")\n",
        "\n",
        "  for file in tqdm(pretty_midis):\n",
        "    try:\n",
        "      merge_tracks_to_single_instrument(file, f\"pre-processed/{os.path.basename(file)}\")\n",
        "    except Exception as e:\n",
        "      print(f\"There was an error: {e}\")\n",
        "      continue\n",
        "\n",
        "  processed = list(Path(\"pre-processed\").resolve().glob(\"**/*.mid\")) + list(Path(\"pre-processed\").resolve().glob(\"**/*.midi\"))"
      ],
      "metadata": {
        "id": "bpGBO-gULk-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  total_num_files = len(processed)\n",
        "\n",
        "  num_files_valid = round(total_num_files * 0.15)\n",
        "  shuffle(processed)\n",
        "  midi_paths_valid = processed[:num_files_valid]\n",
        "  midi_paths_train = processed[num_files_valid + num_files_test:]\n",
        "\n",
        "  # Chunk MIDIs and perform data augmentation on each subset independently\n",
        "  for files_paths, subset_name in (\n",
        "      (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\")\n",
        "  ):\n",
        "      # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
        "      subset_chunks_dir = Path(f\"Nesmdb_{subset_name}\")\n",
        "\n",
        "      split_files_for_training(\n",
        "          files_paths=files_paths,\n",
        "          tokenizer=tokenizer,\n",
        "          save_dir=subset_chunks_dir,\n",
        "          max_seq_len=1024,\n",
        "          num_overlap_bars=2,\n",
        "      )\n",
        "\n",
        "      # Perform data augmentation\n",
        "      augment_dataset(\n",
        "          subset_chunks_dir,\n",
        "          pitch_offsets=[-12, 12],\n",
        "          velocity_offsets=[-4, 4],\n",
        "          duration_offsets=[-0.5, 0.5],\n",
        "      )\n",
        "\n",
        "  midi_paths_train = list(Path(\"Nesmdb_train\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_train\").glob(\"**/*.midi\"))\n",
        "  midi_paths_valid = list(Path(\"Nesmdb_valid\").glob(\"**/*.mid\")) + list(Path(\"Nesmdb_valid\").glob(\"**/*.midi\"))\n"
      ],
      "metadata": {
        "id": "ywC0L1v5BagW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  def midi_valid(midi) -> bool:\n",
        "      if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "          return False  # time signature different from 4/*, 4 beats per bar\n",
        "      return True\n",
        "\n",
        "  if os.path.exists(\"tokenized_train\"):\n",
        "    shutil.rmtree(\"tokenized_train\")\n",
        "  if os.path.exists(\"tokenized_valid\"):\n",
        "    shutil.rmtree(\"tokenized_valid\")\n",
        "\n",
        "  for dir in (\"train\", \"valid\"):\n",
        "      tokenizer.tokenize_dataset(\n",
        "          Path(f\"Nesmdb_{dir}\").resolve(),\n",
        "          Path(f\"tokenized_{dir}\").resolve(),\n",
        "          midi_valid,\n",
        "      )"
      ],
      "metadata": {
        "id": "8Ku3b5IhBmwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_train = read_json_files(tokenized_train)\n",
        "\n",
        "  tokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\n",
        "  data_objects_valid = read_json_files(tokenized_valid)\n",
        "\n",
        "\n",
        "  if data_objects_train:\n",
        "      print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\n",
        "  else:\n",
        "      print(\"Error reading JSON files.\")"
      ],
      "metadata": {
        "id": "0tR-pOLTBv1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not SKIP_DATA_PREPARATION:\n",
        "  encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\n",
        "  encoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]\n",
        "\n",
        "  all_ids_train = np.concatenate(encoded_train)\n",
        "  all_ids_valid = np.concatenate(encoded_valid)"
      ],
      "metadata": {
        "id": "b-zOTmjrB0PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Tensorflow Dataset"
      ],
      "metadata": {
        "id": "efJeBiciCMpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset_train = tf.data.Dataset.from_tensor_slices(all_ids_train)\n",
        "ids_dataset_valid = tf.data.Dataset.from_tensor_slices(all_ids_valid)"
      ],
      "metadata": {
        "id": "NVsDn3a2CLn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert into sequences"
      ],
      "metadata": {
        "id": "dAwXclCVDyUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 1024\n",
        "\n",
        "sequences_train = ids_dataset_train.batch(SEQ_LENGTH+1, drop_remainder=True)\n",
        "sequences_valid = ids_dataset_valid.batch(SEQ_LENGTH+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "W-Qy2-A-Dxh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing labels"
      ],
      "metadata": {
        "id": "sZJez9FEEAOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    # Convert to float32\n",
        "    input_seq = tf.cast(sequence[:-1], tf.int32)\n",
        "    target_seq = tf.cast(sequence[1:], tf.int32)\n",
        "    return input_seq, target_seq\n",
        "\n",
        "\n",
        "train_ds = sequences_train.map(split_input_target)\n",
        "valid_ds = sequences_valid.map(split_input_target)"
      ],
      "metadata": {
        "id": "hzAZItZcD6eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating training batches"
      ],
      "metadata": {
        "id": "tRj4kNxnEFlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "valid_ds = (\n",
        "    valid_ds\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "-YWJRLhxD-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the model"
      ],
      "metadata": {
        "id": "g1Ic7gH0EJYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1FfofRGCzuD6x54Q3mF2c_f50wuzbPp_i\n",
        "\n",
        "!unzip NESGEN_Nesmdb5.zip\n",
        "!rm -rf NESGEN_Nesmdb5.zip"
      ],
      "metadata": {
        "id": "ufz6VtpbEIa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "AD8NTedeERrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForCausalLM\n",
        "model = TFAutoModelForCausalLM.from_pretrained(\"./nesgen-maestro0612\")\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=\"adam\",\n",
        "              weighted_metrics=[\"sparse_categorical_accuracy\"],\n",
        "              jit_compile=True,\n",
        "              )"
      ],
      "metadata": {
        "id": "A4DAbc3yES6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "if TRAIN:\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=valid_ds,\n",
        "  )"
      ],
      "metadata": {
        "id": "wrue6Hn5EWct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.from_pretrained(\"nesgen_v1\")"
      ],
      "metadata": {
        "id": "sWozgMHIICYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump_seed = False\n",
        "\n",
        "seed = get_seed()\n",
        "input_ids = tf.convert_to_tensor(seed)  # Assuming seed is a 1D tensor of token IDs\n",
        "input_ids = tf.expand_dims(input_ids, 0)  # Add an extra dimension to represent batch size\n",
        "\n",
        "if dump_seed:\n",
        "    midi = tokenizer.decode([seed])\n",
        "    midi.dump_midi(\"seed.mid\")\n",
        "\n",
        "# Generate continuation\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=256,  # Maximum length of generated sequence\n",
        "    num_return_sequences=1,  # Number of sequences to return\n",
        "    do_sample=True,  # Use sampling (True) or greedy decoding (False)\n",
        "    temperature=0.7  # Sampling temperature (lower is more conservative)\n",
        ")\n",
        "\n",
        "input_length = input_ids.shape[1]\n",
        "generated_tokens = outputs[:, input_length:] # skip seed\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated = tokenizer.decode([generated_tokens[0]])\n",
        "generated.dump_midi(\"nesgen-nesdb-generation.mid\")"
      ],
      "metadata": {
        "id": "JbBB7k3qEjzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DLc-Fi8Iyxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}