{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pretty_midi","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-19T10:15:58.669675Z","iopub.execute_input":"2024-12-19T10:15:58.670050Z","iopub.status.idle":"2024-12-19T10:16:10.371520Z","shell.execute_reply.started":"2024-12-19T10:15:58.670016Z","shell.execute_reply":"2024-12-19T10:16:10.370578Z"}},"outputs":[{"name":"stdout","text":"Collecting pretty_midi\n  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from pretty_midi) (1.26.4)\nCollecting mido>=1.1.16 (from pretty_midi)\n  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pretty_midi) (1.16.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mido>=1.1.16->pretty_midi) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mido>=1.1.16->pretty_midi) (3.1.2)\nDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pretty_midi\n  Building wheel for pretty_midi (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592292 sha256=92840beaa26db41089b69bf6490dd347a8fbb8d6b6ad8690d4b800049a7c07e0\n  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\nSuccessfully built pretty_midi\nInstalling collected packages: mido, pretty_midi\nSuccessfully installed mido-1.3.3 pretty_midi-0.2.10\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install gdown\n!pip install miditok\n!pip install midi-clip\n\n!wget https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/utility.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T10:16:40.053209Z","iopub.execute_input":"2024-12-19T10:16:40.054003Z","iopub.status.idle":"2024-12-19T10:17:06.025421Z","shell.execute_reply.started":"2024-12-19T10:16:40.053970Z","shell.execute_reply":"2024-12-19T10:17:06.024337Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.6.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nCollecting miditok\n  Using cached miditok-3.0.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from miditok) (0.26.2)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from miditok) (1.26.4)\nCollecting symusic>=0.5.0 (from miditok)\n  Using cached symusic-0.5.5-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: tokenizers>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from miditok) (0.20.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from miditok) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (4.12.2)\nCollecting pySmartDL (from symusic>=0.5.0->miditok)\n  Using cached pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from symusic>=0.5.0->miditok) (3.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.16.4->miditok) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (2024.6.2)\nUsing cached miditok-3.0.4-py3-none-any.whl (157 kB)\nUsing cached symusic-0.5.5-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\nUsing cached pySmartDL-1.3.4-py3-none-any.whl (20 kB)\nInstalling collected packages: pySmartDL, symusic, miditok\nSuccessfully installed miditok-3.0.4 pySmartDL-1.3.4 symusic-0.5.5\nRequirement already satisfied: midi-clip in /opt/conda/lib/python3.10/site-packages (0.10)\nRequirement already satisfied: mido in /opt/conda/lib/python3.10/site-packages (from midi-clip) (1.3.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mido->midi-clip) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mido->midi-clip) (3.1.2)\n--2024-12-19 10:17:05--  https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/utility.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3697 (3.6K) [text/plain]\nSaving to: 'utility.py.1'\n\nutility.py.1        100%[===================>]   3.61K  --.-KB/s    in 0s      \n\n2024-12-19 10:17:05 (51.1 MB/s) - 'utility.py.1' saved [3697/3697]\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport glob\n\nimport os\nimport random\nimport shutil\nfrom pathlib import Path\nimport pretty_midi\nimport numpy as np\nfrom miditok import REMI, TokenizerConfig\nimport json\nfrom miditok.utils import split_files_for_training\nfrom miditok.data_augmentation import augment_dataset\nfrom random import shuffle\nfrom tqdm import tqdm\n\nimport sys\nimport pickle\n     ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-19T10:17:06.027832Z","iopub.execute_input":"2024-12-19T10:17:06.028657Z","iopub.status.idle":"2024-12-19T10:17:06.586492Z","shell.execute_reply.started":"2024-12-19T10:17:06.028627Z","shell.execute_reply":"2024-12-19T10:17:06.585759Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Get Maestro Dataset\n!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n!unzip 'maestro-v3.0.0-midi.zip'\n!rm 'maestro-v3.0.0-midi.zip'\ndataset_path = \"/kaggle/working/maestro-v3.0.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T10:16:32.898317Z","iopub.status.idle":"2024-12-19T10:16:32.898595Z","shell.execute_reply.started":"2024-12-19T10:16:32.898458Z","shell.execute_reply":"2024-12-19T10:16:32.898472Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to the files of the dataset\n\nmidi_paths = list(Path(dataset_path).resolve().glob(\"**/*.mid\")) + list(Path(dataset_path).resolve().glob(\"**/*.midi\"))\n\nmidis_dir = \"midis\"\nos.makedirs(midis_dir, exist_ok=True)\n\n\nfor i, midi_path in enumerate(midi_paths):\n  new_midi_path = os.path.join(midis_dir, f\"{i}.midi\")\n  shutil.move(str(midi_path), new_midi_path)\n\n\nmidis = list(Path(\"/kaggle/working/midis\").resolve().glob(\"**/*.mid\")) + list(Path(\"/kaggle/working/midis\").resolve().glob(\"**/*.midi\"))\n\ndef sample():\n  return str(random.choice(midis))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.590598Z","iopub.execute_input":"2024-12-18T16:08:35.590978Z","iopub.status.idle":"2024-12-18T16:08:35.647458Z","shell.execute_reply.started":"2024-12-18T16:08:35.590943Z","shell.execute_reply":"2024-12-18T16:08:35.646007Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Paths to the files of the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m midi_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(Path(\u001b[43mdataset_path\u001b[49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*.mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(Path(dataset_path)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*.midi\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m midis_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(midis_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_path' is not defined"],"ename":"NameError","evalue":"name 'dataset_path' is not defined","output_type":"error"}],"execution_count":49},{"cell_type":"code","source":"BEAT_RES = {(0, 1): 12, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n\nTOKENIZER_PARAMS = {\n    \"pitch_range\": (21, 109),\n    \"beat_res\": BEAT_RES,\n    \"num_velocities\": 6,\n    \"special_tokens\": [\"BOS\", \"EOS\"],\n    \"use_chords\": True,\n    \"use_rests\": True,\n    \"use_tempos\": True,\n    \"num_tempos\": 8,\n    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo),\n}\n\nconfig = TokenizerConfig(**TOKENIZER_PARAMS)\n\ntokenizer = REMI(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.648165Z","iopub.status.idle":"2024-12-18T16:08:35.648461Z","shell.execute_reply.started":"2024-12-18T16:08:35.648312Z","shell.execute_reply":"2024-12-18T16:08:35.648334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_size = 1000\ntokenizer.train(vocab_size=vocab_size, files_paths=midis)\nprocessed = [Path(f\"{s}\") for s in midis]\nprint(len(processed))\n\nvalid_perc = 0.05\naugment = False\n\ntotal_num_files = len(processed)\nnum_files_valid = round(total_num_files * valid_perc)\nshuffle(processed)\nmidi_paths_valid = processed[:num_files_valid]\nmidi_paths_train = processed[num_files_valid:]\n\n# Chunk MIDIs and perform data augmentation on each subset independently\n\nfor files_paths, subset_name in (\n    (midi_paths_train, \"train\"),\n    (midi_paths_valid, \"valid\"),\n):\n    print(files_paths[0])\n\n    # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n\n    subset_chunks_dir = Path(f\"Maestro_{subset_name}\")\n\n    split_files_for_training(\n        files_paths=files_paths,\n        tokenizer=tokenizer,\n        save_dir=subset_chunks_dir,\n        max_seq_len=1024,\n        num_overlap_bars=2,\n    )\n\n    # Perform data augmentation\n    if augment:\n        augment_dataset(\n            subset_chunks_dir,\n            pitch_offsets=[-12, 12],\n            velocity_offsets=[-3, 3],\n            duration_offsets=[-0.5, 0.5],\n        )\n\nmidi_paths_train = list(Path(\"Maestro_train\").glob(\"**/*.mid\")) + list(Path(\"Maestro_train\").glob(\"**/*.midi\"))\nmidi_paths_valid = list(Path(\"Maestro_valid\").glob(\"**/*.mid\")) + list(Path(\"Maestro_valid\").glob(\"**/*.midi\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.649253Z","iopub.status.idle":"2024-12-18T16:08:35.649599Z","shell.execute_reply.started":"2024-12-18T16:08:35.649418Z","shell.execute_reply":"2024-12-18T16:08:35.649434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def midi_valid(midi) -> bool:\n\n    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n\n        return False  # time signature different from 4/*, 4 beats per bar\n\n    return True\n\n\n\nif os.path.exists(\"tokenized\"):\n\n  shutil.rmtree(\"tokenized\")\n\n\nfor dir in (\"train\", \"valid\"):\n    tokenizer.tokenize_dataset(        \n    \n        Path(f\"/kaggle/working/Maestro_{dir}\"),\n        Path(f\"/kaggle/working/tokenized_{dir}\"),\n        midi_valid,\n    \n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.651276Z","iopub.status.idle":"2024-12-18T16:08:35.651590Z","shell.execute_reply.started":"2024-12-18T16:08:35.651440Z","shell.execute_reply":"2024-12-18T16:08:35.651457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_json(path: str) -> dict:\n\n  with open(path, \"r\") as f:\n\n    return json.load(f)\n\ndef read_json_files(json_file_paths):\n    \"\"\"Reads a list of JSON files and returns a list of objects.\n    Args:\n        json_file_paths: A list of file paths to JSON files.\n    Returns:\n        A list of objects, where each object represents the data from a JSON file.\n        Returns an empty list if any error occurs during file processing.\n    \"\"\"\n\n    objects = []\n\n    for file_path in tqdm(json_file_paths):\n\n        try:\n\n            objects.append(read_json(file_path))\n\n        except FileNotFoundError:\n\n            print(f\"Error: File not found - {file_path}\")\n\n            return [] # Return empty list on error\n\n        except json.JSONDecodeError:\n\n            print(f\"Error decoding JSON in file: {file_path}\")\n\n            return [] # Return empty list on error\n\n    return objects","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.652880Z","iopub.status.idle":"2024-12-18T16:08:35.653166Z","shell.execute_reply.started":"2024-12-18T16:08:35.653021Z","shell.execute_reply":"2024-12-18T16:08:35.653035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_train = list(Path(\"tokenized_train\").resolve().glob(\"**/*.json\"))\ndata_objects_train = read_json_files(tokenized_train)\n\ntokenized_valid = list(Path(\"tokenized_valid\").resolve().glob(\"**/*.json\"))\ndata_objects_valid = read_json_files(tokenized_valid)\n\nif data_objects_train:\n    print(f\"\\nSuccessfully read {len(data_objects_train)} training JSON files.\")\nelse:\n    print(\"Error reading JSON files.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.654721Z","iopub.status.idle":"2024-12-18T16:08:35.655000Z","shell.execute_reply.started":"2024-12-18T16:08:35.654862Z","shell.execute_reply":"2024-12-18T16:08:35.654876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_train = [np.array(song[\"ids\"][0]) for song in data_objects_train]\nencoded_valid = [np.array(song[\"ids\"][0]) for song in data_objects_valid]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.656276Z","iopub.status.idle":"2024-12-18T16:08:35.656742Z","shell.execute_reply.started":"2024-12-18T16:08:35.656487Z","shell.execute_reply":"2024-12-18T16:08:35.656510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.decode([encoded_train[0][:1024]]).dump_midi(\"sample.mid\")\nall_ids_train = np.concatenate(encoded_train)\nall_ids_valid = np.concatenate(encoded_valid)\nimport datetime\ntoday = datetime.datetime.today()\nday = today.day\nmonth = today.month\nname = \"tokenizer{:d}_{:02d}{:02d}.json\".format(vocab_size, month, day)\ntokenizer.save(name)\nnp.savetxt(\"ids_train_{:02d}{:02d}.txt\".format(month, day), all_ids_train)\nnp.savetxt(\"ids_valid_{:02d}{:02d}.txt\".format(month, day), all_ids_valid)\nall_ids_train = all_ids_train.astype(dtype=np.int32)\nall_ids_valid = all_ids_valid.astype(dtype=np.int32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:08:35.657955Z","iopub.status.idle":"2024-12-18T16:08:35.658398Z","shell.execute_reply.started":"2024-12-18T16:08:35.658173Z","shell.execute_reply":"2024-12-18T16:08:35.658196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# if you need to skip all\n!gdown 1ZIPjenm4tEzAKPc-ONE4gYLzILR3YYqe # tokenizer1000_1217.json\n!gdown 1LN8wrTcUOzlPkQs7Gh-RD9Z2ftbua_E6 # ids_train_1217.txt\n#!gdown 12SOuWNUM9ofo5dhGWvNEj09c_dYisB7g # ids_valid_1217.txt\ntokenizer = REMI(params=\"tokenizer1000_1217.json\")\nall_ids_train = np.loadtxt(\"ids_train_1217.txt\").astype(dtype=np.int32)\n#all_ids_valid = np.loadtxt(\"ids_valid_1217.txt\").astype(dtype=np.int32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T10:30:19.492355Z","iopub.execute_input":"2024-12-19T10:30:19.492691Z","iopub.status.idle":"2024-12-19T10:30:34.447660Z","shell.execute_reply.started":"2024-12-19T10:30:19.492660Z","shell.execute_reply":"2024-12-19T10:30:34.446764Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1ZIPjenm4tEzAKPc-ONE4gYLzILR3YYqe\nTo: /kaggle/working/tokenizer1000_1217.json\n100%|██████████████████████████████████████| 64.2k/64.2k [00:00<00:00, 81.6MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1LN8wrTcUOzlPkQs7Gh-RD9Z2ftbua_E6\nFrom (redirected): https://drive.google.com/uc?id=1LN8wrTcUOzlPkQs7Gh-RD9Z2ftbua_E6&confirm=t&uuid=76360760-4baa-4e8d-9846-61207fa5a31c\nTo: /kaggle/working/ids_train_1217.txt\n100%|█████████████████████████████████████████| 397M/397M [00:01<00:00, 248MB/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"vocab_size = len(tokenizer)\nseq_length = 512\nnormalized_seq = (all_ids_train - vocab_size / 2) / (vocab_size / 2)\n\n# Suddivisione in sequenze\nall_ids_train_seq = [normalized_seq[i:i + seq_length] \n                 for i in range(0, len(normalized_seq) - seq_length, seq_length)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T11:16:02.891557Z","iopub.execute_input":"2024-12-19T11:16:02.892250Z","iopub.status.idle":"2024-12-19T11:16:02.957198Z","shell.execute_reply.started":"2024-12-19T11:16:02.892220Z","shell.execute_reply":"2024-12-19T11:16:02.956242Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Generator con LSTM\nclass LSTMGenerator(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n        super(LSTMGenerator, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        out = self.fc(out)\n        return self.tanh(out)\n\n# Discriminator con LSTM\nclass LSTMDiscriminator(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers):\n        super(LSTMDiscriminator, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        out = self.fc(out[:, -1, :])  # Take the last hidden state\n        return self.sigmoid(out)\n\n# Parametri\nhidden_dim = 256\nnum_layers = 2\nbatch_size = 128\nnoise = 100\n\n# Dataset personalizzato\nclass TokenDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.data[idx], dtype=torch.float32)\n\n# Generazione dati di esempio (da sostituire con dati MIDI normalizzati)\n# Ogni sequenza è un vettore di dimensione (seq_length)\ndataset = TokenDataset(all_ids_train_seq)\ndataloader = DataLoader(dataset, batch_size=batch_size)\n\n# Inizializzazione modelli\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nG = LSTMGenerator(noise, hidden_dim, seq_length, num_layers).to(device)\nD = LSTMDiscriminator(seq_length, hidden_dim, num_layers).to(device)\n\ncriterion = nn.BCELoss()\noptimizer_G = optim.Adam(G.parameters(), lr=0.0002)\noptimizer_D = optim.Adam(D.parameters(), lr=0.0002)\n\n# Training loop\nepochs = 200\nfor epoch in range(epochs):\n    for real_data in dataloader:\n        batch_size = real_data.size(0)\n        real_data = real_data.to(device)\n        \n        # Etichette\n        real_labels = torch.ones(batch_size, 1).to(device)\n        fake_labels = torch.zeros(batch_size, 1).to(device)\n        \n        # Train Discriminator\n        D.zero_grad()\n        z = torch.randn(batch_size, seq_length, noise).to(device)\n        fake_data = G(z)\n        \n        outputs_real = D(real_data)\n        \n        loss_real = criterion(outputs_real, real_labels)\n        \n        outputs_fake = D(fake_data)        \n        loss_fake = criterion(outputs_fake, fake_labels)\n        \n        loss_D = loss_real + loss_fake\n        loss_D.backward()\n        optimizer_D.step()\n        \n        # Train Generator\n        G.zero_grad()\n        outputs = D(fake_data)\n        loss_G = criterion(outputs, real_labels)\n        loss_G.backward()\n        optimizer_G.step()\n        \n    print(f'Epoca [{epoch+1}/{epochs}] Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T11:20:16.975582Z","iopub.execute_input":"2024-12-19T11:20:16.975886Z","iopub.status.idle":"2024-12-19T11:20:17.198947Z","shell.execute_reply.started":"2024-12-19T11:20:16.975862Z","shell.execute_reply":"2024-12-19T11:20:17.197621Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[59], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, seq_length, noise)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     77\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m G(z)\n\u001b[0;32m---> 79\u001b[0m outputs_real \u001b[38;5;241m=\u001b[39m \u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m loss_real \u001b[38;5;241m=\u001b[39m criterion(outputs_real, real_labels)\n\u001b[1;32m     83\u001b[0m outputs_fake \u001b[38;5;241m=\u001b[39m D(fake_data)        \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[59], line 28\u001b[0m, in \u001b[0;36mLSTMDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 28\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Take the last hidden state\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:898\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    894\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m    895\u001b[0m                           max_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    896\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    897\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:827\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    826\u001b[0m                        ):\n\u001b[0;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    829\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 512, got 1"],"ename":"RuntimeError","evalue":"input.size(-1) must be equal to input_size. Expected 512, got 1","output_type":"error"}],"execution_count":59},{"cell_type":"code","source":"# Dimensioni del rumore\nnum_samples = 1  # Numero di canzoni da generare\nz = torch.randn(num_samples, noise)  # Rumore casuale\nz = z.to(device)\n# Genera il campione\ngenerated_data = G(z).cpu().detach().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:51:22.577030Z","iopub.execute_input":"2024-12-18T16:51:22.577391Z","iopub.status.idle":"2024-12-18T16:51:22.583707Z","shell.execute_reply.started":"2024-12-18T16:51:22.577356Z","shell.execute_reply":"2024-12-18T16:51:22.582944Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"boundary = int(vocab_size / 2)\npred_token = [x * boundary + boundary for x in generated_data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:51:25.156108Z","iopub.execute_input":"2024-12-18T16:51:25.156460Z","iopub.status.idle":"2024-12-18T16:51:25.161148Z","shell.execute_reply.started":"2024-12-18T16:51:25.156428Z","shell.execute_reply":"2024-12-18T16:51:25.160132Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"decoded = tokenizer.decode(pred_token)\ndecoded.dump_midi(\"generated.mid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:51:28.185218Z","iopub.execute_input":"2024-12-18T16:51:28.185888Z","iopub.status.idle":"2024-12-18T16:51:28.191157Z","shell.execute_reply.started":"2024-12-18T16:51:28.185849Z","shell.execute_reply":"2024-12-18T16:51:28.190221Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'generated.mid')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T16:51:30.556880Z","iopub.execute_input":"2024-12-18T16:51:30.557488Z","iopub.status.idle":"2024-12-18T16:51:30.563573Z","shell.execute_reply.started":"2024-12-18T16:51:30.557449Z","shell.execute_reply":"2024-12-18T16:51:30.562572Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/generated.mid","text/html":"<a href='generated.mid' target='_blank'>generated.mid</a><br>"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}