{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4-w5fIGbm3-"
      },
      "source": [
        "# Getting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vO6_YgvYQIg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get the full version of the Lakh MIDI Dataset v0.1\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
        "!tar xvf lmd_full.tar.gz\n",
        "!rm lmd_full.tar.gz\n",
        "\n",
        "dataset_path = \"/content/lmd_full\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "khHJHOl-buMg"
      },
      "outputs": [],
      "source": [
        "#@title Get a smaller version of the Lakh MIDI Dataset v0.1\n",
        "%%capture\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz\n",
        "!tar xvf clean_midi.tar.gz\n",
        "!rm clean_midi.tar.gz\n",
        "\n",
        "dataset_path = \"/content/clean_midi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get the NESMDB dataset\n",
        "!gdown 1gIli7G1wu0QWDLzRc-CPWB8C4Hu0XVn3\n",
        "!unzip nesmdb_midi.zip\n",
        "!rm nesmdb_midi.zip"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "bkOU_DPSFtzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "1fNB6qpNyd3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install libraries to manage MIDI files and their tokenization\n",
        "%%capture\n",
        "!pip install miditok\n",
        "!pip install pretty_midi\n",
        "!pip install --upgrade \"transformers>=4.45\""
      ],
      "metadata": {
        "id": "8kvV9qjPxmQc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions"
      ],
      "metadata": {
        "id": "S3IKHrd7fZ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_to_range(arr, range_min=0, range_max=1):\n",
        "    # Get the minimum and maximum of the array\n",
        "    arr_min = np.min(arr)\n",
        "    arr_max = np.max(arr)\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    normalized_arr = (arr - arr_min) / (arr_max - arr_min)\n",
        "\n",
        "    # Scale to [range_min, range_max] -> [-1, 1]\n",
        "    scaled_arr = normalized_arr * (range_max - range_min) + range_min\n",
        "\n",
        "    return scaled_arr, arr_min, arr_max\n",
        "\n",
        "def de_normalize(arr, original_min, original_max, range_min=0, range_max=1):\n",
        "    # Scale to [0, 1]\n",
        "    scaled_arr = (arr - range_min) / (range_max - range_min)\n",
        "\n",
        "    # Normalize to [original_min, original_max]\n",
        "    de_normalized_arr = scaled_arr * (original_max - original_min) + original_min\n",
        "\n",
        "    return de_normalized_arr"
      ],
      "metadata": {
        "id": "jHv5d8Jjfbys"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation (using miditok)"
      ],
      "metadata": {
        "id": "Xdc6l_csvXub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from miditok import REMI\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths to the files of the dataset\n",
        "midi_paths = list(Path(\"clean_midi\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "C2QC9kBULFYr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: use a pre-trained tokenizer"
      ],
      "metadata": {
        "id": "2W_7oCxCK7Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download tokenizer trained params\n",
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/tokenizer/clean_midi_remi_params.json"
      ],
      "metadata": {
        "cellView": "form",
        "id": "26pVTepGK0Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = REMI(params=\"clean_midi_remi_params.json\")"
      ],
      "metadata": {
        "id": "z8p7PrAsLgI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: train the tokenizer"
      ],
      "metadata": {
        "id": "Om7QRtH7KzVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = REMI()\n",
        "# tokenizer.train(vocab_size=30000, files_paths=midi_paths)\n",
        "# tokenizer.save(\"tokenizer.json\")"
      ],
      "metadata": {
        "id": "x-gHD8p8O614"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup `DatasetMIDI`"
      ],
      "metadata": {
        "id": "lpBSIdPnO93D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
        "from miditok.utils import split_files_for_training\n",
        "\n",
        "# Split MIDI paths in train/valid/test sets\n",
        "total_num_files = len(midi_paths)\n",
        "num_files_valid = round(total_num_files * 0.15)\n",
        "num_files_test = round(total_num_files * 0.15)\n",
        "shuffle(midi_paths)\n",
        "midi_paths_valid = midi_paths[:num_files_valid]\n",
        "midi_paths_test = midi_paths[num_files_valid:num_files_valid + num_files_test]\n",
        "midi_paths_train = midi_paths[num_files_valid + num_files_test:]\n",
        "\n",
        "# Chunk MIDIs and perform data augmentation on each subset independently\n",
        "for files_paths, subset_name in (\n",
        "    (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\"), (midi_paths_test, \"test\")\n",
        "):\n",
        "\n",
        "    # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
        "    subset_chunks_dir = Path(f\"Lakh_{subset_name}\")\n",
        "    split_files_for_training(\n",
        "        files_paths=files_paths,\n",
        "        tokenizer=tokenizer,\n",
        "        save_dir=subset_chunks_dir,\n",
        "        max_seq_len=1024,\n",
        "        num_overlap_bars=2,\n",
        "    )\n",
        "\n",
        "    # Perform data augmentation\n",
        "    #augment_dataset(\n",
        "    #    subset_chunks_dir,\n",
        "    #    pitch_offsets=[-12, 12],\n",
        "    #    velocity_offsets=[-4, 4],\n",
        "    #    duration_offsets=[-0.5, 0.5],\n",
        "    #)\n",
        "\n",
        "# Create Dataset and Collator for training\n",
        "midi_paths_train = list(Path(\"Lakh_train\").glob(\"**/*.mid\"))\n",
        "midi_paths_valid = list(Path(\"Lakh_valid\").glob(\"**/*.mid\"))\n",
        "midi_paths_test = list(Path(\"Lakh_test\").glob(\"**/*.mid\"))\n",
        "kwargs_dataset = {\"max_seq_len\": 1024, \"tokenizer\": tokenizer, \"bos_token_id\": tokenizer[\"BOS_None\"], \"eos_token_id\": tokenizer[\"EOS_None\"]}\n",
        "dataset_train = DatasetMIDI(midi_paths_train, **kwargs_dataset)\n",
        "dataset_valid = DatasetMIDI(midi_paths_valid, **kwargs_dataset)\n",
        "dataset_test = DatasetMIDI(midi_paths_test, **kwargs_dataset)"
      ],
      "metadata": {
        "id": "SsYHVeG1ewXr",
        "outputId": "9b70e960-70cf-4fdd-b0bb-8221015f78af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Splitting music files (Lakh_train):   4%|‚ñç         | 474/12080 [00:15<06:20, 30.53it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "File not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a293bc7ea661>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Split the MIDIs into chunks of sizes approximately about 1024 tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msubset_chunks_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Lakh_{subset_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     split_files_for_training(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mfiles_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/miditok/utils/split.py\u001b[0m in \u001b[0;36msplit_files_for_training\u001b[0;34m(files_paths, tokenizer, save_dir, max_seq_len, average_num_tokens_per_note, num_overlap_bars, min_seq_len)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0msaving_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIDI_FILES_EXTENSIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0mchunk_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mchunk_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_abc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: File not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "J4kIRsvy5eEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show some information of the Dataset"
      ],
      "metadata": {
        "id": "y6SCIg0R9P_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(Path(\"Lakh_train\", \"BAP\", \"Verdammt lang her_t0_0.mid\"))\n",
        "print((tokens))"
      ],
      "metadata": {
        "id": "M1op31ZfKSvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)\n",
        "print(dataset_train[0])\n",
        "#tokens = tokenizer(Path(\"Lakh_train\", \"Asia\", \"Don't Cry_t0_0.mid\"))\n",
        "#print(type(tokens))\n",
        "#tokenizer(tokens).dump_midi(\"test.mid\")"
      ],
      "metadata": {
        "id": "RRbEoWJ05dwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding and cleaning of DatasetMIDI"
      ],
      "metadata": {
        "id": "M03yfai2Koj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "def torch_tensor_to_padded_numpy(tensor: torch.Tensor,\n",
        "                                 padded_max_length: int) -> np.ndarray:\n",
        "  array = tensor.numpy()\n",
        "  if array[0] != tokenizer[\"BOS_None\"]:\n",
        "    array = np.insert(array, 0, tokenizer[\"BOS_None\"])\n",
        "  if array[-1] != tokenizer[\"EOS_None\"]:\n",
        "    array = np.append(array, tokenizer[\"EOS_None\"])\n",
        "\n",
        "  array = np.pad(array, (0, padded_max_length - len(array)), 'constant')\n",
        "  return array\n",
        "\n",
        "\n",
        "count = 0\n",
        "train_x = []\n",
        "val_x = []\n",
        "test_x = []\n",
        "\n",
        "max_len_train = max(len(arr[\"input_ids\"]) for arr in dataset_train)\n",
        "max_len_val = max(len(arr[\"input_ids\"]) for arr in dataset_valid)\n",
        "max_len_test = max(len(arr[\"input_ids\"]) for arr in dataset_test)\n",
        "max_len = max(max_len_train, max_len_val, max_len_test)\n",
        "print(\"Max length of sequence in train_x is: \" + str(max_len_train))\n",
        "print(\"Max length of sequence in val_x is: \" + str(max_len_val))\n",
        "print(\"Max length of sequence in test_x is: \" + str(max_len_test))\n",
        "\n",
        "print(\"Using max_length: \" + str(max_len))\n",
        "\n",
        "for (result, input) in \\\n",
        "[(train_x, dataset_train), (val_x, dataset_valid), (test_x, dataset_test)]:\n",
        "  for i in input:\n",
        "    ids = i['input_ids']\n",
        "    array = torch_tensor_to_padded_numpy(ids, max_len)\n",
        "    result.append(array)\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "print(\"Shape of train_x is \" + str(train_x.shape))\n",
        "val_x = np.array(val_x)\n",
        "print(\"Shape of val_x is \" + str(val_x.shape))\n",
        "test_x = np.array(test_x)\n",
        "print(\"Shape of test_x is \" + str(test_x.shape))"
      ],
      "metadata": {
        "id": "mQhxzxXs9qfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the generated train, valid and test arrays (if necessary)"
      ],
      "metadata": {
        "id": "ZpLfUsoRJj0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt('train_x.txt', train_x, fmt='%d')\n",
        "np.savetxt('val_x.txt', val_x, fmt='%d')\n",
        "np.savetxt('test_x.txt', test_x, fmt='%d')"
      ],
      "metadata": {
        "id": "qztOZJUJFO2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading previous train, valid and test arrays (if necessary)"
      ],
      "metadata": {
        "id": "ywj2PhITJ48M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.loadtxt('train_x.txt', dtype=int)\n",
        "val_x = np.loadtxt('val_x.txt', dtype=int)\n",
        "test_x = np.loadtxt('test_x.txt', dtype=int)"
      ],
      "metadata": {
        "id": "NUuco-1GJ_cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization..."
      ],
      "metadata": {
        "id": "l3dqG92BL34R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert not np.any(np.isnan(train_x))\n",
        "assert not np.any(np.isnan(val_x))\n",
        "assert not np.any(np.isnan(test_x))\n",
        "\n",
        "normalized_train_x, original_min_train, original_max_train = normalize_to_range(train_x, 0, 1)\n",
        "assert (np.max(normalized_train_x)) == 1\n",
        "assert (np.min(normalized_train_x)) == 0\n",
        "normalized_val_x, original_min_val, original_max_val = normalize_to_range(val_x, 0, 1)\n",
        "assert (np.max(normalized_val_x)) == 1\n",
        "assert (np.min(normalized_val_x)) == 0\n",
        "normalized_test_x, original_min_test, original_max_test = normalize_to_range(test_x, 0, 1)\n",
        "assert (np.max(normalized_test_x)) == 1\n",
        "assert (np.min(normalized_test_x)) == 0\n"
      ],
      "metadata": {
        "id": "NSnJFf4HL6GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##... or if you want to skip normalization"
      ],
      "metadata": {
        "id": "AUJM1xby7uEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_x = train_x\n",
        "normalized_val_x = val_x\n",
        "normalized_test_x = test_x"
      ],
      "metadata": {
        "id": "ihLMpnm77yCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing labels"
      ],
      "metadata": {
        "id": "nBBvXuLILqXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_y = np.roll(normalized_train_x, shift=-1, axis=1)\n",
        "normalized_val_y = np.roll(normalized_val_x, shift=-1, axis=1)\n",
        "normalized_test_y = np.roll(normalized_test_x, shift=-1, axis=1)\n",
        "\n",
        "print(\"Shape of normalized_train_y is \" + str(normalized_train_y.shape))\n",
        "print(\"Shape of normalized_val_y is \" + str(normalized_val_y.shape))\n",
        "print(\"Shape of normalized_test_y is \" + str(normalized_test_y.shape))"
      ],
      "metadata": {
        "id": "thmTBKuRLsY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "XFDGv_G1LRHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `keras_nlp`\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "xfPxd5kPoaYM",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a transformer"
      ],
      "metadata": {
        "id": "0uKsPYm2LZq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp.layers as nlp_layers\n",
        "\n",
        "def create_transformer(vocab_size, seq_len, embedding_dim, num_heads, dff, num_layers):\n",
        "  # Input\n",
        "    inputs = tf.keras.Input(shape=(seq_len,))\n",
        "\n",
        "    # Embedding\n",
        "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    # Encoder\n",
        "    encoder = nlp_layers.TransformerEncoder(num_heads=num_heads, intermediate_dim=dff)(embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = nlp_layers.TransformerDecoder(num_heads=num_heads, intermediate_dim=dff)(embedding, encoder)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "    # Crea il modello\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "CaUJ3jcVieCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate a transformer"
      ],
      "metadata": {
        "id": "626l8-BJOk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.vocab_size\n",
        "seq_len = max_len\n",
        "\n",
        "model, encoder, decoder = create_transformer(vocab_size=vocab_size,\n",
        "                                             seq_len=seq_len,\n",
        "                                             embedding_dim=256,\n",
        "                                             num_heads=8,\n",
        "                                             dff=1024,\n",
        "                                             num_layers=6)"
      ],
      "metadata": {
        "id": "3-OlyQeLOuwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the transformer"
      ],
      "metadata": {
        "id": "Rd_Nvq7HPdjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(normalized_train_x, normalized_train_y,\n",
        "          epochs=5,\n",
        "          validation_data=(normalized_val_x, normalized_val_y),\n",
        "          callbacks=[early_stopping],\n",
        "          batch_size=32\n",
        "          )\n",
        "\n",
        "model.save(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "RKbpsdsuPftD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model loading (optional)"
      ],
      "metadata": {
        "id": "6OqJAURL9wUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "iBdPDN4b9yUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model usage\n",
        "\n",
        "Here we use the trained model to generate new MIDI"
      ],
      "metadata": {
        "id": "FYxmN_EF9SVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ],
      "metadata": {
        "id": "lbIBpXv4-meU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_random_ids_from_dataset(dataset):\n",
        "  return dataset[np.random.choice(dataset.shape[0])]\n",
        "\n",
        "def sample_next_token(probabilities) -> int:\n",
        "  # Ensure the probabilities sum to 1 (they should, but numerical issues might affect it)\n",
        "  last_token_probs = probabilities[0, -1]\n",
        "  last_token_probs /= last_token_probs.sum()\n",
        "  return np.random.choice(len(last_token_probs), p=last_token_probs)\n",
        "\n",
        "def next_token(model, seed_ids):\n",
        "    probabilities = model.predict(seed_ids, verbose=0)\n",
        "    next_token = sample_next_token(probabilities)\n",
        "    return next_token\n",
        "\n",
        "def generate_ids(model, seed_ids, eos_id, pad_id, bos_id, max_len=None, show_progress=True):\n",
        "  if max_len is None:\n",
        "    max_len = seed_ids.shape[1]\n",
        "  seed = seed_ids\n",
        "  generated_ids = []\n",
        "  if not show_progress:\n",
        "    iterations = range(max_len)\n",
        "  else:\n",
        "    iterations = tqdm(range(max_len))\n",
        "\n",
        "  for _ in iterations:\n",
        "    next_token_id = next_token(model, seed)\n",
        "    generated_ids.append(next_token_id)\n",
        "    if next_token_id == eos_id:\n",
        "      break\n",
        "    elif next_token_id == pad_id:\n",
        "      continue\n",
        "\n",
        "    seed = np.roll(seed, -1, axis=1)\n",
        "    seed[0, -1] = next_token_id\n",
        "\n",
        "  result = np.array(generated_ids)\n",
        "  result[0] = bos_id\n",
        "  result[-1] = eos_id\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "A3W0Gv_m9UiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the IDs for the new sequence"
      ],
      "metadata": {
        "id": "iO4GRyYGLccJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = get_random_ids_from_dataset(normalized_test_y).reshape((1, max_len))\n",
        "generated_ids = generate_ids(\n",
        "    model,\n",
        "    seed,\n",
        "    eos_id=tokenizer[\"EOS_None\"],\n",
        "    pad_id=tokenizer[\"PAD_None\"],\n",
        "    bos_id=tokenizer[\"BOS_None\"],\n",
        "    max_len=100\n",
        ")\n",
        "print(\"\\nGenerated\\n\" + str(generated_ids))"
      ],
      "metadata": {
        "id": "BIlFL6aAA20b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion from IDs to MIDI"
      ],
      "metadata": {
        "id": "oOFStSBEIRIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility function"
      ],
      "metadata": {
        "id": "GOnX87TrL2W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import miditok\n",
        "\n",
        "def ids_to_midi(\n",
        "    ids: np.ndarray,\n",
        "    tokenizer: miditok.tokenizations.remi.REMI,\n",
        "    file_name: str =\"result.mid\",\n",
        "    output_dir: str = \"/content/\"\n",
        "  ):\n",
        "  tokenizer([ids.astype(np.int32)]).dump_midi(Path(output_dir, file_name))"
      ],
      "metadata": {
        "id": "Ol03tIJQCO-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual conversion"
      ],
      "metadata": {
        "id": "uT6nOKPbL4kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"result.mid\"\n",
        "\n",
        "print(f\"Converting IDs to MIDI file: {file_name}...\")\n",
        "\n",
        "ids_to_midi(generated_ids, tokenizer, file_name=file_name)\n",
        "\n",
        "print(\"DONE!\")"
      ],
      "metadata": {
        "id": "h1LT6OUOJAP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End to End utility\n",
        "\n",
        "For generating multiple files in one call"
      ],
      "metadata": {
        "id": "vOXLRcYWOg4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_midi(\n",
        "    dataset,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    output_folder=\"/content/gen_midi\",\n",
        "    num_files=1,\n",
        "    max_len=100\n",
        "):\n",
        "  if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "  for i in tqdm(range(num_files)):\n",
        "    seed = get_random_ids_from_dataset(normalized_test_y).reshape((1, normalized_test_y.shape[1]))\n",
        "    generated_ids = generate_ids(\n",
        "        model,\n",
        "        seed,\n",
        "        eos_id=tokenizer[\"EOS_None\"],\n",
        "        pad_id=tokenizer[\"PAD_None\"],\n",
        "        bos_id=tokenizer[\"BOS_None\"],\n",
        "        max_len=max_len,\n",
        "        show_progress=False\n",
        "    )\n",
        "    file_name = str(i)+\".mid\"/\n",
        "    ids_to_midi(generated_ids, tokenizer, file_name=file_name, output_dir=output_folder)\n"
      ],
      "metadata": {
        "id": "5d7geVO3Oj2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate some files"
      ],
      "metadata": {
        "id": "qO1YVt5xP2FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_files = 10\n",
        "generate_midi(dataset_test,\n",
        "               model,\n",
        "               tokenizer,\n",
        "               output_folder=\"/content/gen_midi/\",\n",
        "               num_files=n_files,\n",
        "               max_len=100\n",
        "               )"
      ],
      "metadata": {
        "id": "Bpa2z_dzP0kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd PART - Playing the MIDI"
      ],
      "metadata": {
        "id": "4e3Ci7lIQ4WN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPKJ0WAsd1pT"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtbAeJt-d4ML"
      },
      "outputs": [],
      "source": [
        "def random_file(root, keyword=None):\n",
        "    import glob\n",
        "    import os\n",
        "    import random\n",
        "    mid_files = glob.glob(os.path.join(root, \"**\", \"*.mid\"), recursive=True)\n",
        "    if keyword is not None:\n",
        "      mid_files = [file for file in mid_files if keyword in file.lower()]\n",
        "    return random.choice(mid_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "hJG7c4biNYrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZEn9Xq4aAWO",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Installing the required libraries\n",
        "%%capture\n",
        "!apt-get update -qq && apt-get install -y fluidsynth\n",
        "!pip install pretty_midi midi-clip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download example Soundfonts (GeneralUser GS v2 and PICONICA)\n",
        "%%capture\n",
        "!gdown 1wlpTIS70nQHMrYBjDT0M6nyg07kUejUv\n",
        "!unzip GeneralUser_GS_v2.0.0--doc_r2.zip\n",
        "!rm -rf GeneralUser_GS_v2.0.0--doc_r2.zip support documentation demo\\ MIDIs\n",
        "!mv GeneralUser\\ GS\\ v2.0.0.sf2 guGS.sf2\n",
        "\n",
        "# PICONICA\n",
        "!gdown 1uk51T9Gvo1n2JRl3_CHCg2FVGWiNI4qJ"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vYLKV8QBgJi2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: download other soundfonts (pDPP)\n",
        "%%capture\n",
        "# Pokemon\n",
        "!gdown 1vDK_xH7WeAqQrrBFXfh4Q205x6oNhTQt"
      ],
      "metadata": {
        "id": "jButvEyvwx8p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN6kSFkZaWce"
      },
      "source": [
        "## Utility function to generate the audio on Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Taken from https://github.com/bzamecnik/midi2audio/blob/master/midi2audio.py"
      ],
      "metadata": {
        "id": "GsvltbQjMO2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "__all__ = ['FluidSynth']\n",
        "\n",
        "DEFAULT_SOUND_FONT = '~/.fluidsynth/default_sound_font.sf2'\n",
        "DEFAULT_SAMPLE_RATE = 44100\n",
        "DEFAULT_GAIN = 0.2\n",
        "\n",
        "class FluidSynth():\n",
        "    def __init__(self, sound_font=DEFAULT_SOUND_FONT, sample_rate=DEFAULT_SAMPLE_RATE, gain=DEFAULT_GAIN):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.sound_font = os.path.expanduser(sound_font)\n",
        "        self.gain = gain\n",
        "\n",
        "    def midi_to_audio(self, midi_file: str, audio_file: str, verbose=True):\n",
        "        if verbose:\n",
        "            stdout = None\n",
        "        else:\n",
        "            stdout = subprocess.DEVNULL\n",
        "        subprocess.call(\n",
        "            ['fluidsynth', '-ni', '-g', str(self.gain), self.sound_font, midi_file, '-F', audio_file, '-r', str(self.sample_rate)],\n",
        "            stdout=stdout,\n",
        "        )\n",
        "\n",
        "    def play_midi(self, midi_file):\n",
        "        subprocess.call(['fluidsynth', '-i', '-g', str(self.gain), self.sound_font, midi_file, '-r', str(self.sample_rate)])"
      ],
      "metadata": {
        "id": "JAgDunjjMJTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other utility functions"
      ],
      "metadata": {
        "id": "XGGrotfQMk1Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WINfP4LzacAg"
      },
      "outputs": [],
      "source": [
        "import pretty_midi\n",
        "import os\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_midi_info(midi_path, print_notes=False):\n",
        "  midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "  print(\"Instruments: \", [instrument.name for instrument in midi_data.instruments])\n",
        "  print(\"MIDI duration: {duration:.2f} seconds\".format(duration=midi_data.get_end_time()))\n",
        "  if print_notes:\n",
        "    for instrument in midi_data.instruments:\n",
        "      print(instrument.name)\n",
        "      for note in instrument.notes:\n",
        "        print(note.start, note.end, note.pitch, note.velocity)\n",
        "\n",
        "def piano_roll(midi_path):\n",
        "  plt.figure(figsize=(12, 4))\n",
        "  plot_piano_roll(path, 24, 84)\n",
        "\n",
        "def plot_piano_roll(path, start_pitch, end_pitch, fs=100):\n",
        "    midi_data = pretty_midi.PrettyMIDI(path)\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(midi_data.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "def change_midi_velocity(midi_path, output_path, delta=0): # Renamed the function to avoid name conflict\n",
        "  midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "  for instrument in midi_data.instruments:\n",
        "    for note in instrument.notes:\n",
        "      note.velocity += delta\n",
        "  midi_data.write(output_path)\n",
        "\n",
        "def convert_midi_to_wav(soundfont_path, midi_path, output_path, gain=None, velocity_change=0): # Renamed the argument\n",
        "  change_midi_velocity(midi_path, \"temp.mid\", delta=velocity_change) # Call the renamed function\n",
        "  FluidSynth(soundfont_path, gain=gain).midi_to_audio(\"temp.mid\", output_path)\n",
        "  os.remove(\"temp.mid\")\n",
        "\n",
        "\n",
        "def trim_midi(midi_path, start, end):\n",
        "  import mido\n",
        "  import midi_clip\n",
        "  mid = mido.MidiFile(midi_path)\n",
        "  trimmed_midi = midi_clip.midi_clip(mid, start, end)\n",
        "\n",
        "  dir_name, base_name = os.path.split(midi_path)\n",
        "  new_base_name = \"trimmed_\" + base_name\n",
        "  output_path = os.path.join(dir_name, new_base_name)\n",
        "  trimmed_midi.save(output_path)\n",
        "  return output_path\n",
        "\n",
        "def playMidi(midi_file_path,\n",
        "             soundfont_path=\"/content/guGS.sf2\",\n",
        "             output_path=\"audio.wav\",\n",
        "             start=None,\n",
        "             end=None,\n",
        "             gain=DEFAULT_GAIN,\n",
        "             velocity_change=0\n",
        "             ):\n",
        "    from IPython.display import Audio\n",
        "\n",
        "    if start is not None and end is not None:\n",
        "      midi_file_path = trim_midi(midi_file_path, start, end)\n",
        "      convert_midi_to_wav(soundfont_path, midi_file_path, output_path, gain=gain, velocity_change=velocity_change)\n",
        "      os.remove(midi_file_path)\n",
        "    else:\n",
        "      convert_midi_to_wav(soundfont_path, midi_file_path, output_path, gain=gain, velocity_change=velocity_change)\n",
        "    return Audio(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using generated MIDI"
      ],
      "metadata": {
        "id": "XKlx5gVYN_6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show info\n",
        "\n",
        "generated_midi_path = \"gen_midi/3.mid\" # @param {type:\"string\"}\n",
        "\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(generated_midi_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4AYEKGI5OCW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Play the MIDI\n",
        "\n",
        "generated_midi_path = \"gen_midi/4.mid\" # @param {type:\"string\"}\n",
        "soundfont = \"PICONICA.sf2\" # @param [\"PICONICA.sf2\", \"guGS.sf2\", \"PokeDP.sf2\"]\n",
        "\n",
        "playMidi(generated_midi_path, soundfont_path=soundfont)"
      ],
      "metadata": {
        "id": "5HMXZUnuoNFY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras (playing other MIDIs)"
      ],
      "metadata": {
        "id": "ImkU4rMAN1oi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CithkaLAafKv"
      },
      "source": [
        "## Play a random MIDI of the Lakh dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUE9qdC2aiOs"
      },
      "outputs": [],
      "source": [
        "path = random_file(dataset_path)\n",
        "print(\"Converting: \" + path)\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(path)\n",
        "print(\"Synthetized:\")\n",
        "playMidi(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Play a random MIDI of the NESMDB dataset"
      ],
      "metadata": {
        "id": "RN-UiflHNYQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = random_file(\"nesmdb_midi\")\n",
        "print(\"Converting: \" + path)\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(path)\n",
        "print(\"Synthetized:\")\n",
        "playMidi(path, soundfont_path=\"PICONICA.sf2\", velocity_change=30, gain=1)"
      ],
      "metadata": {
        "id": "K-1eJsT7NX_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pretty_midi\n",
        "\n",
        "class midi_to_tokens():\n",
        "    def __init__(self, path, steps_per_beat=12):\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.pm = pretty_midi.PrettyMIDI(path)\n",
        "        self.dbs = self.pm.get_downbeats().tolist() + [self.pm.get_end_time()] # dbs := downbeats\n",
        "        self.tokens = self._tokenize()\n",
        "\n",
        "    def __call__(self):\n",
        "        return ' '.join(self.tokens)\n",
        "\n",
        "    def _time_to_step(self, time):\n",
        "        return round(self.pm.time_to_tick(time) / self.pm.resolution * self.steps_per_beat)\n",
        "\n",
        "    def _event_to_tokens(self, event):\n",
        "        if event in ('bar', 'beat'):\n",
        "            return [event]\n",
        "        elif isinstance(event, pretty_midi.containers.Note):\n",
        "            return [f'note_{event.pitch}', f'len_{self._time_to_step(event.end) - self._time_to_step(event.start)}']\n",
        "\n",
        "    def _trim_note(self, note, start, end):\n",
        "        n = copy.copy(note)\n",
        "        n.start, n.end = max(n.start, start), min(n.end, end)\n",
        "        return n\n",
        "\n",
        "    def _tokenize(self, start_measure=1, end_measure=None):\n",
        "        start, end = self.dbs[start_measure - 1], self.dbs[end_measure or -1]\n",
        "\n",
        "        notes = []\n",
        "        for inst in self.pm.instruments:\n",
        "            notes += inst.notes\n",
        "        notes.sort(key=lambda x: (x.start, -x.pitch))\n",
        "\n",
        "        events = []\n",
        "        events += [(self._time_to_step(db), 'bar') for db in self.dbs if start <= db < end]\n",
        "        events += [(self._time_to_step(b), 'beat') for b in set(self.pm.get_beats()) - set(self.dbs) if start <= b < end] # beats without downbeats\n",
        "        events += [(self._time_to_step(max(n.start, start)), self._trim_note(n, start, end)) for n in notes if start <= n.start < end or start < n.end <= end]\n",
        "        events.sort(key=lambda x: x[0])\n",
        "\n",
        "        tokens = []\n",
        "        last_beat = 0\n",
        "        for step, event in events:\n",
        "            if event in ('bar', 'beat'):\n",
        "                last_beat = step\n",
        "            if step - last_beat:\n",
        "                tokens.append(f'pos_{step - last_beat}')\n",
        "            tokens += self._event_to_tokens(event)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def measures(self, start_measure=1, end_measure=None):\n",
        "        return self._tokenize(start_measure, end_measure)"
      ],
      "metadata": {
        "id": "4__omfRU0MMz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Tokenization e Generation"
      ],
      "metadata": {
        "id": "ofcPhnyn9GSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str(midi_paths[8])"
      ],
      "metadata": {
        "id": "9aDpqPCg3hHe",
        "outputId": "3a6e392c-3eb3-4a33-e4f5-ad1f9523fd0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/clean_midi/Genesis/Watcher of the Skies.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = midi_to_tokens(str(midi_paths[8]), steps_per_beat=12).tokens"
      ],
      "metadata": {
        "id": "I6TT4KDk0bOR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "\n",
        "class TokensToMidi:\n",
        "    def __init__(self, tokens, steps_per_beat=12, ticks_per_beat=960, tempo=120):\n",
        "        self.tokens = tokens\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.ticks_per_step = ticks_per_beat // steps_per_beat\n",
        "        self.tempo = tempo\n",
        "        self.ticks_per_beat = ticks_per_beat\n",
        "\n",
        "    def _ticks_to_time(self, ticks):\n",
        "        return ticks * 60 / (self.tempo * self.ticks_per_beat)\n",
        "\n",
        "    def generate_midi(self):\n",
        "        pm = pretty_midi.PrettyMIDI(initial_tempo=self.tempo)\n",
        "        instrument = pretty_midi.Instrument(program=38)\n",
        "\n",
        "        time = 0\n",
        "        last_beat = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(self.tokens):\n",
        "            token = self.tokens[i]\n",
        "\n",
        "            if token == \"bar\":\n",
        "                time += self._ticks_to_time(self.ticks_per_step * self.steps_per_beat)\n",
        "                last_beat = time\n",
        "            elif token == \"beat\":\n",
        "                time = last_beat\n",
        "                last_beat = time √¨\n",
        "            elif token.startswith(\"pos_\"):\n",
        "                position = int(token.split(\"_\")[1])\n",
        "                time = last_beat + self._ticks_to_time(self.ticks_per_step * position)\n",
        "            elif token.startswith(\"note_\"):\n",
        "                pitch = int(token.split(\"_\")[1])\n",
        "                length_token = self.tokens[i + 1]\n",
        "                length = int(length_token.split(\"_\")[1])\n",
        "                duration = self._ticks_to_time(self.ticks_per_step * length)\n",
        "\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch,\n",
        "                    start=time,\n",
        "                    end=time + duration\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "                i += 1  √¨\n",
        "            i += 1\n",
        "\n",
        "        pm.instruments.append(instrument)\n",
        "        pm.write(\"reconstructed_output.mid\")\n",
        "        return pm"
      ],
      "metadata": {
        "id": "bRgEkZjM2Bmp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "midi_reconstructor = TokensToMidi(tokens)\n",
        "midi_reconstructor.generate_midi()"
      ],
      "metadata": {
        "id": "dd0UY_Pj4WE0",
        "outputId": "9a50e84e-908d-454c-b450-fe64f8c88833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pretty_midi.pretty_midi.PrettyMIDI at 0x7cff74d04160>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncyRMB9d4ZT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}