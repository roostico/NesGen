{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4-w5fIGbm3-"
      },
      "source": [
        "# Getting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vO6_YgvYQIg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get the full version of the Lakh MIDI Dataset v0.1\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
        "!tar xvf lmd_full.tar.gz\n",
        "!rm lmd_full.tar.gz\n",
        "\n",
        "dataset_path = \"/content/lmd_full\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "khHJHOl-buMg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get a smaller version of the Lakh MIDI Dataset v0.1\n",
        "%%capture\n",
        "!wget http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz\n",
        "!tar xvf clean_midi.tar.gz\n",
        "!rm clean_midi.tar.gz\n",
        "\n",
        "dataset_path = \"/content/clean_midi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get the NESMDB dataset\n",
        "!gdown 1gIli7G1wu0QWDLzRc-CPWB8C4Hu0XVn3\n",
        "!unzip nesmdb_midi.zip\n",
        "!rm nesmdb_midi.zip"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "bkOU_DPSFtzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation (using miditok)"
      ],
      "metadata": {
        "id": "Xdc6l_csvXub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pretty_midi"
      ],
      "metadata": {
        "id": "IBe7RC5BFnGd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Paths to the files of the dataset\n",
        "midi_paths = list(Path(\"clean_midi\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "Xgzc6NC0FqwB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "J4kIRsvy5eEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "midis_dir = \"midis\"\n",
        "os.makedirs(midis_dir, exist_ok=True)\n",
        "\n",
        "for i, midi_path in enumerate(midi_paths):\n",
        "  new_midi_path = os.path.join(midis_dir, f\"{i}.mid\")\n",
        "  shutil.move(str(midi_path), new_midi_path)\n",
        "\n",
        "midis = list(Path(\"midis\").resolve().glob(\"**/*.mid\"))"
      ],
      "metadata": {
        "id": "KznPqQQe-rC2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "eQW7LSfvbKZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI2Tokens"
      ],
      "metadata": {
        "id": "jl_tgliAbPjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pretty_midi\n",
        "\n",
        "class midi_to_tokens():\n",
        "    def __init__(self, path, steps_per_beat=12, limit=None):\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        try:\n",
        "          self.pm = pretty_midi.PrettyMIDI(path)\n",
        "        except OSError as e:\n",
        "          print(f\"Error reading MIDI file: {e}\")\n",
        "          return\n",
        "        self.dbs = self.pm.get_downbeats().tolist() + [self.pm.get_end_time()] # dbs := downbeats\n",
        "        self.tokens_seqs = self._tokenize(limit=limit)\n",
        "\n",
        "    def __call__(self):\n",
        "        return ' '.join(self.tokens)\n",
        "\n",
        "    def _time_to_step(self, time):\n",
        "        return round(self.pm.time_to_tick(time) / self.pm.resolution * self.steps_per_beat)\n",
        "\n",
        "    def _event_to_tokens(self, event):\n",
        "        if event in ('bar', 'beat'):\n",
        "            return [event]\n",
        "        elif isinstance(event, pretty_midi.containers.Note):\n",
        "            return [f'note_{event.pitch}', f'len_{self._time_to_step(event.end) - self._time_to_step(event.start)}']\n",
        "\n",
        "    def _trim_note(self, note, start, end):\n",
        "        n = copy.copy(note)\n",
        "        n.start, n.end = max(n.start, start), min(n.end, end)\n",
        "        return n\n",
        "\n",
        "    def _tokenize(self, start_measure=1, end_measure=None, limit=None):\n",
        "        start, end = self.dbs[start_measure - 1], self.dbs[end_measure or -1]\n",
        "\n",
        "        notes = []\n",
        "        for inst in self.pm.instruments:\n",
        "            notes += inst.notes\n",
        "        notes.sort(key=lambda x: (x.start, -x.pitch))\n",
        "\n",
        "        events = []\n",
        "        events += [(self._time_to_step(db), 'bar') for db in self.dbs if start <= db < end]\n",
        "        events += [(self._time_to_step(b), 'beat') for b in set(self.pm.get_beats()) - set(self.dbs) if start <= b < end] # beats without downbeats\n",
        "        events += [(self._time_to_step(max(n.start, start)), self._trim_note(n, start, end)) for n in notes if start <= n.start < end or start < n.end <= end]\n",
        "        events.sort(key=lambda x: x[0])\n",
        "\n",
        "        tokens = []\n",
        "        last_beat = 0\n",
        "\n",
        "        try:\n",
        "            for step, event in events:\n",
        "                if event in ('bar', 'beat'):\n",
        "                    last_beat = step\n",
        "                if step - last_beat:\n",
        "                    tokens.append(f'pos_{step - last_beat}')\n",
        "                tokens += self._event_to_tokens(event)\n",
        "        except Exception as e:\n",
        "            print(f\"Error while translating events to tokens: {e}\")\n",
        "\n",
        "        if limit is None:\n",
        "            return [tokens]\n",
        "        tokens = np.array(tokens)\n",
        "        num_chunks = len(tokens) // limit\n",
        "        return tokens[:num_chunks * limit].reshape(-1, limit)\n",
        "\n",
        "    def measures(self, start_measure=1, end_measure=None):\n",
        "        return self._tokenize(start_measure, end_measure)"
      ],
      "metadata": {
        "id": "CrSlr4mxAWlU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokens2MIDI"
      ],
      "metadata": {
        "id": "kjvAidVeGXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokensToMidi:\n",
        "    def __init__(self, tokens, steps_per_beat=12, ticks_per_beat=960, tempo=120):\n",
        "        self.tokens = tokens\n",
        "        self.steps_per_beat = steps_per_beat\n",
        "        self.ticks_per_step = ticks_per_beat // steps_per_beat\n",
        "        self.tempo = tempo\n",
        "        self.ticks_per_beat = ticks_per_beat\n",
        "\n",
        "    def _ticks_to_time(self, ticks):\n",
        "        return ticks * 60 / (self.tempo * self.ticks_per_beat)\n",
        "\n",
        "    def generate_midi(self, path):\n",
        "        pm = pretty_midi.PrettyMIDI(initial_tempo=self.tempo)\n",
        "        instrument = pretty_midi.Instrument(program=38)\n",
        "\n",
        "        time = 0\n",
        "        last_beat = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(self.tokens):\n",
        "            token = self.tokens[i]\n",
        "\n",
        "            if token == \"bar\":\n",
        "                time += self._ticks_to_time(self.ticks_per_step * self.steps_per_beat)\n",
        "                last_beat = time\n",
        "            elif token == \"beat\":\n",
        "                time = last_beat\n",
        "                last_beat = time\n",
        "            elif token.startswith(\"pos_\"):\n",
        "                position = int(token.split(\"_\")[1])\n",
        "                time = last_beat + self._ticks_to_time(self.ticks_per_step * position)\n",
        "            elif token.startswith(\"note_\"):\n",
        "                pitch = int(token.split(\"_\")[1])\n",
        "                try:\n",
        "                  length_token = self.tokens[i + 1]\n",
        "                  length = int(length_token.split(\"_\")[1])\n",
        "                except IndexError:\n",
        "                  length = 1\n",
        "                duration = self._ticks_to_time(self.ticks_per_step * length)\n",
        "\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch,\n",
        "                    start=time,\n",
        "                    end=time + duration\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "                i += 1\n",
        "            i += 1\n",
        "\n",
        "        pm.instruments.append(instrument)\n",
        "        pm.write(path)\n",
        "        return pm"
      ],
      "metadata": {
        "id": "oDUS-wjOGWtg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self, limit=None):\n",
        "        self._encoder = LabelEncoder()\n",
        "        self.PAD_id = 0\n",
        "        self.BOS_id = 1\n",
        "        self.EOS_id = 2\n",
        "        self.limit = limit\n",
        "\n",
        "    def _tokenize(self, midi_paths):\n",
        "      \"\"\"\n",
        "      midi_paths: list of paths to MIDI files\n",
        "      returns: list of lists of string tokens\n",
        "      \"\"\"\n",
        "      tokens = []\n",
        "      for path in tqdm(midi_paths):\n",
        "        try:\n",
        "          seqs = midi_to_tokens(str(path), steps_per_beat=12, limit=self.limit).tokens_seqs\n",
        "          for seq in seqs:\n",
        "              seq_list = seq.tolist()\n",
        "              seq_list.insert(0, \"Start\")\n",
        "              seq_list.append(\"End\")\n",
        "              tokens.append(np.array(seq_list))\n",
        "        except AttributeError:\n",
        "          print(f\"Error reading MIDI file: {path}\")\n",
        "          continue\n",
        "        except Exception as e:\n",
        "          print(f\"There was an unexpected error: {e}\")\n",
        "          continue\n",
        "      return tokens\n",
        "\n",
        "    def fit_and_encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      flattened_array = np.concatenate([np.array(sublist).flatten() for sublist in tokens])\n",
        "      self._encoder.fit(flattened_array)\n",
        "      transformed = [self._encoder.transform(i) for i in tokens]\n",
        "      self.EOS_id = self._encoder.transform([\"End\"])[0]\n",
        "      self.BOS_id = self._encoder.transform([\"Start\"])[0]\n",
        "      self.PAD_id = self._encoder.classes_.shape[0]\n",
        "      self._encoder.classes_ = np.append(self._encoder.classes_, [\"Pad\"])\n",
        "      return transformed\n",
        "\n",
        "    def encode(self, midi_paths):\n",
        "      tokens = self._tokenize(midi_paths)\n",
        "      return [self._encoder.transform(i) for i in tokens]\n",
        "\n",
        "    def decode(self, encoded_tokens, path=\"reconstructed_midi.mid\"):\n",
        "      string_tokens = [self._encoder.inverse_transform(i) for i in encoded_tokens]\n",
        "      for i in range(len(string_tokens)):\n",
        "        midi_reconstructor = TokensToMidi(string_tokens[i])\n",
        "        midi_reconstructor.generate_midi(str(i) + path)\n",
        "\n",
        "    def pad(self, encoded_tokens):\n",
        "      self._seq_length = max(len(arr) for arr in encoded_tokens)\n",
        "      return np.array([np.pad(arr, (self._seq_length - len(arr), 0), mode='constant', constant_values=self.PAD_id) for arr in encoded_tokens])\n",
        "\n",
        "    def save(self, path: str):\n",
        "      np.savetxt(path, self.encoder.classes_, fmt=\"%s\")\n",
        "\n",
        "    def load(self, path: str):\n",
        "      self._encoder.classes_ = np.loadtxt(path, dtype=\"str\")\n",
        "\n",
        "    @property\n",
        "    def encoder(self):\n",
        "      return self._encoder\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "      return self._encoder.classes_.shape[0]\n",
        "\n",
        "    @property\n",
        "    def seq_length(self):\n",
        "      return self._seq_length\n",
        "\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "      return self.PAD_id\n",
        "\n",
        "    @property\n",
        "    def bos_id(self):\n",
        "      return self.BOS_id\n",
        "\n",
        "    @property\n",
        "    def eos_id(self):\n",
        "      return self.EOS_id\n"
      ],
      "metadata": {
        "id": "utD8X3r1AgaG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download trained Tokenizer and tokens"
      ],
      "metadata": {
        "id": "ZEHCnWHiCmqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1QrMzoYewqyxv2TJEgwS53-8l6rlpi4RG\n",
        "!gdown 1dwNkvRopC8gIpDzD2iEFZADe4aeF-w_F\n",
        "\n",
        "!mv tokens_lim1000_files2500 tokens.txt\n",
        "!mv tokenizer_lim1000_files2500 tokenizer.txt"
      ],
      "metadata": {
        "id": "3b1cVVQ7CpmS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a previously fitted tokenizer and..."
      ],
      "metadata": {
        "id": "FXJQ4eeyCETV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(limit=1000)\n",
        "tok.load(\"tokenizer.txt\")"
      ],
      "metadata": {
        "id": "EDyLhCU5CKUQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ...load already tokenized data..."
      ],
      "metadata": {
        "id": "EWrvEj48CQjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sequences = 7000\n",
        "padded_tokens = np.loadtxt(\"tokens.txt\")[:n_sequences]\n",
        "print(f\"Loaded {padded_tokens.shape[0]} tokenized sequences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "065RdJgOCThU",
        "outputId": "2bdd615e-1d04-437e-b562-b89c0fd40a43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tokenized version of 15389 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ...**OR** fit the tokenizer..."
      ],
      "metadata": {
        "id": "uITXgRsfHn4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(limit=500)\n",
        "encoded_tokens = tok.fit_and_encode(midis[:50])\n",
        "\n",
        "print(f\"PAD_id is {tok.pad_id}\")\n",
        "print(f\"BOS_id is {tok.bos_id}\")\n",
        "print(f\"EOS_id is {tok.eos_id}\")\n",
        "print(f\"Vocab size is {tok.vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOxAY9VTHp56",
        "outputId": "ec21c867-607a-406e-9629-6108c46f25ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 2/50 [00:01<00:29,  1.61it/s]/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PAD_id is 297\n",
            "BOS_id is 1\n",
            "EOS_id is 0\n",
            "Vocab size is 298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ...and add the Padding"
      ],
      "metadata": {
        "id": "KjDSHc2lIxwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tokens = tok.pad(encoded_tokens)\n",
        "print(f\"Maximum sequence len is {tok.seq_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m4dFeH1Iy5D",
        "outputId": "52bcd00b-d8a5-493b-b033-a4b0491a6aca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence len is 502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "XFDGv_G1LRHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `keras_nlp`\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "xfPxd5kPoaYM",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp.layers as nlp_layers\n",
        "\n",
        "def create_transformer(vocab_size, seq_len, embedding_dim, num_heads, dff, num_layers):\n",
        "  # Input\n",
        "    inputs = tf.keras.Input(shape=(seq_len,))\n",
        "\n",
        "    # Embedding\n",
        "    embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    # Encoder\n",
        "    encoder = nlp_layers.TransformerEncoder(num_heads=num_heads, intermediate_dim=dff)(embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = nlp_layers.TransformerDecoder(num_heads=num_heads, intermediate_dim=dff)(embedding, encoder)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "    # Crea il modello\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "dx2RaTilyKa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tok.vocab_size\n",
        "seq_len = padded_tokens.shape[1]\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model, encoder, decoder = create_transformer(vocab_size=vocab_size,\n",
        "                                             seq_len=seq_len,\n",
        "                                             embedding_dim=512,\n",
        "                                             num_heads=8,\n",
        "                                             dff=2048,\n",
        "                                             num_layers=12)"
      ],
      "metadata": {
        "id": "rxRlJjdDyUIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate a transformer"
      ],
      "metadata": {
        "id": "626l8-BJOk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_perc = 0.8\n",
        "train_size = int(train_perc * padded_tokens.shape[0])\n",
        "\n",
        "normalized_train_x = padded_tokens[:train_size]\n",
        "normalized_val_x = padded_tokens[train_size:]\n",
        "\n",
        "normalized_train_y = np.roll(normalized_train_x, shift=-1, axis=1)\n",
        "normalized_val_y = np.roll(normalized_val_x, shift=-1, axis=1)"
      ],
      "metadata": {
        "id": "FdmvqZajeVOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the transformer"
      ],
      "metadata": {
        "id": "Rd_Nvq7HPdjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(normalized_train_x, normalized_train_y,\n",
        "          epochs=10,\n",
        "          validation_data=(normalized_val_x, normalized_val_y),\n",
        "          callbacks=[early_stopping],\n",
        "          batch_size=32\n",
        "          )\n",
        "\n",
        "model.save(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "RKbpsdsuPftD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model loading (optional)"
      ],
      "metadata": {
        "id": "6OqJAURL9wUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"NesGen_v1.keras\")"
      ],
      "metadata": {
        "id": "iBdPDN4b9yUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model usage\n",
        "\n",
        "Here we use the trained model to generate new MIDI"
      ],
      "metadata": {
        "id": "FYxmN_EF9SVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ],
      "metadata": {
        "id": "lbIBpXv4-meU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_random_ids_from_dataset(dataset):\n",
        "  return dataset[np.random.choice(dataset.shape[0])]\n",
        "\n",
        "def sample_next_token(probabilities) -> int:\n",
        "  # Ensure the probabilities sum to 1 (they should, but numerical issues might affect it)\n",
        "  last_token_probs = probabilities[0, -1]\n",
        "  last_token_probs /= last_token_probs.sum()\n",
        "  return np.random.choice(len(last_token_probs), p=last_token_probs)\n",
        "\n",
        "def next_token(model, seed_ids):\n",
        "    probabilities = model.predict(seed_ids, verbose=0)\n",
        "    next_token = sample_next_token(probabilities)\n",
        "    return next_token\n",
        "\n",
        "def generate_ids(model, seed_ids, eos_id, pad_id, bos_id, max_len=None, show_progress=True):\n",
        "  if max_len is None:\n",
        "    max_len = seed_ids.shape[1]\n",
        "  seed = seed_ids\n",
        "  generated_ids = []\n",
        "  if not show_progress:\n",
        "    iterations = range(max_len)\n",
        "  else:\n",
        "    iterations = tqdm(range(max_len))\n",
        "\n",
        "  for _ in iterations:\n",
        "    next_token_id = next_token(model, seed)\n",
        "    generated_ids.append(next_token_id)\n",
        "    if next_token_id == eos_id:\n",
        "      break\n",
        "    elif next_token_id == pad_id:\n",
        "      continue\n",
        "\n",
        "    seed = np.roll(seed, -1, axis=1)\n",
        "    seed[0, -1] = next_token_id\n",
        "\n",
        "  result = np.array(generated_ids)\n",
        "  result[0] = bos_id\n",
        "  result[-1] = eos_id\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "A3W0Gv_m9UiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the IDs for the new sequence"
      ],
      "metadata": {
        "id": "iO4GRyYGLccJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = get_random_ids_from_dataset(normalized_test_y).reshape((1, max_len))\n",
        "generated_ids = generate_ids(\n",
        "    model,\n",
        "    seed,\n",
        "    eos_id=tokenizer[\"EOS_None\"],\n",
        "    pad_id=tokenizer[\"PAD_None\"],\n",
        "    bos_id=tokenizer[\"BOS_None\"],\n",
        "    max_len=100\n",
        ")\n",
        "print(\"\\nGenerated\\n\" + str(generated_ids))"
      ],
      "metadata": {
        "id": "BIlFL6aAA20b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion from IDs to MIDI"
      ],
      "metadata": {
        "id": "oOFStSBEIRIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility function"
      ],
      "metadata": {
        "id": "GOnX87TrL2W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import miditok\n",
        "\n",
        "def ids_to_midi(\n",
        "    ids: np.ndarray,\n",
        "    tokenizer: miditok.tokenizations.remi.REMI,\n",
        "    file_name: str =\"result.mid\",\n",
        "    output_dir: str = \"/content/\"\n",
        "  ):\n",
        "  tokenizer([ids.astype(np.int32)]).dump_midi(Path(output_dir, file_name))"
      ],
      "metadata": {
        "id": "Ol03tIJQCO-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual conversion"
      ],
      "metadata": {
        "id": "uT6nOKPbL4kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"result.mid\"\n",
        "\n",
        "print(f\"Converting IDs to MIDI file: {file_name}...\")\n",
        "\n",
        "ids_to_midi(generated_ids, tokenizer, file_name=file_name)\n",
        "\n",
        "print(\"DONE!\")"
      ],
      "metadata": {
        "id": "h1LT6OUOJAP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End to End utility\n",
        "\n",
        "For generating multiple files in one call"
      ],
      "metadata": {
        "id": "vOXLRcYWOg4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_midi(\n",
        "    dataset,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    output_folder=\"/content/gen_midi\",\n",
        "    num_files=1,\n",
        "    max_len=100\n",
        "):\n",
        "  if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "  for i in tqdm(range(num_files)):\n",
        "    seed = get_random_ids_from_dataset(normalized_test_y).reshape((1, normalized_test_y.shape[1]))\n",
        "    generated_ids = generate_ids(\n",
        "        model,\n",
        "        seed,\n",
        "        eos_id=tokenizer[\"EOS_None\"],\n",
        "        pad_id=tokenizer[\"PAD_None\"],\n",
        "        bos_id=tokenizer[\"BOS_None\"],\n",
        "        max_len=max_len,\n",
        "        show_progress=False\n",
        "    )\n",
        "    file_name = str(i)+\".mid\"/\n",
        "    ids_to_midi(generated_ids, tokenizer, file_name=file_name, output_dir=output_folder)\n"
      ],
      "metadata": {
        "id": "5d7geVO3Oj2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate some files"
      ],
      "metadata": {
        "id": "qO1YVt5xP2FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_files = 10\n",
        "generate_midi(dataset_test,\n",
        "               model,\n",
        "               tokenizer,\n",
        "               output_folder=\"/content/gen_midi/\",\n",
        "               num_files=n_files,\n",
        "               max_len=100\n",
        "               )"
      ],
      "metadata": {
        "id": "Bpa2z_dzP0kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd PART - Playing the MIDI"
      ],
      "metadata": {
        "id": "4e3Ci7lIQ4WN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPKJ0WAsd1pT"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtbAeJt-d4ML"
      },
      "outputs": [],
      "source": [
        "def random_file(root, keyword=None):\n",
        "    import glob\n",
        "    import os\n",
        "    import random\n",
        "    mid_files = glob.glob(os.path.join(root, \"**\", \"*.mid\"), recursive=True)\n",
        "    if keyword is not None:\n",
        "      mid_files = [file for file in mid_files if keyword in file.lower()]\n",
        "    return random.choice(mid_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "hJG7c4biNYrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZEn9Xq4aAWO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Installing the required libraries\n",
        "%%capture\n",
        "!apt-get update -qq && apt-get install -y fluidsynth\n",
        "!pip install pretty_midi midi-clip\n",
        "\n",
        "# GS2\n",
        "!gdown 1wlpTIS70nQHMrYBjDT0M6nyg07kUejUv\n",
        "!unzip GeneralUser_GS_v2.0.0--doc_r2.zip\n",
        "!rm -rf GeneralUser_GS_v2.0.0--doc_r2.zip support documentation demo\\ MIDIs\n",
        "!mv GeneralUser\\ GS\\ v2.0.0.sf2 guGS.sf2\n",
        "\n",
        "# PICONICA\n",
        "!gdown 1uk51T9Gvo1n2JRl3_CHCg2FVGWiNI4qJ\n",
        "\n",
        "# Utility library\n",
        "!wget https://raw.githubusercontent.com/roostico/NesGen/refs/heads/main/utility.py\n",
        "\n",
        "from utility import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using generated MIDI"
      ],
      "metadata": {
        "id": "XKlx5gVYN_6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show info\n",
        "\n",
        "generated_midi_path = \"gen_midi/3.mid\" # @param {type:\"string\"}\n",
        "\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(generated_midi_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4AYEKGI5OCW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Play the MIDI\n",
        "\n",
        "generated_midi_path = \"gen_midi/4.mid\" # @param {type:\"string\"}\n",
        "soundfont = \"PICONICA.sf2\" # @param [\"PICONICA.sf2\", \"guGS.sf2\", \"PokeDP.sf2\"]\n",
        "\n",
        "playMidi(generated_midi_path, soundfont_path=soundfont)"
      ],
      "metadata": {
        "id": "5HMXZUnuoNFY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras (playing other MIDIs)"
      ],
      "metadata": {
        "id": "ImkU4rMAN1oi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CithkaLAafKv"
      },
      "source": [
        "## Play a random MIDI of the Lakh dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUE9qdC2aiOs"
      },
      "outputs": [],
      "source": [
        "path = random_file(dataset_path)\n",
        "print(\"Converting: \" + path)\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(path)\n",
        "print(\"Synthetized:\")\n",
        "playMidi(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Play a random MIDI of the NESMDB dataset"
      ],
      "metadata": {
        "id": "RN-UiflHNYQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = random_file(\"nesmdb_midi\")\n",
        "print(\"Converting: \" + path)\n",
        "print(\"Midi info:\")\n",
        "show_midi_info(path)\n",
        "print(\"Synthetized:\")\n",
        "playMidi(path, soundfont_path=\"PICONICA.sf2\", velocity_change=30, gain=1)"
      ],
      "metadata": {
        "id": "K-1eJsT7NX_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}